{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18872d5e-2ee7-4f1c-8374-c436aa9ea3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, GradientBoostingClassifier, VotingClassifier, \n",
    "    AdaBoostClassifier, StackingClassifier\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    cross_val_score, StratifiedKFold, train_test_split, cross_val_predict, \n",
    "    GridSearchCV, RandomizedSearchCV\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, make_scorer, roc_auc_score, \n",
    "    confusion_matrix, classification_report\n",
    ")\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler, LabelEncoder, OneHotEncoder, RobustScaler\n",
    ")\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.feature_selection import RFECV, SelectFromModel\n",
    "\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.activations import linear, relu, sigmoid\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from imblearn.pipeline import make_pipeline as make_imblearn_pipeline\n",
    "from imblearn.pipeline import Pipeline as imblearn_Pipeline\n",
    "\n",
    "from feature_engine.encoding import CountFrequencyEncoder\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "import random\n",
    "\n",
    "from Functions_Classes import *\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "np.random.seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "403b851f-60a3-4d92-838e-9d6f00c5cc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"C:/Users/Cagan Deliktas/Desktop/ProjectDataMining2/DM2_DataCraft/data/training_data.xls\")\n",
    "X_test = pd.read_excel(\"C:/Users/Cagan Deliktas/Desktop/ProjectDataMining2/DM2_DataCraft/data/test_data_no_target.xls\")\n",
    "\n",
    "df = df.loc[:, df.columns != 'Perform']\n",
    "#df = df.loc[:, df.columns != 'Group']\n",
    "\n",
    "\n",
    "X_train = df.loc[:, df.columns != 'Class']\n",
    "y_train = df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "006456f7-eecd-4486-abb2-db0ff3ef51a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = X_train.loc[:, ~X_train.columns.isin(['Group'])].columns.to_list()\n",
    "X_train.loc[:, numeric_columns] = X_train.loc[:, numeric_columns].replace(\n",
    "    {\n",
    "        'NA': np.nan, \n",
    "        '': np.nan,\n",
    "        ' ': np.nan\n",
    "    }\n",
    ").astype(float)\n",
    "\n",
    "numeric_columns = X_test.loc[:, ~X_test.columns.isin(['Group'])].columns.to_list()\n",
    "X_test[numeric_columns] = X_test.loc[:, numeric_columns].replace(\n",
    "    {\n",
    "        'NA': np.nan, \n",
    "        '': np.nan,\n",
    "        ' ': np.nan\n",
    "    }\n",
    ").astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88066b03-5993-437f-9af7-d0f10d3bf8ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group</th>\n",
       "      <th>I1</th>\n",
       "      <th>I2</th>\n",
       "      <th>I3</th>\n",
       "      <th>I4</th>\n",
       "      <th>I5</th>\n",
       "      <th>I6</th>\n",
       "      <th>I7</th>\n",
       "      <th>I8</th>\n",
       "      <th>I9</th>\n",
       "      <th>I10</th>\n",
       "      <th>I11</th>\n",
       "      <th>I12</th>\n",
       "      <th>I13</th>\n",
       "      <th>I14</th>\n",
       "      <th>I15</th>\n",
       "      <th>I16</th>\n",
       "      <th>I17</th>\n",
       "      <th>I18</th>\n",
       "      <th>I19</th>\n",
       "      <th>I20</th>\n",
       "      <th>I21</th>\n",
       "      <th>I22</th>\n",
       "      <th>I23</th>\n",
       "      <th>I24</th>\n",
       "      <th>I25</th>\n",
       "      <th>I26</th>\n",
       "      <th>I27</th>\n",
       "      <th>I28</th>\n",
       "      <th>I29</th>\n",
       "      <th>I30</th>\n",
       "      <th>I31</th>\n",
       "      <th>I32</th>\n",
       "      <th>I33</th>\n",
       "      <th>I34</th>\n",
       "      <th>I35</th>\n",
       "      <th>I36</th>\n",
       "      <th>I37</th>\n",
       "      <th>I38</th>\n",
       "      <th>I39</th>\n",
       "      <th>I40</th>\n",
       "      <th>I41</th>\n",
       "      <th>I42</th>\n",
       "      <th>I43</th>\n",
       "      <th>I44</th>\n",
       "      <th>I45</th>\n",
       "      <th>I46</th>\n",
       "      <th>I47</th>\n",
       "      <th>I48</th>\n",
       "      <th>I49</th>\n",
       "      <th>I50</th>\n",
       "      <th>I51</th>\n",
       "      <th>I52</th>\n",
       "      <th>I53</th>\n",
       "      <th>I54</th>\n",
       "      <th>I55</th>\n",
       "      <th>I56</th>\n",
       "      <th>I57</th>\n",
       "      <th>I58</th>\n",
       "      <th>dI1</th>\n",
       "      <th>dI2</th>\n",
       "      <th>dI3</th>\n",
       "      <th>dI4</th>\n",
       "      <th>dI5</th>\n",
       "      <th>dI6</th>\n",
       "      <th>dI7</th>\n",
       "      <th>dI8</th>\n",
       "      <th>dI9</th>\n",
       "      <th>dI10</th>\n",
       "      <th>dI11</th>\n",
       "      <th>dI12</th>\n",
       "      <th>dI13</th>\n",
       "      <th>dI14</th>\n",
       "      <th>dI15</th>\n",
       "      <th>dI16</th>\n",
       "      <th>dI17</th>\n",
       "      <th>dI18</th>\n",
       "      <th>dI19</th>\n",
       "      <th>dI20</th>\n",
       "      <th>dI21</th>\n",
       "      <th>dI22</th>\n",
       "      <th>dI23</th>\n",
       "      <th>dI24</th>\n",
       "      <th>dI25</th>\n",
       "      <th>dI26</th>\n",
       "      <th>dI27</th>\n",
       "      <th>dI28</th>\n",
       "      <th>dI29</th>\n",
       "      <th>dI30</th>\n",
       "      <th>dI31</th>\n",
       "      <th>dI32</th>\n",
       "      <th>dI33</th>\n",
       "      <th>dI34</th>\n",
       "      <th>dI35</th>\n",
       "      <th>dI36</th>\n",
       "      <th>dI37</th>\n",
       "      <th>dI38</th>\n",
       "      <th>dI39</th>\n",
       "      <th>dI40</th>\n",
       "      <th>dI41</th>\n",
       "      <th>dI42</th>\n",
       "      <th>dI43</th>\n",
       "      <th>dI44</th>\n",
       "      <th>dI45</th>\n",
       "      <th>dI46</th>\n",
       "      <th>dI47</th>\n",
       "      <th>dI48</th>\n",
       "      <th>dI49</th>\n",
       "      <th>dI50</th>\n",
       "      <th>dI51</th>\n",
       "      <th>dI52</th>\n",
       "      <th>dI53</th>\n",
       "      <th>dI54</th>\n",
       "      <th>dI55</th>\n",
       "      <th>dI56</th>\n",
       "      <th>dI57</th>\n",
       "      <th>dI58</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G9</td>\n",
       "      <td>0.136495</td>\n",
       "      <td>-0.028429</td>\n",
       "      <td>-0.037772</td>\n",
       "      <td>-0.232459</td>\n",
       "      <td>-0.016222</td>\n",
       "      <td>-0.187506</td>\n",
       "      <td>-0.322545</td>\n",
       "      <td>-0.043743</td>\n",
       "      <td>0.125389</td>\n",
       "      <td>-0.014757</td>\n",
       "      <td>-0.033105</td>\n",
       "      <td>0.303035</td>\n",
       "      <td>-0.093811</td>\n",
       "      <td>-0.598917</td>\n",
       "      <td>-0.271292</td>\n",
       "      <td>-0.256749</td>\n",
       "      <td>-0.100146</td>\n",
       "      <td>-0.045525</td>\n",
       "      <td>-0.078422</td>\n",
       "      <td>-0.060129</td>\n",
       "      <td>-0.069528</td>\n",
       "      <td>-0.052432</td>\n",
       "      <td>-0.114432</td>\n",
       "      <td>-0.104989</td>\n",
       "      <td>0.342845</td>\n",
       "      <td>-0.159417</td>\n",
       "      <td>0.006772</td>\n",
       "      <td>-0.303193</td>\n",
       "      <td>-0.163287</td>\n",
       "      <td>-0.080599</td>\n",
       "      <td>-0.828880</td>\n",
       "      <td>-1.064215</td>\n",
       "      <td>-0.547067</td>\n",
       "      <td>-0.540497</td>\n",
       "      <td>-0.676045</td>\n",
       "      <td>-0.305007</td>\n",
       "      <td>-0.507724</td>\n",
       "      <td>-0.191437</td>\n",
       "      <td>-0.087362</td>\n",
       "      <td>-0.856151</td>\n",
       "      <td>0.802525</td>\n",
       "      <td>0.733080</td>\n",
       "      <td>0.006512</td>\n",
       "      <td>0.533290</td>\n",
       "      <td>0.195197</td>\n",
       "      <td>0.058094</td>\n",
       "      <td>-0.228889</td>\n",
       "      <td>-0.150821</td>\n",
       "      <td>-0.104986</td>\n",
       "      <td>-0.026743</td>\n",
       "      <td>0.188312</td>\n",
       "      <td>-0.250701</td>\n",
       "      <td>-0.101190</td>\n",
       "      <td>-0.357521</td>\n",
       "      <td>-0.527956</td>\n",
       "      <td>0.611385</td>\n",
       "      <td>-0.092714</td>\n",
       "      <td>-0.055733</td>\n",
       "      <td>-0.065709</td>\n",
       "      <td>-0.002144</td>\n",
       "      <td>-0.004367</td>\n",
       "      <td>-0.079805</td>\n",
       "      <td>0.178280</td>\n",
       "      <td>0.078155</td>\n",
       "      <td>0.072802</td>\n",
       "      <td>0.002090</td>\n",
       "      <td>0.211770</td>\n",
       "      <td>-0.003073</td>\n",
       "      <td>-0.188447</td>\n",
       "      <td>0.117769</td>\n",
       "      <td>0.001613</td>\n",
       "      <td>-0.024223</td>\n",
       "      <td>0.103204</td>\n",
       "      <td>0.032484</td>\n",
       "      <td>0.002688</td>\n",
       "      <td>0.000765</td>\n",
       "      <td>-0.004447</td>\n",
       "      <td>0.148967</td>\n",
       "      <td>-0.018521</td>\n",
       "      <td>-0.014110</td>\n",
       "      <td>-0.001996</td>\n",
       "      <td>-0.002369</td>\n",
       "      <td>-0.120036</td>\n",
       "      <td>0.013172</td>\n",
       "      <td>-0.215571</td>\n",
       "      <td>-0.021999</td>\n",
       "      <td>0.001728</td>\n",
       "      <td>-0.000050</td>\n",
       "      <td>-0.012120</td>\n",
       "      <td>-0.040172</td>\n",
       "      <td>-0.060103</td>\n",
       "      <td>-0.059464</td>\n",
       "      <td>-0.044899</td>\n",
       "      <td>0.015735</td>\n",
       "      <td>0.022919</td>\n",
       "      <td>-0.003106</td>\n",
       "      <td>0.001233</td>\n",
       "      <td>-0.002339</td>\n",
       "      <td>0.040628</td>\n",
       "      <td>0.411684</td>\n",
       "      <td>0.073090</td>\n",
       "      <td>0.526222</td>\n",
       "      <td>0.071060</td>\n",
       "      <td>-0.019531</td>\n",
       "      <td>0.359889</td>\n",
       "      <td>-0.020476</td>\n",
       "      <td>0.057151</td>\n",
       "      <td>0.077110</td>\n",
       "      <td>0.102563</td>\n",
       "      <td>0.188481</td>\n",
       "      <td>-0.016027</td>\n",
       "      <td>-0.135451</td>\n",
       "      <td>-0.189667</td>\n",
       "      <td>0.250967</td>\n",
       "      <td>0.022171</td>\n",
       "      <td>-0.004265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G5</td>\n",
       "      <td>-0.714522</td>\n",
       "      <td>-0.042137</td>\n",
       "      <td>-0.052968</td>\n",
       "      <td>-0.796862</td>\n",
       "      <td>-0.018394</td>\n",
       "      <td>0.070102</td>\n",
       "      <td>-0.076321</td>\n",
       "      <td>-0.063864</td>\n",
       "      <td>-1.045521</td>\n",
       "      <td>-0.037353</td>\n",
       "      <td>-0.792515</td>\n",
       "      <td>-1.082483</td>\n",
       "      <td>0.025798</td>\n",
       "      <td>-0.833652</td>\n",
       "      <td>-0.625088</td>\n",
       "      <td>-0.333608</td>\n",
       "      <td>0.072579</td>\n",
       "      <td>-0.046963</td>\n",
       "      <td>0.223022</td>\n",
       "      <td>-0.605902</td>\n",
       "      <td>-0.131099</td>\n",
       "      <td>-0.235929</td>\n",
       "      <td>-0.073920</td>\n",
       "      <td>-0.063247</td>\n",
       "      <td>-0.798768</td>\n",
       "      <td>-0.899983</td>\n",
       "      <td>1.388771</td>\n",
       "      <td>-0.248677</td>\n",
       "      <td>-0.058083</td>\n",
       "      <td>-0.014470</td>\n",
       "      <td>0.092095</td>\n",
       "      <td>0.561368</td>\n",
       "      <td>0.224819</td>\n",
       "      <td>0.223190</td>\n",
       "      <td>0.098852</td>\n",
       "      <td>-0.128227</td>\n",
       "      <td>-0.215876</td>\n",
       "      <td>-0.007164</td>\n",
       "      <td>-0.035260</td>\n",
       "      <td>-0.123911</td>\n",
       "      <td>-0.089751</td>\n",
       "      <td>-0.094963</td>\n",
       "      <td>0.362818</td>\n",
       "      <td>0.011107</td>\n",
       "      <td>-1.506356</td>\n",
       "      <td>-0.573679</td>\n",
       "      <td>-0.955222</td>\n",
       "      <td>-0.818880</td>\n",
       "      <td>-1.063295</td>\n",
       "      <td>-1.022679</td>\n",
       "      <td>-1.336188</td>\n",
       "      <td>-0.612039</td>\n",
       "      <td>-0.061357</td>\n",
       "      <td>-0.482805</td>\n",
       "      <td>-0.017077</td>\n",
       "      <td>1.192135</td>\n",
       "      <td>-0.114981</td>\n",
       "      <td>-0.028074</td>\n",
       "      <td>-0.004451</td>\n",
       "      <td>-0.000536</td>\n",
       "      <td>-0.002288</td>\n",
       "      <td>-0.045597</td>\n",
       "      <td>-0.080639</td>\n",
       "      <td>-0.081924</td>\n",
       "      <td>-0.033862</td>\n",
       "      <td>-0.005111</td>\n",
       "      <td>-0.261836</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>-0.045046</td>\n",
       "      <td>0.999854</td>\n",
       "      <td>-0.008835</td>\n",
       "      <td>-0.122379</td>\n",
       "      <td>-0.199892</td>\n",
       "      <td>0.013615</td>\n",
       "      <td>0.014404</td>\n",
       "      <td>-0.000405</td>\n",
       "      <td>0.021573</td>\n",
       "      <td>-0.024160</td>\n",
       "      <td>-0.037420</td>\n",
       "      <td>-0.012610</td>\n",
       "      <td>0.003007</td>\n",
       "      <td>0.003617</td>\n",
       "      <td>-0.106893</td>\n",
       "      <td>-0.394834</td>\n",
       "      <td>-0.132496</td>\n",
       "      <td>-0.027354</td>\n",
       "      <td>-0.129804</td>\n",
       "      <td>-0.066157</td>\n",
       "      <td>-0.494334</td>\n",
       "      <td>0.123781</td>\n",
       "      <td>0.284328</td>\n",
       "      <td>0.281308</td>\n",
       "      <td>0.212767</td>\n",
       "      <td>0.192042</td>\n",
       "      <td>0.146926</td>\n",
       "      <td>-0.118826</td>\n",
       "      <td>-0.039203</td>\n",
       "      <td>-0.256107</td>\n",
       "      <td>0.176622</td>\n",
       "      <td>0.168840</td>\n",
       "      <td>0.487752</td>\n",
       "      <td>0.029464</td>\n",
       "      <td>0.014232</td>\n",
       "      <td>0.039633</td>\n",
       "      <td>0.025667</td>\n",
       "      <td>0.006626</td>\n",
       "      <td>0.005180</td>\n",
       "      <td>0.006128</td>\n",
       "      <td>-0.016375</td>\n",
       "      <td>0.020727</td>\n",
       "      <td>-0.006525</td>\n",
       "      <td>-0.018790</td>\n",
       "      <td>-0.098543</td>\n",
       "      <td>0.317744</td>\n",
       "      <td>-0.180502</td>\n",
       "      <td>-0.009215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G10</td>\n",
       "      <td>0.104791</td>\n",
       "      <td>-0.038188</td>\n",
       "      <td>-0.053191</td>\n",
       "      <td>0.620233</td>\n",
       "      <td>0.148587</td>\n",
       "      <td>0.489875</td>\n",
       "      <td>0.319274</td>\n",
       "      <td>-0.060246</td>\n",
       "      <td>0.053174</td>\n",
       "      <td>-0.025008</td>\n",
       "      <td>-0.456840</td>\n",
       "      <td>1.284450</td>\n",
       "      <td>-0.133470</td>\n",
       "      <td>3.207672</td>\n",
       "      <td>2.373230</td>\n",
       "      <td>1.304427</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.361293</td>\n",
       "      <td>2.995661</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.188988</td>\n",
       "      <td>-0.044158</td>\n",
       "      <td>-0.024550</td>\n",
       "      <td>-0.586562</td>\n",
       "      <td>-0.176292</td>\n",
       "      <td>-1.013037</td>\n",
       "      <td>0.066912</td>\n",
       "      <td>0.219649</td>\n",
       "      <td>0.154490</td>\n",
       "      <td>2.370951</td>\n",
       "      <td>1.384675</td>\n",
       "      <td>0.489152</td>\n",
       "      <td>0.484715</td>\n",
       "      <td>0.367301</td>\n",
       "      <td>0.749572</td>\n",
       "      <td>0.669410</td>\n",
       "      <td>0.423228</td>\n",
       "      <td>0.226897</td>\n",
       "      <td>3.227283</td>\n",
       "      <td>-0.329997</td>\n",
       "      <td>-0.327579</td>\n",
       "      <td>-1.033898</td>\n",
       "      <td>0.014531</td>\n",
       "      <td>0.211889</td>\n",
       "      <td>-1.197156</td>\n",
       "      <td>2.860444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.584223</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.272375</td>\n",
       "      <td>7.427558</td>\n",
       "      <td>-0.182816</td>\n",
       "      <td>-2.713205</td>\n",
       "      <td>-1.877595</td>\n",
       "      <td>-0.568691</td>\n",
       "      <td>0.224945</td>\n",
       "      <td>0.052749</td>\n",
       "      <td>0.377640</td>\n",
       "      <td>0.002656</td>\n",
       "      <td>0.001226</td>\n",
       "      <td>0.226060</td>\n",
       "      <td>0.207653</td>\n",
       "      <td>0.270327</td>\n",
       "      <td>0.283061</td>\n",
       "      <td>0.002934</td>\n",
       "      <td>0.454366</td>\n",
       "      <td>0.004264</td>\n",
       "      <td>0.188623</td>\n",
       "      <td>-0.265918</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.063796</td>\n",
       "      <td>1.076458</td>\n",
       "      <td>0.240011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.028327</td>\n",
       "      <td>1.764826</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005847</td>\n",
       "      <td>-0.011166</td>\n",
       "      <td>-0.012626</td>\n",
       "      <td>-0.010822</td>\n",
       "      <td>0.056514</td>\n",
       "      <td>-0.100007</td>\n",
       "      <td>-0.216081</td>\n",
       "      <td>-0.127274</td>\n",
       "      <td>-0.056206</td>\n",
       "      <td>0.175751</td>\n",
       "      <td>-0.011770</td>\n",
       "      <td>0.493157</td>\n",
       "      <td>0.487919</td>\n",
       "      <td>0.438576</td>\n",
       "      <td>0.574623</td>\n",
       "      <td>0.564379</td>\n",
       "      <td>-0.165933</td>\n",
       "      <td>-0.051256</td>\n",
       "      <td>0.410379</td>\n",
       "      <td>0.056624</td>\n",
       "      <td>0.047592</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.020586</td>\n",
       "      <td>0.237539</td>\n",
       "      <td>0.017314</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.404158</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.272937</td>\n",
       "      <td>0.774169</td>\n",
       "      <td>-0.007144</td>\n",
       "      <td>0.123954</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.110103</td>\n",
       "      <td>0.186669</td>\n",
       "      <td>-0.030720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G2</td>\n",
       "      <td>-0.532847</td>\n",
       "      <td>-0.006582</td>\n",
       "      <td>-0.023377</td>\n",
       "      <td>1.306702</td>\n",
       "      <td>-0.068909</td>\n",
       "      <td>0.048024</td>\n",
       "      <td>-0.119481</td>\n",
       "      <td>-0.021057</td>\n",
       "      <td>-1.012916</td>\n",
       "      <td>-0.011783</td>\n",
       "      <td>1.206727</td>\n",
       "      <td>0.311773</td>\n",
       "      <td>-0.005928</td>\n",
       "      <td>3.869459</td>\n",
       "      <td>-1.064793</td>\n",
       "      <td>0.107702</td>\n",
       "      <td>-0.126984</td>\n",
       "      <td>-0.044360</td>\n",
       "      <td>-0.181023</td>\n",
       "      <td>-0.691971</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.195138</td>\n",
       "      <td>-0.104877</td>\n",
       "      <td>-0.093976</td>\n",
       "      <td>-0.757725</td>\n",
       "      <td>0.004432</td>\n",
       "      <td>-1.471299</td>\n",
       "      <td>0.643575</td>\n",
       "      <td>-0.067005</td>\n",
       "      <td>-0.006874</td>\n",
       "      <td>-0.087499</td>\n",
       "      <td>0.110638</td>\n",
       "      <td>0.046880</td>\n",
       "      <td>0.047141</td>\n",
       "      <td>-0.274713</td>\n",
       "      <td>0.169046</td>\n",
       "      <td>-0.179742</td>\n",
       "      <td>0.047391</td>\n",
       "      <td>0.015197</td>\n",
       "      <td>0.105158</td>\n",
       "      <td>-0.045135</td>\n",
       "      <td>-0.051329</td>\n",
       "      <td>0.202098</td>\n",
       "      <td>0.034693</td>\n",
       "      <td>2.904519</td>\n",
       "      <td>4.514844</td>\n",
       "      <td>-0.241111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.521576</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.308812</td>\n",
       "      <td>-0.542532</td>\n",
       "      <td>-0.165028</td>\n",
       "      <td>1.490354</td>\n",
       "      <td>-1.550745</td>\n",
       "      <td>-0.918676</td>\n",
       "      <td>0.013484</td>\n",
       "      <td>-0.013198</td>\n",
       "      <td>0.050586</td>\n",
       "      <td>0.010356</td>\n",
       "      <td>0.007522</td>\n",
       "      <td>0.194792</td>\n",
       "      <td>0.010436</td>\n",
       "      <td>0.107880</td>\n",
       "      <td>0.122549</td>\n",
       "      <td>0.017641</td>\n",
       "      <td>0.136566</td>\n",
       "      <td>0.010365</td>\n",
       "      <td>0.086853</td>\n",
       "      <td>-0.286395</td>\n",
       "      <td>-0.014883</td>\n",
       "      <td>0.347297</td>\n",
       "      <td>0.017765</td>\n",
       "      <td>0.068701</td>\n",
       "      <td>0.015540</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.016119</td>\n",
       "      <td>0.003992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.043909</td>\n",
       "      <td>-0.000107</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>-0.003895</td>\n",
       "      <td>0.002490</td>\n",
       "      <td>-0.003034</td>\n",
       "      <td>-0.015845</td>\n",
       "      <td>0.002377</td>\n",
       "      <td>0.001974</td>\n",
       "      <td>0.056340</td>\n",
       "      <td>0.010802</td>\n",
       "      <td>0.063094</td>\n",
       "      <td>0.062424</td>\n",
       "      <td>0.057012</td>\n",
       "      <td>0.118399</td>\n",
       "      <td>0.116161</td>\n",
       "      <td>-0.017039</td>\n",
       "      <td>0.000839</td>\n",
       "      <td>0.054025</td>\n",
       "      <td>0.030561</td>\n",
       "      <td>0.006389</td>\n",
       "      <td>-0.073937</td>\n",
       "      <td>0.764136</td>\n",
       "      <td>-0.076195</td>\n",
       "      <td>-0.114682</td>\n",
       "      <td>0.119667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001799</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004938</td>\n",
       "      <td>0.018494</td>\n",
       "      <td>-0.003350</td>\n",
       "      <td>-0.029214</td>\n",
       "      <td>0.045747</td>\n",
       "      <td>-0.076884</td>\n",
       "      <td>-0.037859</td>\n",
       "      <td>-0.012046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G3</td>\n",
       "      <td>-0.200815</td>\n",
       "      <td>-0.016334</td>\n",
       "      <td>-0.036754</td>\n",
       "      <td>-0.886675</td>\n",
       "      <td>0.484495</td>\n",
       "      <td>-1.148744</td>\n",
       "      <td>0.152517</td>\n",
       "      <td>-0.043580</td>\n",
       "      <td>-0.935537</td>\n",
       "      <td>-0.023262</td>\n",
       "      <td>-0.908986</td>\n",
       "      <td>-0.525121</td>\n",
       "      <td>0.015492</td>\n",
       "      <td>-0.347325</td>\n",
       "      <td>0.296360</td>\n",
       "      <td>-0.242201</td>\n",
       "      <td>0.120049</td>\n",
       "      <td>-0.048293</td>\n",
       "      <td>0.290658</td>\n",
       "      <td>-0.345816</td>\n",
       "      <td>0.249586</td>\n",
       "      <td>-0.241812</td>\n",
       "      <td>-0.082055</td>\n",
       "      <td>-0.077706</td>\n",
       "      <td>-0.845163</td>\n",
       "      <td>-0.257777</td>\n",
       "      <td>0.919065</td>\n",
       "      <td>-0.522102</td>\n",
       "      <td>0.146076</td>\n",
       "      <td>0.043851</td>\n",
       "      <td>1.281726</td>\n",
       "      <td>0.039106</td>\n",
       "      <td>0.135331</td>\n",
       "      <td>0.134652</td>\n",
       "      <td>0.654099</td>\n",
       "      <td>1.437536</td>\n",
       "      <td>1.995784</td>\n",
       "      <td>-0.145004</td>\n",
       "      <td>-0.029483</td>\n",
       "      <td>0.252151</td>\n",
       "      <td>0.308723</td>\n",
       "      <td>0.293393</td>\n",
       "      <td>-0.527888</td>\n",
       "      <td>-0.003680</td>\n",
       "      <td>-1.553644</td>\n",
       "      <td>-1.233945</td>\n",
       "      <td>-0.947111</td>\n",
       "      <td>-0.926073</td>\n",
       "      <td>-0.772468</td>\n",
       "      <td>-0.636440</td>\n",
       "      <td>-0.833875</td>\n",
       "      <td>-0.527935</td>\n",
       "      <td>-0.014170</td>\n",
       "      <td>-0.142943</td>\n",
       "      <td>1.070523</td>\n",
       "      <td>-0.284682</td>\n",
       "      <td>-0.155110</td>\n",
       "      <td>-0.026941</td>\n",
       "      <td>0.480767</td>\n",
       "      <td>0.021831</td>\n",
       "      <td>-0.003234</td>\n",
       "      <td>-0.041412</td>\n",
       "      <td>0.112513</td>\n",
       "      <td>-0.157224</td>\n",
       "      <td>-0.146180</td>\n",
       "      <td>-0.014677</td>\n",
       "      <td>-0.451950</td>\n",
       "      <td>0.034598</td>\n",
       "      <td>-0.114443</td>\n",
       "      <td>-0.307095</td>\n",
       "      <td>-0.346711</td>\n",
       "      <td>0.104144</td>\n",
       "      <td>-0.508920</td>\n",
       "      <td>-0.096666</td>\n",
       "      <td>0.044162</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.085082</td>\n",
       "      <td>0.254664</td>\n",
       "      <td>-0.000408</td>\n",
       "      <td>-0.015390</td>\n",
       "      <td>-0.006226</td>\n",
       "      <td>-0.012542</td>\n",
       "      <td>-0.101059</td>\n",
       "      <td>0.091145</td>\n",
       "      <td>0.282110</td>\n",
       "      <td>-0.005348</td>\n",
       "      <td>0.112377</td>\n",
       "      <td>0.036976</td>\n",
       "      <td>0.731570</td>\n",
       "      <td>0.050165</td>\n",
       "      <td>0.038419</td>\n",
       "      <td>0.038011</td>\n",
       "      <td>0.265998</td>\n",
       "      <td>1.614120</td>\n",
       "      <td>1.806955</td>\n",
       "      <td>-0.122743</td>\n",
       "      <td>-0.001985</td>\n",
       "      <td>0.126103</td>\n",
       "      <td>0.630259</td>\n",
       "      <td>0.618027</td>\n",
       "      <td>-1.599633</td>\n",
       "      <td>0.032793</td>\n",
       "      <td>-0.126733</td>\n",
       "      <td>-0.163593</td>\n",
       "      <td>-0.225889</td>\n",
       "      <td>-0.026460</td>\n",
       "      <td>-0.080892</td>\n",
       "      <td>-0.095963</td>\n",
       "      <td>-0.014812</td>\n",
       "      <td>-0.324584</td>\n",
       "      <td>-0.019002</td>\n",
       "      <td>-0.379323</td>\n",
       "      <td>-0.046024</td>\n",
       "      <td>0.282145</td>\n",
       "      <td>0.011008</td>\n",
       "      <td>0.010496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Group        I1        I2        I3        I4        I5        I6        I7  \\\n",
       "0    G9  0.136495 -0.028429 -0.037772 -0.232459 -0.016222 -0.187506 -0.322545   \n",
       "1    G5 -0.714522 -0.042137 -0.052968 -0.796862 -0.018394  0.070102 -0.076321   \n",
       "2   G10  0.104791 -0.038188 -0.053191  0.620233  0.148587  0.489875  0.319274   \n",
       "3    G2 -0.532847 -0.006582 -0.023377  1.306702 -0.068909  0.048024 -0.119481   \n",
       "4    G3 -0.200815 -0.016334 -0.036754 -0.886675  0.484495 -1.148744  0.152517   \n",
       "\n",
       "         I8        I9       I10       I11       I12       I13       I14  \\\n",
       "0 -0.043743  0.125389 -0.014757 -0.033105  0.303035 -0.093811 -0.598917   \n",
       "1 -0.063864 -1.045521 -0.037353 -0.792515 -1.082483  0.025798 -0.833652   \n",
       "2 -0.060246  0.053174 -0.025008 -0.456840  1.284450 -0.133470  3.207672   \n",
       "3 -0.021057 -1.012916 -0.011783  1.206727  0.311773 -0.005928  3.869459   \n",
       "4 -0.043580 -0.935537 -0.023262 -0.908986 -0.525121  0.015492 -0.347325   \n",
       "\n",
       "        I15       I16       I17       I18       I19       I20       I21  \\\n",
       "0 -0.271292 -0.256749 -0.100146 -0.045525 -0.078422 -0.060129 -0.069528   \n",
       "1 -0.625088 -0.333608  0.072579 -0.046963  0.223022 -0.605902 -0.131099   \n",
       "2  2.373230  1.304427       NaN       NaN -0.361293  2.995661       NaN   \n",
       "3 -1.064793  0.107702 -0.126984 -0.044360 -0.181023 -0.691971       NaN   \n",
       "4  0.296360 -0.242201  0.120049 -0.048293  0.290658 -0.345816  0.249586   \n",
       "\n",
       "        I22       I23       I24       I25       I26       I27       I28  \\\n",
       "0 -0.052432 -0.114432 -0.104989  0.342845 -0.159417  0.006772 -0.303193   \n",
       "1 -0.235929 -0.073920 -0.063247 -0.798768 -0.899983  1.388771 -0.248677   \n",
       "2 -0.188988 -0.044158 -0.024550 -0.586562 -0.176292 -1.013037  0.066912   \n",
       "3  0.195138 -0.104877 -0.093976 -0.757725  0.004432 -1.471299  0.643575   \n",
       "4 -0.241812 -0.082055 -0.077706 -0.845163 -0.257777  0.919065 -0.522102   \n",
       "\n",
       "        I29       I30       I31       I32       I33       I34       I35  \\\n",
       "0 -0.163287 -0.080599 -0.828880 -1.064215 -0.547067 -0.540497 -0.676045   \n",
       "1 -0.058083 -0.014470  0.092095  0.561368  0.224819  0.223190  0.098852   \n",
       "2  0.219649  0.154490  2.370951  1.384675  0.489152  0.484715  0.367301   \n",
       "3 -0.067005 -0.006874 -0.087499  0.110638  0.046880  0.047141 -0.274713   \n",
       "4  0.146076  0.043851  1.281726  0.039106  0.135331  0.134652  0.654099   \n",
       "\n",
       "        I36       I37       I38       I39       I40       I41       I42  \\\n",
       "0 -0.305007 -0.507724 -0.191437 -0.087362 -0.856151  0.802525  0.733080   \n",
       "1 -0.128227 -0.215876 -0.007164 -0.035260 -0.123911 -0.089751 -0.094963   \n",
       "2  0.749572  0.669410  0.423228  0.226897  3.227283 -0.329997 -0.327579   \n",
       "3  0.169046 -0.179742  0.047391  0.015197  0.105158 -0.045135 -0.051329   \n",
       "4  1.437536  1.995784 -0.145004 -0.029483  0.252151  0.308723  0.293393   \n",
       "\n",
       "        I43       I44       I45       I46       I47       I48       I49  \\\n",
       "0  0.006512  0.533290  0.195197  0.058094 -0.228889 -0.150821 -0.104986   \n",
       "1  0.362818  0.011107 -1.506356 -0.573679 -0.955222 -0.818880 -1.063295   \n",
       "2 -1.033898  0.014531  0.211889 -1.197156  2.860444       NaN  3.584223   \n",
       "3  0.202098  0.034693  2.904519  4.514844 -0.241111       NaN -0.521576   \n",
       "4 -0.527888 -0.003680 -1.553644 -1.233945 -0.947111 -0.926073 -0.772468   \n",
       "\n",
       "        I50       I51       I52       I53       I54       I55       I56  \\\n",
       "0 -0.026743  0.188312 -0.250701 -0.101190 -0.357521 -0.527956  0.611385   \n",
       "1 -1.022679 -1.336188 -0.612039 -0.061357 -0.482805 -0.017077  1.192135   \n",
       "2       NaN  1.272375  7.427558 -0.182816 -2.713205 -1.877595 -0.568691   \n",
       "3       NaN -0.308812 -0.542532 -0.165028  1.490354 -1.550745 -0.918676   \n",
       "4 -0.636440 -0.833875 -0.527935 -0.014170 -0.142943  1.070523 -0.284682   \n",
       "\n",
       "        I57       I58       dI1       dI2       dI3       dI4       dI5  \\\n",
       "0 -0.092714 -0.055733 -0.065709 -0.002144 -0.004367 -0.079805  0.178280   \n",
       "1 -0.114981 -0.028074 -0.004451 -0.000536 -0.002288 -0.045597 -0.080639   \n",
       "2  0.224945  0.052749  0.377640  0.002656  0.001226  0.226060  0.207653   \n",
       "3  0.013484 -0.013198  0.050586  0.010356  0.007522  0.194792  0.010436   \n",
       "4 -0.155110 -0.026941  0.480767  0.021831 -0.003234 -0.041412  0.112513   \n",
       "\n",
       "        dI6       dI7       dI8       dI9      dI10      dI11      dI12  \\\n",
       "0  0.078155  0.072802  0.002090  0.211770 -0.003073 -0.188447  0.117769   \n",
       "1 -0.081924 -0.033862 -0.005111 -0.261836  0.000122 -0.045046  0.999854   \n",
       "2  0.270327  0.283061  0.002934  0.454366  0.004264  0.188623 -0.265918   \n",
       "3  0.107880  0.122549  0.017641  0.136566  0.010365  0.086853 -0.286395   \n",
       "4 -0.157224 -0.146180 -0.014677 -0.451950  0.034598 -0.114443 -0.307095   \n",
       "\n",
       "       dI13      dI14      dI15      dI16      dI17      dI18      dI19  \\\n",
       "0  0.001613 -0.024223  0.103204  0.032484  0.002688  0.000765 -0.004447   \n",
       "1 -0.008835 -0.122379 -0.199892  0.013615  0.014404 -0.000405  0.021573   \n",
       "2  0.000000  2.063796  1.076458  0.240011       NaN       NaN -0.028327   \n",
       "3 -0.014883  0.347297  0.017765  0.068701  0.015540  0.000208  0.016119   \n",
       "4 -0.346711  0.104144 -0.508920 -0.096666  0.044162  0.000159  0.085082   \n",
       "\n",
       "       dI20      dI21      dI22      dI23      dI24      dI25      dI26  \\\n",
       "0  0.148967 -0.018521 -0.014110 -0.001996 -0.002369 -0.120036  0.013172   \n",
       "1 -0.024160 -0.037420 -0.012610  0.003007  0.003617 -0.106893 -0.394834   \n",
       "2  1.764826       NaN  0.005847 -0.011166 -0.012626 -0.010822  0.056514   \n",
       "3  0.003992       NaN  0.043909 -0.000107  0.000099 -0.003895  0.002490   \n",
       "4  0.254664 -0.000408 -0.015390 -0.006226 -0.012542 -0.101059  0.091145   \n",
       "\n",
       "       dI27      dI28      dI29      dI30      dI31      dI32      dI33  \\\n",
       "0 -0.215571 -0.021999  0.001728 -0.000050 -0.012120 -0.040172 -0.060103   \n",
       "1 -0.132496 -0.027354 -0.129804 -0.066157 -0.494334  0.123781  0.284328   \n",
       "2 -0.100007 -0.216081 -0.127274 -0.056206  0.175751 -0.011770  0.493157   \n",
       "3 -0.003034 -0.015845  0.002377  0.001974  0.056340  0.010802  0.063094   \n",
       "4  0.282110 -0.005348  0.112377  0.036976  0.731570  0.050165  0.038419   \n",
       "\n",
       "       dI34      dI35      dI36      dI37      dI38      dI39      dI40  \\\n",
       "0 -0.059464 -0.044899  0.015735  0.022919 -0.003106  0.001233 -0.002339   \n",
       "1  0.281308  0.212767  0.192042  0.146926 -0.118826 -0.039203 -0.256107   \n",
       "2  0.487919  0.438576  0.574623  0.564379 -0.165933 -0.051256  0.410379   \n",
       "3  0.062424  0.057012  0.118399  0.116161 -0.017039  0.000839  0.054025   \n",
       "4  0.038011  0.265998  1.614120  1.806955 -0.122743 -0.001985  0.126103   \n",
       "\n",
       "       dI41      dI42      dI43      dI44      dI45      dI46      dI47  \\\n",
       "0  0.040628  0.411684  0.073090  0.526222  0.071060 -0.019531  0.359889   \n",
       "1  0.176622  0.168840  0.487752  0.029464  0.014232  0.039633  0.025667   \n",
       "2  0.056624  0.047592  0.000000 -0.020586  0.237539  0.017314  0.516667   \n",
       "3  0.030561  0.006389 -0.073937  0.764136 -0.076195 -0.114682  0.119667   \n",
       "4  0.630259  0.618027 -1.599633  0.032793 -0.126733 -0.163593 -0.225889   \n",
       "\n",
       "       dI48      dI49      dI50      dI51      dI52      dI53      dI54  \\\n",
       "0 -0.020476  0.057151  0.077110  0.102563  0.188481 -0.016027 -0.135451   \n",
       "1  0.006626  0.005180  0.006128 -0.016375  0.020727 -0.006525 -0.018790   \n",
       "2       NaN  0.404158       NaN  0.272937  0.774169 -0.007144  0.123954   \n",
       "3       NaN  0.001799       NaN  0.004938  0.018494 -0.003350 -0.029214   \n",
       "4 -0.026460 -0.080892 -0.095963 -0.014812 -0.324584 -0.019002 -0.379323   \n",
       "\n",
       "       dI55      dI56      dI57      dI58  \n",
       "0 -0.189667  0.250967  0.022171 -0.004265  \n",
       "1 -0.098543  0.317744 -0.180502 -0.009215  \n",
       "2  0.000000 -0.110103  0.186669 -0.030720  \n",
       "3  0.045747 -0.076884 -0.037859 -0.012046  \n",
       "4 -0.046024  0.282145  0.011008  0.010496  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bc0384-cbe0-44f2-8213-eb9593d584ad",
   "metadata": {},
   "source": [
    "## Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aecc89f2-c2ee-4ea5-8684-821d96bb9233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 117)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172d4e68-6920-4466-b4c6-440cd7b966cd",
   "metadata": {},
   "source": [
    "# Detect Categorical and Numerical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76f2cc05-a1fe-4b2c-a756-99453a0ada77",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['Group']\n",
    "numerical_features = [col for col in X_train.columns if col not in categorical_features + ['Class']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe56f45-887d-425d-96bd-e5893fd39e36",
   "metadata": {},
   "source": [
    "## Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b83df02-a2f3-4ad0-acf9-23eadc386a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_pipeline = Pipeline([\n",
    "    ('imputer', KNNImputer(n_neighbors=5)), \n",
    "    ('scaler', RobustScaler()),\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('one_hot', OneHotEncoder())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numerical_pipeline, numerical_features),\n",
    "    ('cat', categorical_pipeline, categorical_features)\n",
    "])\n",
    "\n",
    "#rfecv_classifier = DecisionTreeClassifier(random_state=42)\n",
    "#selector = RFECV(estimator=rfecv_classifier, step=1, cv=StratifiedKFold(3), scoring=matrix_error_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1852d5c1-cd68-4fb6-a691-4436538012a3",
   "metadata": {},
   "source": [
    "# Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b67dee76-3a59-4ef8-9f03-a0547f35a411",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_classifiers = {\n",
    "    'random_forest': RandomForestClassifier(random_state=42),\n",
    "    'xgboost': XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'),\n",
    "    'gradient_boosting': GradientBoostingClassifier(random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c7d5ad-cc22-4982-8ab4-d46941945757",
   "metadata": {},
   "source": [
    "### 1st Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2bd0131-06fc-46d9-b811-ef906f980149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores for random_forest: [-0.910625 -0.921875 -0.93375  -0.918125 -0.94375 ]\n",
      "Average cost error for random_forest: -0.9256249999999999\n",
      "Cross-validation scores for xgboost: [-0.92     -0.88     -0.895    -0.853125 -0.8875  ]\n",
      "Average cost error for xgboost: -0.8871249999999999\n",
      "Cross-validation scores for gradient_boosting: [-0.903125 -0.8775   -0.88     -0.880625 -0.89375 ]\n",
      "Average cost error for gradient_boosting: -0.8869999999999999\n"
     ]
    }
   ],
   "source": [
    "y_train_mapped = y_train.copy()\n",
    "y_train_mapped[y_train == -1] = 0\n",
    "y_train_mapped[y_train == 0] = 1\n",
    "y_train_mapped[y_train == 1] = 2\n",
    "\n",
    "cv_scores = {}\n",
    "\n",
    "for name, classifier in final_classifiers.items():\n",
    "    pipeline = make_imblearn_pipeline(\n",
    "        preprocessor,\n",
    "        SMOTE(random_state=42),\n",
    "        #selector,\n",
    "        classifier\n",
    "    )\n",
    "   \n",
    "    scores = cross_val_score(pipeline, X_train, y_train_mapped, cv=StratifiedKFold(5), scoring=matrix_error_function, n_jobs=-1)\n",
    "   \n",
    "    cv_scores[name] = scores\n",
    "    print(f'Cross-validation scores for {name}: {scores}')\n",
    "    print(f'Average cost error for {name}: {np.mean(scores)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb74f04-cafc-4668-9e24-53f490958d6c",
   "metadata": {},
   "source": [
    "### 2nd pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36026290-5dc5-4c21-8343-5a2825dc5dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores for random_forest: [-0.906875 -0.894375 -0.916875 -0.895    -0.891875]\n",
      "Average cost error for random_forest: -0.901\n",
      "Cross-validation scores for xgboost: [-0.92125  -0.92     -0.876875 -0.881875 -0.87875 ]\n",
      "Average cost error for xgboost: -0.8957499999999999\n",
      "Cross-validation scores for gradient_boosting: [-0.91375  -0.873125 -0.885625 -0.879375 -0.91    ]\n",
      "Average cost error for gradient_boosting: -0.892375\n"
     ]
    }
   ],
   "source": [
    "y_train_mapped = y_train.copy()\n",
    "y_train_mapped[y_train == -1] = 0\n",
    "y_train_mapped[y_train == 0] = 1\n",
    "y_train_mapped[y_train == 1] = 2\n",
    "\n",
    "cv_scores = {}\n",
    "\n",
    "for name, classifier in final_classifiers.items():\n",
    "    pipeline = make_imblearn_pipeline(\n",
    "        preprocessor,\n",
    "        RandomUnderSampler(random_state=42),\n",
    "        #selector,\n",
    "        classifier\n",
    "    )\n",
    "   \n",
    "    scores = cross_val_score(pipeline, X_train, y_train_mapped, cv=StratifiedKFold(5), scoring=matrix_error_function, n_jobs=-1)\n",
    "   \n",
    "    cv_scores[name] = scores\n",
    "    print(f'Cross-validation scores for {name}: {scores}')\n",
    "    print(f'Average cost error for {name}: {np.mean(scores)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef46b126-e091-4327-81e7-29b2349fb57a",
   "metadata": {},
   "source": [
    "### 3rd Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "960e99a6-0646-43f2-a247-52bba16be3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores for random_forest: [-0.91     -0.903125 -0.949375 -0.933125 -0.91375 ]\n",
      "Average cost error for random_forest: -0.921875\n",
      "Cross-validation scores for xgboost: [-0.916875 -0.893125 -0.87875  -0.88125  -0.9075  ]\n",
      "Average cost error for xgboost: -0.8955\n",
      "Cross-validation scores for gradient_boosting: [-0.936875 -0.8675   -0.889375 -0.871875 -0.885   ]\n",
      "Average cost error for gradient_boosting: -0.8901249999999999\n"
     ]
    }
   ],
   "source": [
    "y_train_mapped = y_train.copy()\n",
    "y_train_mapped[y_train == -1] = 0\n",
    "y_train_mapped[y_train == 0] = 1\n",
    "y_train_mapped[y_train == 1] = 2\n",
    "\n",
    "cv_scores = {}\n",
    "\n",
    "for name, classifier in final_classifiers.items():\n",
    "    pipeline = make_imblearn_pipeline(\n",
    "        preprocessor,\n",
    "        RandomOverSampler(random_state=42),\n",
    "        #selector,\n",
    "        classifier\n",
    "    )\n",
    "   \n",
    "    scores = cross_val_score(pipeline, X_train, y_train_mapped, cv=StratifiedKFold(5), scoring=matrix_error_function, n_jobs=-1)\n",
    "   \n",
    "    cv_scores[name] = scores\n",
    "    print(f'Cross-validation scores for {name}: {scores}')\n",
    "    print(f'Average cost error for {name}: {np.mean(scores)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f1d6b8-72cc-4f0b-9965-a99084f3135e",
   "metadata": {},
   "source": [
    "### 4th Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c37b2f9-7003-47f1-bf47-7a9bf2b2e29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores for random_forest: [-0.90375  -0.8975   -0.9325   -0.874375 -0.9175  ]\n",
      "Average cost error for random_forest: -0.905125\n",
      "Cross-validation scores for xgboost: [-0.909375 -0.915625 -0.89375  -0.889375 -0.9075  ]\n",
      "Average cost error for xgboost: -0.903125\n",
      "Cross-validation scores for gradient_boosting: [-0.899375 -0.87875  -0.88125  -0.87375  -0.88875 ]\n",
      "Average cost error for gradient_boosting: -0.884375\n"
     ]
    }
   ],
   "source": [
    "y_train_mapped = y_train.copy()\n",
    "y_train_mapped[y_train == -1] = 0\n",
    "y_train_mapped[y_train == 0] = 1\n",
    "y_train_mapped[y_train == 1] = 2\n",
    "\n",
    "cv_scores = {}\n",
    "\n",
    "for name, classifier in final_classifiers.items():\n",
    "    pipeline = make_imblearn_pipeline(\n",
    "        preprocessor,\n",
    "        #RandomOverSampler(random_state=42),\n",
    "        #selector,\n",
    "        classifier\n",
    "    )\n",
    "   \n",
    "    scores = cross_val_score(pipeline, X_train, y_train_mapped, cv=StratifiedKFold(5), scoring=matrix_error_function, n_jobs=-1)\n",
    "   \n",
    "    cv_scores[name] = scores\n",
    "    print(f'Cross-validation scores for {name}: {scores}')\n",
    "    print(f'Average cost error for {name}: {np.mean(scores)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2917ac84-39d6-44ff-91ab-76a305ea41df",
   "metadata": {},
   "source": [
    "### 5th Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de4d98c4-3191-4601-97cd-b431c259cdfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature selection started!\n",
      "Model Fitting and Prediction started!\n",
      "Feature selection started!\n",
      "Model Fitting and Prediction started!\n",
      "Feature selection started!\n",
      "Model Fitting and Prediction started!\n",
      "Feature selection started!\n",
      "Model Fitting and Prediction started!\n",
      "Feature selection started!\n",
      "Model Fitting and Prediction started!\n"
     ]
    }
   ],
   "source": [
    "n_neighbors = 20\n",
    "contamination = 0.1\n",
    "cv_scores_five = dict()\n",
    "cv_scores_five['random_forest'] = []\n",
    "cv_scores_five['xgboost'] = []\n",
    "cv_scores_five['gradient_boosting'] = []\n",
    "\n",
    "y_train_mapped = y_train.copy()\n",
    "y_train_mapped[y_train == -1] = 0\n",
    "y_train_mapped[y_train == 0] = 1\n",
    "y_train_mapped[y_train == 1] = 2\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "for train_index, test_index in skf.split(X_train, y_train):\n",
    "    X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "    y_train_fold, y_test_fold = y_train_mapped.iloc[train_index], y_train_mapped.iloc[test_index]\n",
    "   \n",
    "    X_train_fold_preprocessed = preprocessor.fit_transform(X_train_fold)\n",
    "    X_test_fold_preprocessed = preprocessor.transform(X_test_fold)\n",
    "   \n",
    "    lof = LocalOutlierFactor(n_neighbors=n_neighbors, contamination=contamination)\n",
    "    outliers = lof.fit_predict(X_train_fold_preprocessed)\n",
    "    mask = outliers != -1\n",
    "    X_train_fold_filtered = X_train_fold_preprocessed[mask]\n",
    "    y_train_fold_filtered = y_train_fold[mask]\n",
    "   \n",
    "    sampler = RandomOverSampler(random_state=42)\n",
    "    X_train_fold_resampled, y_train_fold_resampled = sampler.fit_resample(X_train_fold_filtered, y_train_fold_filtered)\n",
    "\n",
    "    print('Feature selection started!')\n",
    "    feature_selector = SelectFromModel(DecisionTreeClassifier(random_state=42))\n",
    "    feature_selector.fit(X_train_fold_resampled, y_train_fold_resampled)\n",
    "    X_train_fold_selected = feature_selector.transform(X_train_fold_resampled)\n",
    "    X_test_fold_selected = feature_selector.transform(X_test_fold_preprocessed)\n",
    "\n",
    "    print('Model Fitting and Prediction started!')\n",
    "    for name, classifier in final_classifiers.items():\n",
    "        classifier.fit(X_train_fold_selected, y_train_fold_resampled)\n",
    "        y_pred_fold = classifier.predict(X_test_fold_selected)\n",
    "        score = custom_error_cost_score(y_test_fold, y_pred_fold)\n",
    "        cv_scores_five[name].append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0ad1b10-27f3-4b4c-8cbf-a8eb08fbf5e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores for random_forest: [0.910625, 0.889375, 0.9075, 0.904375, 0.915625]\n",
      "Average cost error for random_forest: 0.9055\n",
      "Cross-validation scores for xgboost: [0.923125, 0.878125, 0.8725, 0.894375, 0.925625]\n",
      "Average cost error for xgboost: 0.89875\n",
      "Cross-validation scores for gradient_boosting: [0.918125, 0.893125, 0.875625, 0.8725, 0.896875]\n",
      "Average cost error for gradient_boosting: 0.89125\n"
     ]
    }
   ],
   "source": [
    "for name, scores in cv_scores_five.items():\n",
    "    print(f'Cross-validation scores for {name}: {scores}')\n",
    "    print(f'Average cost error for {name}: {np.mean(scores)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63060f84-b0b0-4353-bb4f-b96bbcefb47e",
   "metadata": {},
   "source": [
    "### 6th Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52bef8fb-4817-41e2-b043-d4ee29976020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial shape:  (6400, 117)\n",
      "Feature selection started!\n",
      "Last shape:  (2439, 58)\n",
      "Model Fitting and Prediction started!\n",
      "Model Fitting and Prediction finished!\n",
      "**********************************************************\n",
      "Initial shape:  (6400, 117)\n",
      "Feature selection started!\n",
      "Last shape:  (2415, 59)\n",
      "Model Fitting and Prediction started!\n",
      "Model Fitting and Prediction finished!\n",
      "**********************************************************\n",
      "Initial shape:  (6400, 117)\n",
      "Feature selection started!\n",
      "Last shape:  (2439, 61)\n",
      "Model Fitting and Prediction started!\n",
      "Model Fitting and Prediction finished!\n",
      "**********************************************************\n",
      "Initial shape:  (6400, 117)\n",
      "Feature selection started!\n",
      "Last shape:  (2436, 58)\n",
      "Model Fitting and Prediction started!\n",
      "Model Fitting and Prediction finished!\n",
      "**********************************************************\n",
      "Initial shape:  (6400, 117)\n",
      "Feature selection started!\n",
      "Last shape:  (2436, 63)\n",
      "Model Fitting and Prediction started!\n",
      "Model Fitting and Prediction finished!\n",
      "**********************************************************\n",
      "Cross-validation scores for random_forest: [0.9475, 0.9025, 0.906875, 0.955625, 0.9175]\n",
      "Average cost error for random_forest: 0.9259999999999999\n",
      "Cross-validation scores for xgboost: [0.9625, 0.900625, 0.918125, 0.9525, 0.905]\n",
      "Average cost error for xgboost: 0.92775\n",
      "Cross-validation scores for gradient_boosting: [0.95, 0.915, 0.906875, 0.923125, 0.921875]\n",
      "Average cost error for gradient_boosting: 0.9233750000000001\n"
     ]
    }
   ],
   "source": [
    "n_neighbors = 20\n",
    "contamination = 0.1\n",
    "cv_scores = dict()\n",
    "cv_scores['random_forest'] = []\n",
    "cv_scores['xgboost'] = []\n",
    "cv_scores['gradient_boosting'] = []\n",
    "\n",
    "y_train_mapped = y_train.copy()\n",
    "y_train_mapped[y_train == -1] = 0\n",
    "y_train_mapped[y_train == 0] = 1\n",
    "y_train_mapped[y_train == 1] = 2\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "for train_index, test_index in skf.split(X_train, y_train):\n",
    "    X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "    y_train_fold, y_test_fold = y_train_mapped.iloc[train_index], y_train_mapped.iloc[test_index]\n",
    "\n",
    "    print('Initial shape: ', pd.DataFrame(X_train_fold).shape)\n",
    "   \n",
    "    X_train_fold = preprocessor.fit_transform(X_train_fold)\n",
    "    X_test_fold = preprocessor.transform(X_test_fold)\n",
    "   \n",
    "    lof = LocalOutlierFactor(n_neighbors=n_neighbors, contamination=contamination)\n",
    "    outliers = lof.fit_predict(X_train_fold)\n",
    "    mask = outliers != -1\n",
    "    X_train_fold = X_train_fold[mask]\n",
    "    y_train_fold = y_train_fold[mask]\n",
    "   \n",
    "    sampler = RandomUnderSampler(random_state=42)\n",
    "    X_train_fold, y_train_fold = sampler.fit_resample(X_train_fold, y_train_fold)\n",
    "\n",
    "    print('Feature selection started!')\n",
    "    feature_selector = SelectFromModel(DecisionTreeClassifier(random_state=42))\n",
    "    feature_selector.fit(X_train_fold, y_train_fold)\n",
    "    X_train_fold = feature_selector.transform(X_train_fold)\n",
    "    X_test_fold = feature_selector.transform(X_test_fold)\n",
    "\n",
    "    print('Last shape: ', pd.DataFrame(X_train_fold).shape)\n",
    "\n",
    "    print('Model Fitting and Prediction started!')\n",
    "    for name, classifier in final_classifiers.items():\n",
    "        classifier.fit(X_train_fold, y_train_fold)\n",
    "        y_pred_fold = classifier.predict(X_test_fold)\n",
    "        score = custom_error_cost_score(y_test_fold, y_pred_fold)\n",
    "        cv_scores[name].append(score)\n",
    "    print('Model Fitting and Prediction finished!')\n",
    "    print('**********************************************************')\n",
    "    \n",
    "for name, scores in cv_scores.items():\n",
    "    print(f'Cross-validation scores for {name}: {scores}')\n",
    "    print(f'Average cost error for {name}: {np.mean(scores)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8db2a4-e8dd-4150-b5ab-b20afb41645b",
   "metadata": {},
   "source": [
    "### 7th Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fa153ad-bf9d-429e-b3a0-d10d6342eaf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial shape:  (6400, 117)\n",
      "Feature selection started!\n",
      "Last shape:  (9045, 61)\n",
      "Model Fitting and Prediction started!\n",
      "Model Fitting and Prediction finished!\n",
      "**********************************************************\n",
      "Initial shape:  (6400, 117)\n",
      "Feature selection started!\n",
      "Last shape:  (9042, 58)\n",
      "Model Fitting and Prediction started!\n",
      "Model Fitting and Prediction finished!\n",
      "**********************************************************\n",
      "Initial shape:  (6400, 117)\n",
      "Feature selection started!\n",
      "Last shape:  (9042, 63)\n",
      "Model Fitting and Prediction started!\n",
      "Model Fitting and Prediction finished!\n",
      "**********************************************************\n",
      "Initial shape:  (6400, 117)\n",
      "Feature selection started!\n",
      "Last shape:  (9042, 66)\n",
      "Model Fitting and Prediction started!\n",
      "Model Fitting and Prediction finished!\n",
      "**********************************************************\n",
      "Initial shape:  (6400, 117)\n",
      "Feature selection started!\n",
      "Last shape:  (9045, 61)\n",
      "Model Fitting and Prediction started!\n",
      "Model Fitting and Prediction finished!\n",
      "**********************************************************\n",
      "Cross-validation scores for random_forest: [0.91125, 0.8975, 0.935, 0.884375, 0.9075]\n",
      "Average cost error for random_forest: 0.907125\n",
      "Cross-validation scores for xgboost: [0.959375, 0.885625, 0.91875, 0.9175, 0.895625]\n",
      "Average cost error for xgboost: 0.915375\n",
      "Cross-validation scores for gradient_boosting: [0.91125, 0.86, 0.850625, 0.875, 0.86125]\n",
      "Average cost error for gradient_boosting: 0.8716250000000001\n"
     ]
    }
   ],
   "source": [
    "n_neighbors = 20\n",
    "contamination = 0.1\n",
    "cv_scores = dict()\n",
    "cv_scores['random_forest'] = []\n",
    "cv_scores['xgboost'] = []\n",
    "cv_scores['gradient_boosting'] = []\n",
    "\n",
    "y_train_mapped = y_train.copy()\n",
    "y_train_mapped[y_train == -1] = 0\n",
    "y_train_mapped[y_train == 0] = 1\n",
    "y_train_mapped[y_train == 1] = 2\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "for train_index, test_index in skf.split(X_train, y_train):\n",
    "    X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "    y_train_fold, y_test_fold = y_train_mapped.iloc[train_index], y_train_mapped.iloc[test_index]\n",
    "\n",
    "    print('Initial shape: ', pd.DataFrame(X_train_fold).shape)\n",
    "   \n",
    "    X_train_fold = preprocessor.fit_transform(X_train_fold)\n",
    "    X_test_fold = preprocessor.transform(X_test_fold)\n",
    "   \n",
    "    # lof = LocalOutlierFactor(n_neighbors=n_neighbors, contamination=contamination)\n",
    "    # outliers = lof.fit_predict(X_train_fold)\n",
    "    # mask = outliers != -1\n",
    "    # X_train_fold = X_train_fold[mask]\n",
    "    # y_train_fold = y_train_fold[mask]\n",
    "   \n",
    "    sampler = RandomOverSampler(random_state=42)\n",
    "    X_train_fold, y_train_fold = sampler.fit_resample(X_train_fold, y_train_fold)\n",
    "\n",
    "    print('Feature selection started!')\n",
    "    feature_selector = SelectFromModel(DecisionTreeClassifier(random_state=42))\n",
    "    feature_selector.fit(X_train_fold, y_train_fold)\n",
    "    X_train_fold = feature_selector.transform(X_train_fold)\n",
    "    X_test_fold = feature_selector.transform(X_test_fold)\n",
    "\n",
    "    print('Last shape: ', pd.DataFrame(X_train_fold).shape)\n",
    "\n",
    "    print('Model Fitting and Prediction started!')\n",
    "    for name, classifier in final_classifiers.items():\n",
    "        classifier.fit(X_train_fold, y_train_fold)\n",
    "        y_pred_fold = classifier.predict(X_test_fold)\n",
    "        score = custom_error_cost_score(y_test_fold, y_pred_fold)\n",
    "        cv_scores[name].append(score)\n",
    "    print('Model Fitting and Prediction finished!')\n",
    "    print('**********************************************************')\n",
    "    \n",
    "for name, scores in cv_scores.items():\n",
    "    print(f'Cross-validation scores for {name}: {scores}')\n",
    "    print(f'Average cost error for {name}: {np.mean(scores)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6499eb-ce79-4792-95e8-83d6046a6bd9",
   "metadata": {},
   "source": [
    "### 8th Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1aa281ed-c9f0-4d35-9f5d-470d48e1874d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial shape:  (6400, 117)\n",
      "Feature selection started!\n",
      "Last shape:  (6400, 62)\n",
      "Model Fitting and Prediction started!\n",
      "Model Fitting and Prediction finished!\n",
      "**********************************************************\n",
      "Initial shape:  (6400, 117)\n",
      "Feature selection started!\n",
      "Last shape:  (6400, 64)\n",
      "Model Fitting and Prediction started!\n",
      "Model Fitting and Prediction finished!\n",
      "**********************************************************\n",
      "Initial shape:  (6400, 117)\n",
      "Feature selection started!\n",
      "Last shape:  (6400, 61)\n",
      "Model Fitting and Prediction started!\n",
      "Model Fitting and Prediction finished!\n",
      "**********************************************************\n",
      "Initial shape:  (6400, 117)\n",
      "Feature selection started!\n",
      "Last shape:  (6400, 61)\n",
      "Model Fitting and Prediction started!\n",
      "Model Fitting and Prediction finished!\n",
      "**********************************************************\n",
      "Initial shape:  (6400, 117)\n",
      "Feature selection started!\n",
      "Last shape:  (6400, 58)\n",
      "Model Fitting and Prediction started!\n",
      "Model Fitting and Prediction finished!\n",
      "**********************************************************\n",
      "Cross-validation scores for random_forest: [0.92125, 0.866875, 0.874375, 0.89, 0.9125]\n",
      "Average cost error for random_forest: 0.893\n",
      "Cross-validation scores for xgboost: [0.94, 0.918125, 0.896875, 0.8925, 0.904375]\n",
      "Average cost error for xgboost: 0.9103749999999999\n",
      "Cross-validation scores for gradient_boosting: [0.89625, 0.849375, 0.91125, 0.888125, 0.905]\n",
      "Average cost error for gradient_boosting: 0.89\n"
     ]
    }
   ],
   "source": [
    "n_neighbors = 20\n",
    "contamination = 0.1\n",
    "cv_scores = dict()\n",
    "cv_scores['random_forest'] = []\n",
    "cv_scores['xgboost'] = []\n",
    "cv_scores['gradient_boosting'] = []\n",
    "\n",
    "y_train_mapped = y_train.copy()\n",
    "y_train_mapped[y_train == -1] = 0\n",
    "y_train_mapped[y_train == 0] = 1\n",
    "y_train_mapped[y_train == 1] = 2\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "for train_index, test_index in skf.split(X_train, y_train):\n",
    "    X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "    y_train_fold, y_test_fold = y_train_mapped.iloc[train_index], y_train_mapped.iloc[test_index]\n",
    "\n",
    "    print('Initial shape: ', pd.DataFrame(X_train_fold).shape)\n",
    "   \n",
    "    X_train_fold = preprocessor.fit_transform(X_train_fold)\n",
    "    X_test_fold = preprocessor.transform(X_test_fold)\n",
    "   \n",
    "    # lof = LocalOutlierFactor(n_neighbors=n_neighbors, contamination=contamination)\n",
    "    # outliers = lof.fit_predict(X_train_fold)\n",
    "    # mask = outliers != -1\n",
    "    # X_train_fold = X_train_fold[mask]\n",
    "    # y_train_fold = y_train_fold[mask]\n",
    "   \n",
    "    # sampler = RandomOverSampler(random_state=42)\n",
    "    # X_train_fold, y_train_fold = sampler.fit_resample(X_train_fold, y_train_fold)\n",
    "\n",
    "    print('Feature selection started!')\n",
    "    feature_selector = SelectFromModel(DecisionTreeClassifier(random_state=42))\n",
    "    feature_selector.fit(X_train_fold, y_train_fold)\n",
    "    X_train_fold = feature_selector.transform(X_train_fold)\n",
    "    X_test_fold = feature_selector.transform(X_test_fold)\n",
    "\n",
    "    print('Last shape: ', pd.DataFrame(X_train_fold).shape)\n",
    "\n",
    "    print('Model Fitting and Prediction started!')\n",
    "    for name, classifier in final_classifiers.items():\n",
    "        classifier.fit(X_train_fold, y_train_fold)\n",
    "        y_pred_fold = classifier.predict(X_test_fold)\n",
    "        score = custom_error_cost_score(y_test_fold, y_pred_fold)\n",
    "        cv_scores[name].append(score)\n",
    "    print('Model Fitting and Prediction finished!')\n",
    "    print('**********************************************************')\n",
    "    \n",
    "for name, scores in cv_scores.items():\n",
    "    print(f'Cross-validation scores for {name}: {scores}')\n",
    "    print(f'Average cost error for {name}: {np.mean(scores)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21587c91-92a0-4066-af0d-e1512a6a20ea",
   "metadata": {},
   "source": [
    "## 9th Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ca5aa57-4bf8-442d-8fe5-daf56b37baa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial shape:  (6400, 117)\n",
      "Feature selection started!\n",
      "Last shape:  (5760, 65)\n",
      "Model Fitting and Prediction started!\n",
      "Model Fitting and Prediction finished!\n",
      "**********************************************************\n",
      "Initial shape:  (6400, 117)\n",
      "Feature selection started!\n",
      "Last shape:  (5760, 67)\n",
      "Model Fitting and Prediction started!\n",
      "Model Fitting and Prediction finished!\n",
      "**********************************************************\n",
      "Initial shape:  (6400, 117)\n",
      "Feature selection started!\n",
      "Last shape:  (5760, 62)\n",
      "Model Fitting and Prediction started!\n",
      "Model Fitting and Prediction finished!\n",
      "**********************************************************\n",
      "Initial shape:  (6400, 117)\n",
      "Feature selection started!\n",
      "Last shape:  (5760, 63)\n",
      "Model Fitting and Prediction started!\n",
      "Model Fitting and Prediction finished!\n",
      "**********************************************************\n",
      "Initial shape:  (6400, 117)\n",
      "Feature selection started!\n",
      "Last shape:  (5760, 65)\n",
      "Model Fitting and Prediction started!\n",
      "Model Fitting and Prediction finished!\n",
      "**********************************************************\n",
      "Cross-validation scores for random_forest: [0.939375, 0.951875, 0.991875, 0.99625, 0.90125]\n",
      "Average cost error for random_forest: 0.9561249999999999\n",
      "Cross-validation scores for xgboost: [0.936875, 0.946875, 0.9825, 1.001875, 0.916875]\n",
      "Average cost error for xgboost: 0.9570000000000001\n",
      "Cross-validation scores for gradient_boosting: [0.916875, 0.92875, 0.921875, 0.915625, 0.89125]\n",
      "Average cost error for gradient_boosting: 0.914875\n"
     ]
    }
   ],
   "source": [
    "n_neighbors = 20\n",
    "contamination = 0.1\n",
    "cv_scores = dict()\n",
    "cv_scores['random_forest'] = []\n",
    "cv_scores['xgboost'] = []\n",
    "cv_scores['gradient_boosting'] = []\n",
    "\n",
    "y_train_mapped = y_train.copy()\n",
    "y_train_mapped[y_train == -1] = 0\n",
    "y_train_mapped[y_train == 0] = 1\n",
    "y_train_mapped[y_train == 1] = 2\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "for train_index, test_index in skf.split(X_train, y_train):\n",
    "    X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "    y_train_fold, y_test_fold = y_train_mapped.iloc[train_index], y_train_mapped.iloc[test_index]\n",
    "\n",
    "    print('Initial shape: ', pd.DataFrame(X_train_fold).shape)\n",
    "   \n",
    "    X_train_fold = preprocessor.fit_transform(X_train_fold)\n",
    "    X_test_fold = preprocessor.transform(X_test_fold)\n",
    "   \n",
    "    lof = LocalOutlierFactor(n_neighbors=n_neighbors, contamination=contamination)\n",
    "    outliers = lof.fit_predict(X_train_fold)\n",
    "    mask = outliers != -1\n",
    "    X_train_fold = X_train_fold[mask]\n",
    "    y_train_fold = y_train_fold[mask]\n",
    "   \n",
    "    # sampler = RandomOverSampler(random_state=42)\n",
    "    # X_train_fold, y_train_fold = sampler.fit_resample(X_train_fold, y_train_fold)\n",
    "\n",
    "    print('Feature selection started!')\n",
    "    feature_selector = SelectFromModel(DecisionTreeClassifier(random_state=42))\n",
    "    feature_selector.fit(X_train_fold, y_train_fold)\n",
    "    X_train_fold = feature_selector.transform(X_train_fold)\n",
    "    X_test_fold = feature_selector.transform(X_test_fold)\n",
    "\n",
    "    print('Last shape: ', pd.DataFrame(X_train_fold).shape)\n",
    "\n",
    "    print('Model Fitting and Prediction started!')\n",
    "    for name, classifier in final_classifiers.items():\n",
    "        classifier.fit(X_train_fold, y_train_fold)\n",
    "        y_pred_fold = classifier.predict(X_test_fold)\n",
    "        score = custom_error_cost_score(y_test_fold, y_pred_fold)\n",
    "        cv_scores[name].append(score)\n",
    "    print('Model Fitting and Prediction finished!')\n",
    "    print('**********************************************************')\n",
    "    \n",
    "for name, scores in cv_scores.items():\n",
    "    print(f'Cross-validation scores for {name}: {scores}')\n",
    "    print(f'Average cost error for {name}: {np.mean(scores)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0aaac21-50fe-47db-b5eb-da2d3f30d08f",
   "metadata": {},
   "source": [
    "## 10th Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3601ed5-c329-473c-a4fc-d9a2f93779cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial shape:  (6400, 117)\n",
      "Model Fitting and Prediction started!\n",
      "Model Fitting and Prediction finished!\n",
      "**********************************************************\n",
      "Initial shape:  (6400, 117)\n",
      "Model Fitting and Prediction started!\n",
      "Model Fitting and Prediction finished!\n",
      "**********************************************************\n",
      "Initial shape:  (6400, 117)\n",
      "Model Fitting and Prediction started!\n",
      "Model Fitting and Prediction finished!\n",
      "**********************************************************\n",
      "Initial shape:  (6400, 117)\n",
      "Model Fitting and Prediction started!\n",
      "Model Fitting and Prediction finished!\n",
      "**********************************************************\n",
      "Initial shape:  (6400, 117)\n",
      "Model Fitting and Prediction started!\n",
      "Model Fitting and Prediction finished!\n",
      "**********************************************************\n",
      "Cross-validation scores for random_forest: [0.935, 0.9625, 0.99375, 0.998125, 0.903125]\n",
      "Average cost error for random_forest: 0.9584999999999999\n",
      "Cross-validation scores for xgboost: [0.94125, 0.953125, 0.99125, 0.9975, 0.911875]\n",
      "Average cost error for xgboost: 0.959\n",
      "Cross-validation scores for gradient_boosting: [0.936875, 0.921875, 0.923125, 0.9225, 0.905]\n",
      "Average cost error for gradient_boosting: 0.921875\n"
     ]
    }
   ],
   "source": [
    "n_neighbors = 20\n",
    "contamination = 0.1\n",
    "cv_scores = dict()\n",
    "cv_scores['random_forest'] = []\n",
    "cv_scores['xgboost'] = []\n",
    "cv_scores['gradient_boosting'] = []\n",
    "\n",
    "y_train_mapped = y_train.copy()\n",
    "y_train_mapped[y_train == -1] = 0\n",
    "y_train_mapped[y_train == 0] = 1\n",
    "y_train_mapped[y_train == 1] = 2\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "for train_index, test_index in skf.split(X_train, y_train):\n",
    "    X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "    y_train_fold, y_test_fold = y_train_mapped.iloc[train_index], y_train_mapped.iloc[test_index]\n",
    "\n",
    "    print('Initial shape: ', pd.DataFrame(X_train_fold).shape)\n",
    "   \n",
    "    X_train_fold = preprocessor.fit_transform(X_train_fold)\n",
    "    X_test_fold = preprocessor.transform(X_test_fold)\n",
    "   \n",
    "    lof = LocalOutlierFactor(n_neighbors=n_neighbors, contamination=contamination)\n",
    "    outliers = lof.fit_predict(X_train_fold)\n",
    "    mask = outliers != -1\n",
    "    X_train_fold = X_train_fold_preprocessed[mask]\n",
    "    y_train_fold = y_train_fold[mask]\n",
    "   \n",
    "    sampler = RandomOverSampler(random_state=42)\n",
    "    X_train_fold, y_train_fold = sampler.fit_resample(X_train_fold, y_train_fold)\n",
    "\n",
    "    # print('Feature selection started!')\n",
    "    # feature_selector = SelectFromModel(DecisionTreeClassifier(random_state=42))\n",
    "    # feature_selector.fit(X_train_fold, y_train_fold)\n",
    "    # X_train_fold = feature_selector.transform(X_train_fold)\n",
    "    # X_test_fold = feature_selector.transform(X_test_fold)\n",
    "\n",
    "    # print('Last shape: ', pd.DataFrame(X_train_fold).shape)\n",
    "\n",
    "    print('Model Fitting and Prediction started!')\n",
    "    for name, classifier in final_classifiers.items():\n",
    "        classifier.fit(X_train_fold, y_train_fold)\n",
    "        y_pred_fold = classifier.predict(X_test_fold)\n",
    "        score = custom_error_cost_score(y_test_fold, y_pred_fold)\n",
    "        cv_scores[name].append(score)\n",
    "    print('Model Fitting and Prediction finished!')\n",
    "    print('**********************************************************')\n",
    "    \n",
    "for name, scores in cv_scores.items():\n",
    "    print(f'Cross-validation scores for {name}: {scores}')\n",
    "    print(f'Average cost error for {name}: {np.mean(scores)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d57c62d-bfef-42c1-8201-5768a8b80b44",
   "metadata": {},
   "source": [
    "## 11th Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7c1c552-4d9e-4ffd-b674-3d0f67d2c203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial shape:  (6400, 117)\n",
      "Feature selection started!\n",
      "Model Fitting and Prediction started!\n",
      "Model Fitting and Prediction finished!\n",
      "**********************************************************\n",
      "Initial shape:  (6400, 117)\n",
      "Feature selection started!\n",
      "Model Fitting and Prediction started!\n",
      "Model Fitting and Prediction finished!\n",
      "**********************************************************\n",
      "Initial shape:  (6400, 117)\n",
      "Feature selection started!\n",
      "Model Fitting and Prediction started!\n",
      "Model Fitting and Prediction finished!\n",
      "**********************************************************\n",
      "Initial shape:  (6400, 117)\n",
      "Feature selection started!\n",
      "Model Fitting and Prediction started!\n",
      "Model Fitting and Prediction finished!\n",
      "**********************************************************\n",
      "Initial shape:  (6400, 117)\n",
      "Feature selection started!\n",
      "Model Fitting and Prediction started!\n",
      "Model Fitting and Prediction finished!\n",
      "**********************************************************\n",
      "Cross-validation scores for random_forest: [0.91125, 0.8975, 0.935, 0.884375, 0.9075]\n",
      "Average cost error for random_forest: 0.907125\n",
      "Cross-validation scores for xgboost: [0.959375, 0.885625, 0.91875, 0.9175, 0.895625]\n",
      "Average cost error for xgboost: 0.915375\n",
      "Cross-validation scores for gradient_boosting: [0.91125, 0.86, 0.850625, 0.875, 0.86125]\n",
      "Average cost error for gradient_boosting: 0.8716250000000001\n"
     ]
    }
   ],
   "source": [
    "n_neighbors = 20\n",
    "contamination = 0.1\n",
    "cv_scores = dict()\n",
    "cv_scores['random_forest'] = []\n",
    "cv_scores['xgboost'] = []\n",
    "cv_scores['gradient_boosting'] = []\n",
    "\n",
    "y_train_mapped = y_train.copy()\n",
    "y_train_mapped[y_train == -1] = 0\n",
    "y_train_mapped[y_train == 0] = 1\n",
    "y_train_mapped[y_train == 1] = 2\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "for train_index, test_index in skf.split(X_train, y_train):\n",
    "    X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "    y_train_fold, y_test_fold = y_train_mapped.iloc[train_index], y_train_mapped.iloc[test_index]\n",
    "\n",
    "    print('Initial shape: ', pd.DataFrame(X_train_fold).shape)\n",
    "   \n",
    "    X_train_fold = preprocessor.fit_transform(X_train_fold)\n",
    "    X_test_fold = preprocessor.transform(X_test_fold)\n",
    "   \n",
    "    # lof = LocalOutlierFactor(n_neighbors=n_neighbors, contamination=contamination)\n",
    "    # outliers = lof.fit_predict(X_train_fold)\n",
    "    # mask = outliers != -1\n",
    "    # X_train_fold = X_train_fold_preprocessed[mask]\n",
    "    # y_train_fold = y_train_fold[mask]\n",
    "   \n",
    "    sampler = RandomOverSampler(random_state=42)\n",
    "    X_train_fold, y_train_fold = sampler.fit_resample(X_train_fold, y_train_fold)\n",
    "\n",
    "    print('Feature selection started!')\n",
    "    feature_selector = SelectFromModel(DecisionTreeClassifier(random_state=42))\n",
    "    feature_selector.fit(X_train_fold, y_train_fold)\n",
    "    X_train_fold = feature_selector.transform(X_train_fold)\n",
    "    X_test_fold = feature_selector.transform(X_test_fold)\n",
    "\n",
    "    print('Last shape: ', pd.DataFrame(X_train_fold).shape)\n",
    "\n",
    "    print('Model Fitting and Prediction started!')\n",
    "    for name, classifier in final_classifiers.items():\n",
    "        classifier.fit(X_train_fold, y_train_fold)\n",
    "        y_pred_fold = classifier.predict(X_test_fold)\n",
    "        score = custom_error_cost_score(y_test_fold, y_pred_fold)\n",
    "        cv_scores[name].append(score)\n",
    "    print('Model Fitting and Prediction finished!')\n",
    "    print('**********************************************************')\n",
    "    \n",
    "for name, scores in cv_scores.items():\n",
    "    print(f'Cross-validation scores for {name}: {scores}')\n",
    "    print(f'Average cost error for {name}: {np.mean(scores)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca525e2d-fbf3-488d-ac03-215f1fad945d",
   "metadata": {},
   "source": [
    "# Remove the Group Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8011d390-e5aa-4046-9b7c-032335413f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cagan Deliktas\\AppData\\Local\\Temp\\ipykernel_12796\\3947199440.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train.loc[:, numeric_columns] = X_train.loc[:, numeric_columns].replace(\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(\"C:/Users/Cagan Deliktas/Desktop/ProjectDataMining2/DM2_DataCraft/data/training_data.xls\")\n",
    "X_test = pd.read_excel(\"C:/Users/Cagan Deliktas/Desktop/ProjectDataMining2/DM2_DataCraft/data/test_data_no_target.xls\")\n",
    "\n",
    "X_train = df.loc[:, ~df.columns.isin(['Group', 'Class', 'Perform'])]\n",
    "y_train = df['Class']\n",
    "\n",
    "numeric_columns = X_train.loc[:, ~X_train.columns.isin(['Group'])].columns.to_list()\n",
    "X_train.loc[:, numeric_columns] = X_train.loc[:, numeric_columns].replace(\n",
    "    {\n",
    "        'NA': np.nan, \n",
    "        '': np.nan,\n",
    "        ' ': np.nan\n",
    "    }\n",
    ").astype(float)\n",
    "\n",
    "numeric_columns = X_test.loc[:, ~X_test.columns.isin(['Group'])].columns.to_list()\n",
    "X_test[numeric_columns] = X_test.loc[:, numeric_columns].replace(\n",
    "    {\n",
    "        'NA': np.nan, \n",
    "        '': np.nan,\n",
    "        ' ': np.nan\n",
    "    }\n",
    ").astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ec325e5-fe0d-4336-a121-094f7c43a277",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = Pipeline([\n",
    "    ('imputer', KNNImputer(n_neighbors=10)), \n",
    "    ('scaler', RobustScaler()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "26749f12-a70e-40ed-858f-bca8e28e7827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial shape:  (6400, 116)\n",
      "Last shape:  (8133, 116)\n",
      "Model Fitting and Prediction started!\n",
      "Model Fitting and Prediction finished!\n",
      "**********************************************************\n",
      "Initial shape:  (6400, 116)\n",
      "Last shape:  (8127, 116)\n",
      "Model Fitting and Prediction started!\n",
      "Model Fitting and Prediction finished!\n",
      "**********************************************************\n",
      "Initial shape:  (6400, 116)\n",
      "Last shape:  (8115, 116)\n",
      "Model Fitting and Prediction started!\n",
      "Model Fitting and Prediction finished!\n",
      "**********************************************************\n",
      "Initial shape:  (6400, 116)\n",
      "Last shape:  (8166, 116)\n",
      "Model Fitting and Prediction started!\n",
      "Model Fitting and Prediction finished!\n",
      "**********************************************************\n",
      "Initial shape:  (6400, 116)\n",
      "Last shape:  (8142, 116)\n",
      "Model Fitting and Prediction started!\n",
      "Model Fitting and Prediction finished!\n",
      "**********************************************************\n",
      "Cross-validation scores for random_forest: [0.92875, 0.906875, 0.918125, 0.8875, 0.93125]\n",
      "Average cost error for random_forest: 0.9145\n",
      "Cross-validation scores for xgboost: [0.935, 0.881875, 0.915625, 0.90875, 0.89375]\n",
      "Average cost error for xgboost: 0.907\n",
      "Cross-validation scores for gradient_boosting: [0.888125, 0.874375, 0.893125, 0.8875, 0.85375]\n",
      "Average cost error for gradient_boosting: 0.8793749999999999\n"
     ]
    }
   ],
   "source": [
    "cv_scores = dict()\n",
    "cv_scores['random_forest'] = []\n",
    "cv_scores['xgboost'] = []\n",
    "cv_scores['gradient_boosting'] = []\n",
    "\n",
    "y_train_mapped = y_train.copy()\n",
    "y_train_mapped[y_train == -1] = 0\n",
    "y_train_mapped[y_train == 0] = 1\n",
    "y_train_mapped[y_train == 1] = 2\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "for train_index, test_index in skf.split(X_train, y_train):\n",
    "    X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "    y_train_fold, y_test_fold = y_train_mapped.iloc[train_index], y_train_mapped.iloc[test_index]\n",
    "\n",
    "    print('Initial shape: ', pd.DataFrame(X_train_fold).shape)\n",
    "   \n",
    "    X_train_fold = preprocessor.fit_transform(X_train_fold)\n",
    "    X_test_fold = preprocessor.transform(X_test_fold)\n",
    "   \n",
    "    lof = LocalOutlierFactor(n_neighbors=20, contamination=0.1)\n",
    "    outliers = lof.fit_predict(X_train_fold)\n",
    "    mask = outliers != -1\n",
    "    X_train_fold = X_train_fold[mask]\n",
    "    y_train_fold = y_train_fold[mask]\n",
    "   \n",
    "    sampler = SMOTE(random_state=42)\n",
    "    X_train_fold, y_train_fold = sampler.fit_resample(X_train_fold, y_train_fold)\n",
    "\n",
    "    print('Last shape: ', pd.DataFrame(X_train_fold).shape)\n",
    "\n",
    "    print('Model Fitting and Prediction started!')\n",
    "    for name, classifier in final_classifiers.items():\n",
    "        classifier.fit(X_train_fold, y_train_fold)\n",
    "        y_pred_fold = classifier.predict(X_test_fold)\n",
    "        score = custom_error_cost_score(y_test_fold, y_pred_fold)\n",
    "        cv_scores[name].append(score)\n",
    "    print('Model Fitting and Prediction finished!')\n",
    "    print('**********************************************************')\n",
    "    \n",
    "for name, scores in cv_scores.items():\n",
    "    print(f'Cross-validation scores for {name}: {scores}')\n",
    "    print(f'Average cost error for {name}: {np.mean(scores)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b0a6f7-1673-491f-8d5c-ddc0c4cc3979",
   "metadata": {},
   "source": [
    "### HyperParameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "199958f9-7e77-491b-8d59-d35395cb11f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Best parameters: {'classifier__learning_rate': 0.016175348288740735, 'classifier__max_depth': 4, 'classifier__max_features': 'log2', 'classifier__min_samples_leaf': 6, 'classifier__min_samples_split': 3, 'classifier__n_estimators': 291, 'classifier__subsample': 0.9929904033620958}\n",
      "Best cross-validation score: -0.888876043532818\n"
     ]
    }
   ],
   "source": [
    "y_train_mapped = y_train.copy()\n",
    "y_train_mapped[y_train == -1] = 0\n",
    "y_train_mapped[y_train == 0] = 1\n",
    "y_train_mapped[y_train == 1] = 2\n",
    "\n",
    "gb_pipeline = imblearn_Pipeline([\n",
    "    ('imputer', KNNImputer(n_neighbors=10)),\n",
    "    ('scaler', RobustScaler()),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('classifier', GradientBoostingClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "param_dist = {\n",
    "    'classifier__n_estimators': randint(100, 350),\n",
    "    'classifier__max_depth': randint(3, 10),\n",
    "    'classifier__learning_rate': uniform(0.01, 0.3),\n",
    "    'classifier__subsample': uniform(0.1, 0.9),\n",
    "    'classifier__min_samples_split': randint(2, 20),\n",
    "    'classifier__min_samples_leaf': randint(1, 20),\n",
    "    'classifier__max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    gb_pipeline,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10,\n",
    "    cv=StratifiedKFold(3),\n",
    "    scoring=matrix_error_function,\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    error_score='raise'\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train_mapped)\n",
    "\n",
    "print(f'Best parameters: {random_search.best_params_}')\n",
    "print(f'Best cross-validation score: {random_search.best_score_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39d33f02-0787-48cf-93ab-7eb1a70238b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_mapped = y_train.copy()\n",
    "y_train_mapped[y_train == -1] = 0\n",
    "y_train_mapped[y_train == 0] = 1\n",
    "y_train_mapped[y_train == 1] = 2\n",
    "\n",
    "best_parameters = {'learning_rate': 0.016175348288740735, \n",
    "                   'max_depth': 4, \n",
    "                   'max_features': 'log2', \n",
    "                   'min_samples_leaf': 6, \n",
    "                   'min_samples_split': 3, \n",
    "                   'n_estimators': 291, \n",
    "                   'subsample': 0.9929904033620958,\n",
    "                  'random_state': 42}\n",
    "\n",
    "gb_pipeline_last = imblearn_Pipeline([\n",
    "    ('imputer', KNNImputer(n_neighbors=10)),\n",
    "    ('scaler', RobustScaler()),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('feature_selector', SelectFromModel(DecisionTreeClassifier(random_state=42))),\n",
    "    ('classifier', GradientBoostingClassifier(**best_parameters))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7489d07-67bd-4d50-9613-6d8d8f9e14df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;imputer&#x27;, KNNImputer(n_neighbors=10)),\n",
       "                (&#x27;scaler&#x27;, RobustScaler()), (&#x27;smote&#x27;, SMOTE(random_state=42)),\n",
       "                (&#x27;feature_selector&#x27;,\n",
       "                 SelectFromModel(estimator=DecisionTreeClassifier(random_state=42))),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 GradientBoostingClassifier(learning_rate=0.016175348288740735,\n",
       "                                            max_depth=4, max_features=&#x27;log2&#x27;,\n",
       "                                            min_samples_leaf=6,\n",
       "                                            min_samples_split=3,\n",
       "                                            n_estimators=291, random_state=42,\n",
       "                                            subsample=0.9929904033620958))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;Pipeline<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;imputer&#x27;, KNNImputer(n_neighbors=10)),\n",
       "                (&#x27;scaler&#x27;, RobustScaler()), (&#x27;smote&#x27;, SMOTE(random_state=42)),\n",
       "                (&#x27;feature_selector&#x27;,\n",
       "                 SelectFromModel(estimator=DecisionTreeClassifier(random_state=42))),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 GradientBoostingClassifier(learning_rate=0.016175348288740735,\n",
       "                                            max_depth=4, max_features=&#x27;log2&#x27;,\n",
       "                                            min_samples_leaf=6,\n",
       "                                            min_samples_split=3,\n",
       "                                            n_estimators=291, random_state=42,\n",
       "                                            subsample=0.9929904033620958))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;KNNImputer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.impute.KNNImputer.html\">?<span>Documentation for KNNImputer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>KNNImputer(n_neighbors=10)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;RobustScaler<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.RobustScaler.html\">?<span>Documentation for RobustScaler</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>RobustScaler()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">SMOTE</label><div class=\"sk-toggleable__content fitted\"><pre>SMOTE(random_state=42)</pre></div> </div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;feature_selector: SelectFromModel<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.feature_selection.SelectFromModel.html\">?<span>Documentation for feature_selector: SelectFromModel</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>SelectFromModel(estimator=DecisionTreeClassifier(random_state=42))</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeClassifier(random_state=42)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;DecisionTreeClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeClassifier(random_state=42)</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;GradientBoostingClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\">?<span>Documentation for GradientBoostingClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>GradientBoostingClassifier(learning_rate=0.016175348288740735, max_depth=4,\n",
       "                           max_features=&#x27;log2&#x27;, min_samples_leaf=6,\n",
       "                           min_samples_split=3, n_estimators=291,\n",
       "                           random_state=42, subsample=0.9929904033620958)</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('imputer', KNNImputer(n_neighbors=10)),\n",
       "                ('scaler', RobustScaler()), ('smote', SMOTE(random_state=42)),\n",
       "                ('feature_selector',\n",
       "                 SelectFromModel(estimator=DecisionTreeClassifier(random_state=42))),\n",
       "                ('classifier',\n",
       "                 GradientBoostingClassifier(learning_rate=0.016175348288740735,\n",
       "                                            max_depth=4, max_features='log2',\n",
       "                                            min_samples_leaf=6,\n",
       "                                            min_samples_split=3,\n",
       "                                            n_estimators=291, random_state=42,\n",
       "                                            subsample=0.9929904033620958))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_pipeline_last.fit(X_train, y_train_mapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "989cc8a2-f859-4254-9ceb-f797045359cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.drop('Group', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad18fb68-1edd-4d6c-8c5a-69e7cb6328ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = gb_pipeline_last.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de7be252-bbe6-4f5c-88f3-6c4dbffe9808",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[preds == 0] = -1\n",
    "preds[preds == 1] = 0\n",
    "preds[preds == 2] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23bdbca7-a36f-4b02-bb4e-b36010457d54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1, -1, ...,  0, -1, -1], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c715c32-ea00-4c52-a4bf-5a932db2021a",
   "metadata": {},
   "source": [
    "## Predictions Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb0cd234-6ddb-43d1-bb41-b880804dbdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"comb11.txt\"\n",
    "pd.DataFrame(preds).to_csv(file_path, index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
