{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18872d5e-2ee7-4f1c-8374-c436aa9ea3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier, AdaBoostClassifier, StackingClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, train_test_split, cross_val_predict, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, make_scorer, roc_auc_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder, RobustScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "import random\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "from Functions_Classes import *\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "\n",
    "from feature_engine.encoding import CountFrequencyEncoder\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "403b851f-60a3-4d92-838e-9d6f00c5cc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"C:/Users/Cagan Deliktas/Desktop/ProjectDataMining2/DM2_DataCraft/data/training_data.xls\")\n",
    "X_test_compete = pd.read_excel(\"C:/Users/Cagan Deliktas/Desktop/ProjectDataMining2/DM2_DataCraft/data/test_data_no_target.xls\")\n",
    "\n",
    "df = df.loc[:, df.columns != 'Perform']\n",
    "#df = df.loc[:, df.columns != 'Group']\n",
    "\n",
    "\n",
    "df_x = df.loc[:, df.columns != 'Class']\n",
    "df_y = df['Class']\n",
    "\n",
    "X_train = df_x.copy()\n",
    "y_train =  df_y.copy()\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(df_x, df_y, test_size=0.2,shuffle=True, stratify=df_y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8625a7-a114-471e-b05b-8d132c780626",
   "metadata": {},
   "source": [
    "### Remove one year differences from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fbc4169-a4cc-46f1-9ea3-49e38c194715",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.loc[:, ~X_train.columns.str.contains('d')]\n",
    "X_test_compete = X_test_compete.loc[:, ~X_test_compete.columns.str.contains('d')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "006456f7-eecd-4486-abb2-db0ff3ef51a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = X_train.loc[:, ~X_train.columns.isin(['Group'])].columns.to_list()\n",
    "X_train[numeric_columns] = X_train.loc[:, numeric_columns].replace(\n",
    "    {\n",
    "        'NA': np.nan, \n",
    "        '': np.nan,\n",
    "        ' ': np.nan\n",
    "    }\n",
    ").astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88066b03-5993-437f-9af7-d0f10d3bf8ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group</th>\n",
       "      <th>I1</th>\n",
       "      <th>I2</th>\n",
       "      <th>I3</th>\n",
       "      <th>I4</th>\n",
       "      <th>I5</th>\n",
       "      <th>I6</th>\n",
       "      <th>I7</th>\n",
       "      <th>I8</th>\n",
       "      <th>I9</th>\n",
       "      <th>I10</th>\n",
       "      <th>I11</th>\n",
       "      <th>I12</th>\n",
       "      <th>I13</th>\n",
       "      <th>I14</th>\n",
       "      <th>I15</th>\n",
       "      <th>I16</th>\n",
       "      <th>I17</th>\n",
       "      <th>I18</th>\n",
       "      <th>I19</th>\n",
       "      <th>I20</th>\n",
       "      <th>I21</th>\n",
       "      <th>I22</th>\n",
       "      <th>I23</th>\n",
       "      <th>I24</th>\n",
       "      <th>I25</th>\n",
       "      <th>I26</th>\n",
       "      <th>I27</th>\n",
       "      <th>I28</th>\n",
       "      <th>I29</th>\n",
       "      <th>I30</th>\n",
       "      <th>I31</th>\n",
       "      <th>I32</th>\n",
       "      <th>I33</th>\n",
       "      <th>I34</th>\n",
       "      <th>I35</th>\n",
       "      <th>I36</th>\n",
       "      <th>I37</th>\n",
       "      <th>I38</th>\n",
       "      <th>I39</th>\n",
       "      <th>I40</th>\n",
       "      <th>I41</th>\n",
       "      <th>I42</th>\n",
       "      <th>I43</th>\n",
       "      <th>I44</th>\n",
       "      <th>I45</th>\n",
       "      <th>I46</th>\n",
       "      <th>I47</th>\n",
       "      <th>I48</th>\n",
       "      <th>I49</th>\n",
       "      <th>I50</th>\n",
       "      <th>I51</th>\n",
       "      <th>I52</th>\n",
       "      <th>I53</th>\n",
       "      <th>I54</th>\n",
       "      <th>I55</th>\n",
       "      <th>I56</th>\n",
       "      <th>I57</th>\n",
       "      <th>I58</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G9</td>\n",
       "      <td>0.136495</td>\n",
       "      <td>-0.028429</td>\n",
       "      <td>-0.037772</td>\n",
       "      <td>-0.232459</td>\n",
       "      <td>-0.016222</td>\n",
       "      <td>-0.187506</td>\n",
       "      <td>-0.322545</td>\n",
       "      <td>-0.043743</td>\n",
       "      <td>0.125389</td>\n",
       "      <td>-0.014757</td>\n",
       "      <td>-0.033105</td>\n",
       "      <td>0.303035</td>\n",
       "      <td>-0.093811</td>\n",
       "      <td>-0.598917</td>\n",
       "      <td>-0.271292</td>\n",
       "      <td>-0.256749</td>\n",
       "      <td>-0.100146</td>\n",
       "      <td>-0.045525</td>\n",
       "      <td>-0.078422</td>\n",
       "      <td>-0.060129</td>\n",
       "      <td>-0.069528</td>\n",
       "      <td>-0.052432</td>\n",
       "      <td>-0.114432</td>\n",
       "      <td>-0.104989</td>\n",
       "      <td>0.342845</td>\n",
       "      <td>-0.159417</td>\n",
       "      <td>0.006772</td>\n",
       "      <td>-0.303193</td>\n",
       "      <td>-0.163287</td>\n",
       "      <td>-0.080599</td>\n",
       "      <td>-0.828880</td>\n",
       "      <td>-1.064215</td>\n",
       "      <td>-0.547067</td>\n",
       "      <td>-0.540497</td>\n",
       "      <td>-0.676045</td>\n",
       "      <td>-0.305007</td>\n",
       "      <td>-0.507724</td>\n",
       "      <td>-0.191437</td>\n",
       "      <td>-0.087362</td>\n",
       "      <td>-0.856151</td>\n",
       "      <td>0.802525</td>\n",
       "      <td>0.733080</td>\n",
       "      <td>0.006512</td>\n",
       "      <td>0.533290</td>\n",
       "      <td>0.195197</td>\n",
       "      <td>0.058094</td>\n",
       "      <td>-0.228889</td>\n",
       "      <td>-0.150821</td>\n",
       "      <td>-0.104986</td>\n",
       "      <td>-0.026743</td>\n",
       "      <td>0.188312</td>\n",
       "      <td>-0.250701</td>\n",
       "      <td>-0.101190</td>\n",
       "      <td>-0.357521</td>\n",
       "      <td>-0.527956</td>\n",
       "      <td>0.611385</td>\n",
       "      <td>-0.092714</td>\n",
       "      <td>-0.055733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G5</td>\n",
       "      <td>-0.714522</td>\n",
       "      <td>-0.042137</td>\n",
       "      <td>-0.052968</td>\n",
       "      <td>-0.796862</td>\n",
       "      <td>-0.018394</td>\n",
       "      <td>0.070102</td>\n",
       "      <td>-0.076321</td>\n",
       "      <td>-0.063864</td>\n",
       "      <td>-1.045521</td>\n",
       "      <td>-0.037353</td>\n",
       "      <td>-0.792515</td>\n",
       "      <td>-1.082483</td>\n",
       "      <td>0.025798</td>\n",
       "      <td>-0.833652</td>\n",
       "      <td>-0.625088</td>\n",
       "      <td>-0.333608</td>\n",
       "      <td>0.072579</td>\n",
       "      <td>-0.046963</td>\n",
       "      <td>0.223022</td>\n",
       "      <td>-0.605902</td>\n",
       "      <td>-0.131099</td>\n",
       "      <td>-0.235929</td>\n",
       "      <td>-0.073920</td>\n",
       "      <td>-0.063247</td>\n",
       "      <td>-0.798768</td>\n",
       "      <td>-0.899983</td>\n",
       "      <td>1.388771</td>\n",
       "      <td>-0.248677</td>\n",
       "      <td>-0.058083</td>\n",
       "      <td>-0.014470</td>\n",
       "      <td>0.092095</td>\n",
       "      <td>0.561368</td>\n",
       "      <td>0.224819</td>\n",
       "      <td>0.223190</td>\n",
       "      <td>0.098852</td>\n",
       "      <td>-0.128227</td>\n",
       "      <td>-0.215876</td>\n",
       "      <td>-0.007164</td>\n",
       "      <td>-0.035260</td>\n",
       "      <td>-0.123911</td>\n",
       "      <td>-0.089751</td>\n",
       "      <td>-0.094963</td>\n",
       "      <td>0.362818</td>\n",
       "      <td>0.011107</td>\n",
       "      <td>-1.506356</td>\n",
       "      <td>-0.573679</td>\n",
       "      <td>-0.955222</td>\n",
       "      <td>-0.818880</td>\n",
       "      <td>-1.063295</td>\n",
       "      <td>-1.022679</td>\n",
       "      <td>-1.336188</td>\n",
       "      <td>-0.612039</td>\n",
       "      <td>-0.061357</td>\n",
       "      <td>-0.482805</td>\n",
       "      <td>-0.017077</td>\n",
       "      <td>1.192135</td>\n",
       "      <td>-0.114981</td>\n",
       "      <td>-0.028074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G10</td>\n",
       "      <td>0.104791</td>\n",
       "      <td>-0.038188</td>\n",
       "      <td>-0.053191</td>\n",
       "      <td>0.620233</td>\n",
       "      <td>0.148587</td>\n",
       "      <td>0.489875</td>\n",
       "      <td>0.319274</td>\n",
       "      <td>-0.060246</td>\n",
       "      <td>0.053174</td>\n",
       "      <td>-0.025008</td>\n",
       "      <td>-0.456840</td>\n",
       "      <td>1.284450</td>\n",
       "      <td>-0.133470</td>\n",
       "      <td>3.207672</td>\n",
       "      <td>2.373230</td>\n",
       "      <td>1.304427</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.361293</td>\n",
       "      <td>2.995661</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.188988</td>\n",
       "      <td>-0.044158</td>\n",
       "      <td>-0.024550</td>\n",
       "      <td>-0.586562</td>\n",
       "      <td>-0.176292</td>\n",
       "      <td>-1.013037</td>\n",
       "      <td>0.066912</td>\n",
       "      <td>0.219649</td>\n",
       "      <td>0.154490</td>\n",
       "      <td>2.370951</td>\n",
       "      <td>1.384675</td>\n",
       "      <td>0.489152</td>\n",
       "      <td>0.484715</td>\n",
       "      <td>0.367301</td>\n",
       "      <td>0.749572</td>\n",
       "      <td>0.669410</td>\n",
       "      <td>0.423228</td>\n",
       "      <td>0.226897</td>\n",
       "      <td>3.227283</td>\n",
       "      <td>-0.329997</td>\n",
       "      <td>-0.327579</td>\n",
       "      <td>-1.033898</td>\n",
       "      <td>0.014531</td>\n",
       "      <td>0.211889</td>\n",
       "      <td>-1.197156</td>\n",
       "      <td>2.860444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.584223</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.272375</td>\n",
       "      <td>7.427558</td>\n",
       "      <td>-0.182816</td>\n",
       "      <td>-2.713205</td>\n",
       "      <td>-1.877595</td>\n",
       "      <td>-0.568691</td>\n",
       "      <td>0.224945</td>\n",
       "      <td>0.052749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G2</td>\n",
       "      <td>-0.532847</td>\n",
       "      <td>-0.006582</td>\n",
       "      <td>-0.023377</td>\n",
       "      <td>1.306702</td>\n",
       "      <td>-0.068909</td>\n",
       "      <td>0.048024</td>\n",
       "      <td>-0.119481</td>\n",
       "      <td>-0.021057</td>\n",
       "      <td>-1.012916</td>\n",
       "      <td>-0.011783</td>\n",
       "      <td>1.206727</td>\n",
       "      <td>0.311773</td>\n",
       "      <td>-0.005928</td>\n",
       "      <td>3.869459</td>\n",
       "      <td>-1.064793</td>\n",
       "      <td>0.107702</td>\n",
       "      <td>-0.126984</td>\n",
       "      <td>-0.044360</td>\n",
       "      <td>-0.181023</td>\n",
       "      <td>-0.691971</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.195138</td>\n",
       "      <td>-0.104877</td>\n",
       "      <td>-0.093976</td>\n",
       "      <td>-0.757725</td>\n",
       "      <td>0.004432</td>\n",
       "      <td>-1.471299</td>\n",
       "      <td>0.643575</td>\n",
       "      <td>-0.067005</td>\n",
       "      <td>-0.006874</td>\n",
       "      <td>-0.087499</td>\n",
       "      <td>0.110638</td>\n",
       "      <td>0.046880</td>\n",
       "      <td>0.047141</td>\n",
       "      <td>-0.274713</td>\n",
       "      <td>0.169046</td>\n",
       "      <td>-0.179742</td>\n",
       "      <td>0.047391</td>\n",
       "      <td>0.015197</td>\n",
       "      <td>0.105158</td>\n",
       "      <td>-0.045135</td>\n",
       "      <td>-0.051329</td>\n",
       "      <td>0.202098</td>\n",
       "      <td>0.034693</td>\n",
       "      <td>2.904519</td>\n",
       "      <td>4.514844</td>\n",
       "      <td>-0.241111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.521576</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.308812</td>\n",
       "      <td>-0.542532</td>\n",
       "      <td>-0.165028</td>\n",
       "      <td>1.490354</td>\n",
       "      <td>-1.550745</td>\n",
       "      <td>-0.918676</td>\n",
       "      <td>0.013484</td>\n",
       "      <td>-0.013198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G3</td>\n",
       "      <td>-0.200815</td>\n",
       "      <td>-0.016334</td>\n",
       "      <td>-0.036754</td>\n",
       "      <td>-0.886675</td>\n",
       "      <td>0.484495</td>\n",
       "      <td>-1.148744</td>\n",
       "      <td>0.152517</td>\n",
       "      <td>-0.043580</td>\n",
       "      <td>-0.935537</td>\n",
       "      <td>-0.023262</td>\n",
       "      <td>-0.908986</td>\n",
       "      <td>-0.525121</td>\n",
       "      <td>0.015492</td>\n",
       "      <td>-0.347325</td>\n",
       "      <td>0.296360</td>\n",
       "      <td>-0.242201</td>\n",
       "      <td>0.120049</td>\n",
       "      <td>-0.048293</td>\n",
       "      <td>0.290658</td>\n",
       "      <td>-0.345816</td>\n",
       "      <td>0.249586</td>\n",
       "      <td>-0.241812</td>\n",
       "      <td>-0.082055</td>\n",
       "      <td>-0.077706</td>\n",
       "      <td>-0.845163</td>\n",
       "      <td>-0.257777</td>\n",
       "      <td>0.919065</td>\n",
       "      <td>-0.522102</td>\n",
       "      <td>0.146076</td>\n",
       "      <td>0.043851</td>\n",
       "      <td>1.281726</td>\n",
       "      <td>0.039106</td>\n",
       "      <td>0.135331</td>\n",
       "      <td>0.134652</td>\n",
       "      <td>0.654099</td>\n",
       "      <td>1.437536</td>\n",
       "      <td>1.995784</td>\n",
       "      <td>-0.145004</td>\n",
       "      <td>-0.029483</td>\n",
       "      <td>0.252151</td>\n",
       "      <td>0.308723</td>\n",
       "      <td>0.293393</td>\n",
       "      <td>-0.527888</td>\n",
       "      <td>-0.003680</td>\n",
       "      <td>-1.553644</td>\n",
       "      <td>-1.233945</td>\n",
       "      <td>-0.947111</td>\n",
       "      <td>-0.926073</td>\n",
       "      <td>-0.772468</td>\n",
       "      <td>-0.636440</td>\n",
       "      <td>-0.833875</td>\n",
       "      <td>-0.527935</td>\n",
       "      <td>-0.014170</td>\n",
       "      <td>-0.142943</td>\n",
       "      <td>1.070523</td>\n",
       "      <td>-0.284682</td>\n",
       "      <td>-0.155110</td>\n",
       "      <td>-0.026941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Group        I1        I2        I3        I4        I5        I6        I7  \\\n",
       "0    G9  0.136495 -0.028429 -0.037772 -0.232459 -0.016222 -0.187506 -0.322545   \n",
       "1    G5 -0.714522 -0.042137 -0.052968 -0.796862 -0.018394  0.070102 -0.076321   \n",
       "2   G10  0.104791 -0.038188 -0.053191  0.620233  0.148587  0.489875  0.319274   \n",
       "3    G2 -0.532847 -0.006582 -0.023377  1.306702 -0.068909  0.048024 -0.119481   \n",
       "4    G3 -0.200815 -0.016334 -0.036754 -0.886675  0.484495 -1.148744  0.152517   \n",
       "\n",
       "         I8        I9       I10       I11       I12       I13       I14  \\\n",
       "0 -0.043743  0.125389 -0.014757 -0.033105  0.303035 -0.093811 -0.598917   \n",
       "1 -0.063864 -1.045521 -0.037353 -0.792515 -1.082483  0.025798 -0.833652   \n",
       "2 -0.060246  0.053174 -0.025008 -0.456840  1.284450 -0.133470  3.207672   \n",
       "3 -0.021057 -1.012916 -0.011783  1.206727  0.311773 -0.005928  3.869459   \n",
       "4 -0.043580 -0.935537 -0.023262 -0.908986 -0.525121  0.015492 -0.347325   \n",
       "\n",
       "        I15       I16       I17       I18       I19       I20       I21  \\\n",
       "0 -0.271292 -0.256749 -0.100146 -0.045525 -0.078422 -0.060129 -0.069528   \n",
       "1 -0.625088 -0.333608  0.072579 -0.046963  0.223022 -0.605902 -0.131099   \n",
       "2  2.373230  1.304427       NaN       NaN -0.361293  2.995661       NaN   \n",
       "3 -1.064793  0.107702 -0.126984 -0.044360 -0.181023 -0.691971       NaN   \n",
       "4  0.296360 -0.242201  0.120049 -0.048293  0.290658 -0.345816  0.249586   \n",
       "\n",
       "        I22       I23       I24       I25       I26       I27       I28  \\\n",
       "0 -0.052432 -0.114432 -0.104989  0.342845 -0.159417  0.006772 -0.303193   \n",
       "1 -0.235929 -0.073920 -0.063247 -0.798768 -0.899983  1.388771 -0.248677   \n",
       "2 -0.188988 -0.044158 -0.024550 -0.586562 -0.176292 -1.013037  0.066912   \n",
       "3  0.195138 -0.104877 -0.093976 -0.757725  0.004432 -1.471299  0.643575   \n",
       "4 -0.241812 -0.082055 -0.077706 -0.845163 -0.257777  0.919065 -0.522102   \n",
       "\n",
       "        I29       I30       I31       I32       I33       I34       I35  \\\n",
       "0 -0.163287 -0.080599 -0.828880 -1.064215 -0.547067 -0.540497 -0.676045   \n",
       "1 -0.058083 -0.014470  0.092095  0.561368  0.224819  0.223190  0.098852   \n",
       "2  0.219649  0.154490  2.370951  1.384675  0.489152  0.484715  0.367301   \n",
       "3 -0.067005 -0.006874 -0.087499  0.110638  0.046880  0.047141 -0.274713   \n",
       "4  0.146076  0.043851  1.281726  0.039106  0.135331  0.134652  0.654099   \n",
       "\n",
       "        I36       I37       I38       I39       I40       I41       I42  \\\n",
       "0 -0.305007 -0.507724 -0.191437 -0.087362 -0.856151  0.802525  0.733080   \n",
       "1 -0.128227 -0.215876 -0.007164 -0.035260 -0.123911 -0.089751 -0.094963   \n",
       "2  0.749572  0.669410  0.423228  0.226897  3.227283 -0.329997 -0.327579   \n",
       "3  0.169046 -0.179742  0.047391  0.015197  0.105158 -0.045135 -0.051329   \n",
       "4  1.437536  1.995784 -0.145004 -0.029483  0.252151  0.308723  0.293393   \n",
       "\n",
       "        I43       I44       I45       I46       I47       I48       I49  \\\n",
       "0  0.006512  0.533290  0.195197  0.058094 -0.228889 -0.150821 -0.104986   \n",
       "1  0.362818  0.011107 -1.506356 -0.573679 -0.955222 -0.818880 -1.063295   \n",
       "2 -1.033898  0.014531  0.211889 -1.197156  2.860444       NaN  3.584223   \n",
       "3  0.202098  0.034693  2.904519  4.514844 -0.241111       NaN -0.521576   \n",
       "4 -0.527888 -0.003680 -1.553644 -1.233945 -0.947111 -0.926073 -0.772468   \n",
       "\n",
       "        I50       I51       I52       I53       I54       I55       I56  \\\n",
       "0 -0.026743  0.188312 -0.250701 -0.101190 -0.357521 -0.527956  0.611385   \n",
       "1 -1.022679 -1.336188 -0.612039 -0.061357 -0.482805 -0.017077  1.192135   \n",
       "2       NaN  1.272375  7.427558 -0.182816 -2.713205 -1.877595 -0.568691   \n",
       "3       NaN -0.308812 -0.542532 -0.165028  1.490354 -1.550745 -0.918676   \n",
       "4 -0.636440 -0.833875 -0.527935 -0.014170 -0.142943  1.070523 -0.284682   \n",
       "\n",
       "        I57       I58  \n",
       "0 -0.092714 -0.055733  \n",
       "1 -0.114981 -0.028074  \n",
       "2  0.224945  0.052749  \n",
       "3  0.013484 -0.013198  \n",
       "4 -0.155110 -0.026941  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bc0384-cbe0-44f2-8213-eb9593d584ad",
   "metadata": {},
   "source": [
    "## Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aecc89f2-c2ee-4ea5-8684-821d96bb9233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 59)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1852d5c1-cd68-4fb6-a691-4436538012a3",
   "metadata": {},
   "source": [
    "# Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "346abda1-a979-431a-b6a2-0219de1a8b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = MLPClassifier(\n",
    "    hidden_layer_sizes=(256, 128, 64),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    max_iter=100000, \n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "voting_estimators = [\n",
    "    ('RandomForest', RandomForestClassifier(random_state=0)),\n",
    "    #('DecisionTree', DecisionTreeClassifier(random_state=0)),\n",
    "    #('SVM', SVC(random_state=0, probability=True)),\n",
    "    #('NaiveBayes', GaussianNB()),\n",
    "    #('KNN', KNeighborsClassifier()),\n",
    "    #('LogisticRegression', LogisticRegression(random_state=0, solver=\"saga\", max_iter=1000)),\n",
    "    #('AdaBoost', AdaBoostClassifier(random_state=0, algorithm='SAMME')),\n",
    "    ('GradientBoost', GradientBoostingClassifier(random_state=0)),\n",
    "    ('XGBoost', XGBClassifier(seed=0)),\n",
    "    ('NeuralNetwork', nn) #hidden_layer_sizes=(20,20) for 2 hidden layers with 20 neurons each\n",
    "]\n",
    "\n",
    "vote_model = VotingClassifier(\n",
    "    estimators=voting_estimators, \n",
    "    voting='hard'\n",
    ")\n",
    "\n",
    "stacking_estimators = [\n",
    "    ('RandomForest', RandomForestClassifier(random_state=0)),\n",
    "    #('DecisionTree', DecisionTreeClassifier(random_state=0)),\n",
    "    #('SVM', SVC(random_state=0, probability=True)),\n",
    "    #('NaiveBayes', GaussianNB()),\n",
    "    #('KNN', KNeighborsClassifier()),\n",
    "    #('AdaBoost', AdaBoostClassifier(random_state=0, algorithm='SAMME')),\n",
    "    ('GradientBoost', GradientBoostingClassifier(random_state=0)),\n",
    "    ('XGBoost', XGBClassifier(seed=0)),\n",
    "    ('NeuralNetwork',nn)\n",
    "]\n",
    "meta_stack_classifier = LogisticRegression(random_state=0, solver=\"saga\", max_iter=1000)\n",
    "\n",
    "stacking_model = StackingClassifier(\n",
    "    estimators=stacking_estimators, \n",
    "    final_estimator=meta_stack_classifier, \n",
    "    cv=5\n",
    ")\n",
    "\n",
    "estimators = [\n",
    "    ('RandomForest', RandomForestClassifier(random_state=0)),\n",
    "    #('DecisionTree', DecisionTreeClassifier(random_state=0)),\n",
    "    #('SVM', SVC(random_state=0, probability=True)),\n",
    "    #('NaiveBayes', GaussianNB()),\n",
    "    #('KNN', KNeighborsClassifier()),\n",
    "    #('LogisticRegression', LogisticRegression(random_state=0, solver=\"saga\", max_iter=1000)),\n",
    "    ('GradientBoost', GradientBoostingClassifier(random_state=0)),\n",
    "    ('XGBoost', XGBClassifier(seed=0)),\n",
    "    #('AdaBoost', AdaBoostClassifier(random_state=0, algorithm='SAMME'))\n",
    "    #('Voting', vote_model),\n",
    "    #('Stacking', stacking_model),\n",
    "    #('NeuralNetwork', MLPClassifier(random_state=0, max_iter=1000)) # 2 hidden layers with 20 neurons each\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3b2aa3-2279-4c45-be46-3fa5b9668c35",
   "metadata": {},
   "source": [
    "# Create Pipeline with different combination of preprocessing steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7665f57b-10f3-482f-b28b-1b4fc3a5b25e",
   "metadata": {},
   "source": [
    "## Combination 7\n",
    "#### knn impute, robust scaler, lof, smote, rfecv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d91f42e-aedb-4430-b6dc-fedea5e7ff89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of xtrain:  (8000, 69)\n",
      "Shape of xtrain:  (7392, 69)\n"
     ]
    }
   ],
   "source": [
    "objs = dict()\n",
    "X_trainP, ohe_encoder = apply_one_hot_encoding(\n",
    "    X_train, \n",
    "    'Group'\n",
    ")\n",
    "objs['ohe'] = ohe_encoder\n",
    "####################################### Imputing Missing Values\n",
    "X_trainP, imp = handle_missing_vals_simple(\n",
    "    X_trainP\n",
    ")\n",
    "\n",
    "objs['miss'] = imp\n",
    "print('Shape of xtrain: ', X_trainP.shape)\n",
    "\n",
    "####################################### Robust\n",
    "std_scale_cols = (\n",
    "    X_trainP\n",
    "    .loc[:, ~X_trainP.columns.str.contains('Group')]\n",
    "    .columns\n",
    ")\n",
    "\n",
    "X_trainP, std_scaler = apply_robust_scaler(\n",
    "    X_trainP, \n",
    "    std_scale_cols\n",
    ")\n",
    "\n",
    "objs['robust_scaler'] = std_scaler\n",
    "####################################### LOF\n",
    "X_trainP_df = pd.concat(\n",
    "    [\n",
    "        X_trainP.reset_index(drop=True), \n",
    "        pd.Series(y_train, name='Class').reset_index(drop=True)\n",
    "    ], \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "X_trainP_df = detect_outliers_with_lof(\n",
    "    data=X_trainP_df\n",
    ")[0]\n",
    "\n",
    "X_trainP = (\n",
    "    X_trainP_df\n",
    "    .loc[:, X_trainP_df.columns != 'Class']\n",
    ")\n",
    "\n",
    "y_trainP = X_trainP_df['Class']\n",
    "print('Shape of xtrain: ', X_trainP.shape)\n",
    "\n",
    "####################################### Smote\n",
    "X_trainP, y_trainP = apply_random_oversampling(X_trainP, y_trainP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d88e15d-861c-40e9-a5be-0c93825ff42b",
   "metadata": {},
   "source": [
    "# Prepare the test set for real predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "618cec44-ca6f-45f0-b9c7-a2bbcc86567f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_compete_group = X_test_compete.loc[:, 'Group'].copy().reset_index(drop=True)\n",
    "X_test_compete = X_test_compete.drop('Group', axis=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bf2774a-3483-4a80-a706-ed4483152e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_competeP = pd.DataFrame(objs['miss'].transform(X_test_compete),columns=X_test_compete.columns)\n",
    "X_test_competeP = pd.DataFrame(objs['robust_scaler'].transform(X_test_competeP), columns=X_test_competeP.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46b98bdf-df95-44c7-ac4f-362d92fe4ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_competeP = pd.concat([X_test_competeP, X_test_compete_group], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af005424-0f82-4853-b4ef-9ca569714772",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_competeP_ohe_cols = pd.DataFrame(\n",
    "        objs['ohe'].transform(X_test_competeP[['Group']]).toarray(),\n",
    "        columns=objs['ohe'].get_feature_names_out(['Group'])\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "X_test_competeP = X_test_competeP.drop('Group', axis=1).reset_index(drop=True)\n",
    "X_test_competeP = pd.concat([X_test_competeP, X_test_competeP_ohe_cols], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c715c32-ea00-4c52-a4bf-5a932db2021a",
   "metadata": {},
   "source": [
    "## Predictions Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81d63b99-d932-4e31-8253-e88d186227f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vote_model.fit(X_trainP, y_trainP)\n",
    "predictions = vote_model.predict(X_test_competeP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb0cd234-6ddb-43d1-bb41-b880804dbdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"preds_comb8_wo_diff_voting.txt\"\n",
    "pd.DataFrame(predictions).to_csv(file_path, index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39eec1c8-72e9-4fc2-b3f0-0d891d939925",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
