{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18872d5e-2ee7-4f1c-8374-c436aa9ea3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier, AdaBoostClassifier, StackingClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, train_test_split, cross_val_predict, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, make_scorer, roc_auc_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "import random\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "\n",
    "from Functions_Classes import *\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "\n",
    "from feature_engine.encoding import CountFrequencyEncoder\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "403b851f-60a3-4d92-838e-9d6f00c5cc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"C:/Users/Cagan Deliktas/Desktop/ProjectDataMining2/DM2_DataCraft/data/training_data.xls\")\n",
    "X_test_compete = pd.read_excel(\"C:/Users/Cagan Deliktas/Desktop/ProjectDataMining2/DM2_DataCraft/data/test_data_no_target.xls\")\n",
    "\n",
    "df = df.loc[:, df.columns != 'Perform']\n",
    "\n",
    "df_x = df.loc[:, df.columns != 'Class']\n",
    "df_y = df['Class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_x, df_y, test_size=0.2,shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "006456f7-eecd-4486-abb2-db0ff3ef51a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = X_train.loc[:, ~X_train.columns.isin(['Group'])].columns.to_list()\n",
    "X_train[numeric_columns] = X_train[numeric_columns].replace(\n",
    "    {\n",
    "        'NA': np.nan, \n",
    "        '': np.nan,\n",
    "        ' ': np.nan\n",
    "    }\n",
    ").astype(float)\n",
    "\n",
    "X_test[numeric_columns] = X_test[numeric_columns].replace(\n",
    "    {\n",
    "        'NA': np.nan, \n",
    "        '': np.nan,\n",
    "        ' ': np.nan\n",
    "    }\n",
    ").astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88066b03-5993-437f-9af7-d0f10d3bf8ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group</th>\n",
       "      <th>I1</th>\n",
       "      <th>I2</th>\n",
       "      <th>I3</th>\n",
       "      <th>I4</th>\n",
       "      <th>I5</th>\n",
       "      <th>I6</th>\n",
       "      <th>I7</th>\n",
       "      <th>I8</th>\n",
       "      <th>I9</th>\n",
       "      <th>I10</th>\n",
       "      <th>I11</th>\n",
       "      <th>I12</th>\n",
       "      <th>I13</th>\n",
       "      <th>I14</th>\n",
       "      <th>I15</th>\n",
       "      <th>I16</th>\n",
       "      <th>I17</th>\n",
       "      <th>I18</th>\n",
       "      <th>I19</th>\n",
       "      <th>I20</th>\n",
       "      <th>I21</th>\n",
       "      <th>I22</th>\n",
       "      <th>I23</th>\n",
       "      <th>I24</th>\n",
       "      <th>I25</th>\n",
       "      <th>I26</th>\n",
       "      <th>I27</th>\n",
       "      <th>I28</th>\n",
       "      <th>I29</th>\n",
       "      <th>I30</th>\n",
       "      <th>I31</th>\n",
       "      <th>I32</th>\n",
       "      <th>I33</th>\n",
       "      <th>I34</th>\n",
       "      <th>I35</th>\n",
       "      <th>I36</th>\n",
       "      <th>I37</th>\n",
       "      <th>I38</th>\n",
       "      <th>I39</th>\n",
       "      <th>I40</th>\n",
       "      <th>I41</th>\n",
       "      <th>I42</th>\n",
       "      <th>I43</th>\n",
       "      <th>I44</th>\n",
       "      <th>I45</th>\n",
       "      <th>I46</th>\n",
       "      <th>I47</th>\n",
       "      <th>I48</th>\n",
       "      <th>I49</th>\n",
       "      <th>I50</th>\n",
       "      <th>I51</th>\n",
       "      <th>I52</th>\n",
       "      <th>I53</th>\n",
       "      <th>I54</th>\n",
       "      <th>I55</th>\n",
       "      <th>I56</th>\n",
       "      <th>I57</th>\n",
       "      <th>I58</th>\n",
       "      <th>dI1</th>\n",
       "      <th>dI2</th>\n",
       "      <th>dI3</th>\n",
       "      <th>dI4</th>\n",
       "      <th>dI5</th>\n",
       "      <th>dI6</th>\n",
       "      <th>dI7</th>\n",
       "      <th>dI8</th>\n",
       "      <th>dI9</th>\n",
       "      <th>dI10</th>\n",
       "      <th>dI11</th>\n",
       "      <th>dI12</th>\n",
       "      <th>dI13</th>\n",
       "      <th>dI14</th>\n",
       "      <th>dI15</th>\n",
       "      <th>dI16</th>\n",
       "      <th>dI17</th>\n",
       "      <th>dI18</th>\n",
       "      <th>dI19</th>\n",
       "      <th>dI20</th>\n",
       "      <th>dI21</th>\n",
       "      <th>dI22</th>\n",
       "      <th>dI23</th>\n",
       "      <th>dI24</th>\n",
       "      <th>dI25</th>\n",
       "      <th>dI26</th>\n",
       "      <th>dI27</th>\n",
       "      <th>dI28</th>\n",
       "      <th>dI29</th>\n",
       "      <th>dI30</th>\n",
       "      <th>dI31</th>\n",
       "      <th>dI32</th>\n",
       "      <th>dI33</th>\n",
       "      <th>dI34</th>\n",
       "      <th>dI35</th>\n",
       "      <th>dI36</th>\n",
       "      <th>dI37</th>\n",
       "      <th>dI38</th>\n",
       "      <th>dI39</th>\n",
       "      <th>dI40</th>\n",
       "      <th>dI41</th>\n",
       "      <th>dI42</th>\n",
       "      <th>dI43</th>\n",
       "      <th>dI44</th>\n",
       "      <th>dI45</th>\n",
       "      <th>dI46</th>\n",
       "      <th>dI47</th>\n",
       "      <th>dI48</th>\n",
       "      <th>dI49</th>\n",
       "      <th>dI50</th>\n",
       "      <th>dI51</th>\n",
       "      <th>dI52</th>\n",
       "      <th>dI53</th>\n",
       "      <th>dI54</th>\n",
       "      <th>dI55</th>\n",
       "      <th>dI56</th>\n",
       "      <th>dI57</th>\n",
       "      <th>dI58</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>G5</td>\n",
       "      <td>0.339901</td>\n",
       "      <td>-0.027090</td>\n",
       "      <td>-0.038183</td>\n",
       "      <td>-0.034894</td>\n",
       "      <td>-0.129739</td>\n",
       "      <td>0.023217</td>\n",
       "      <td>-0.176605</td>\n",
       "      <td>-0.045379</td>\n",
       "      <td>0.309218</td>\n",
       "      <td>-0.020941</td>\n",
       "      <td>0.316883</td>\n",
       "      <td>-0.429229</td>\n",
       "      <td>-0.039442</td>\n",
       "      <td>-0.300570</td>\n",
       "      <td>0.031573</td>\n",
       "      <td>-0.243882</td>\n",
       "      <td>-0.104141</td>\n",
       "      <td>-0.045089</td>\n",
       "      <td>-0.079767</td>\n",
       "      <td>0.052063</td>\n",
       "      <td>-0.127503</td>\n",
       "      <td>-0.116164</td>\n",
       "      <td>-0.081128</td>\n",
       "      <td>-0.066821</td>\n",
       "      <td>0.057271</td>\n",
       "      <td>-0.072791</td>\n",
       "      <td>0.713720</td>\n",
       "      <td>-0.157765</td>\n",
       "      <td>-0.082342</td>\n",
       "      <td>-0.018785</td>\n",
       "      <td>-0.166952</td>\n",
       "      <td>-0.004981</td>\n",
       "      <td>0.062033</td>\n",
       "      <td>0.062133</td>\n",
       "      <td>-0.237783</td>\n",
       "      <td>-0.013891</td>\n",
       "      <td>-0.327838</td>\n",
       "      <td>0.038521</td>\n",
       "      <td>-0.007864</td>\n",
       "      <td>-0.064871</td>\n",
       "      <td>-0.052786</td>\n",
       "      <td>-0.058747</td>\n",
       "      <td>-0.135570</td>\n",
       "      <td>0.089810</td>\n",
       "      <td>-0.711503</td>\n",
       "      <td>-0.064696</td>\n",
       "      <td>-0.466000</td>\n",
       "      <td>-0.313633</td>\n",
       "      <td>-0.613122</td>\n",
       "      <td>-0.631239</td>\n",
       "      <td>-0.805312</td>\n",
       "      <td>-0.351338</td>\n",
       "      <td>-0.085776</td>\n",
       "      <td>-0.497588</td>\n",
       "      <td>-0.692350</td>\n",
       "      <td>-0.562542</td>\n",
       "      <td>0.041910</td>\n",
       "      <td>-0.016354</td>\n",
       "      <td>0.010755</td>\n",
       "      <td>0.001424</td>\n",
       "      <td>0.002607</td>\n",
       "      <td>0.043410</td>\n",
       "      <td>0.029651</td>\n",
       "      <td>-0.007953</td>\n",
       "      <td>0.010559</td>\n",
       "      <td>0.002893</td>\n",
       "      <td>0.084324</td>\n",
       "      <td>0.001083</td>\n",
       "      <td>0.142741</td>\n",
       "      <td>-0.350074</td>\n",
       "      <td>0.001747</td>\n",
       "      <td>0.156097</td>\n",
       "      <td>-0.202596</td>\n",
       "      <td>-0.026362</td>\n",
       "      <td>0.004358</td>\n",
       "      <td>-0.000342</td>\n",
       "      <td>0.012561</td>\n",
       "      <td>-0.047178</td>\n",
       "      <td>0.003102</td>\n",
       "      <td>0.002239</td>\n",
       "      <td>0.001686</td>\n",
       "      <td>0.001928</td>\n",
       "      <td>0.027067</td>\n",
       "      <td>0.066567</td>\n",
       "      <td>0.183923</td>\n",
       "      <td>0.004980</td>\n",
       "      <td>0.007886</td>\n",
       "      <td>0.005248</td>\n",
       "      <td>0.074056</td>\n",
       "      <td>-0.017828</td>\n",
       "      <td>0.046981</td>\n",
       "      <td>0.046482</td>\n",
       "      <td>0.046121</td>\n",
       "      <td>-0.014443</td>\n",
       "      <td>-0.007524</td>\n",
       "      <td>0.022292</td>\n",
       "      <td>0.004008</td>\n",
       "      <td>0.065736</td>\n",
       "      <td>-0.042020</td>\n",
       "      <td>-0.040750</td>\n",
       "      <td>0.171417</td>\n",
       "      <td>0.010829</td>\n",
       "      <td>-0.083443</td>\n",
       "      <td>0.351001</td>\n",
       "      <td>-0.014556</td>\n",
       "      <td>-0.040227</td>\n",
       "      <td>-0.274504</td>\n",
       "      <td>-0.245394</td>\n",
       "      <td>-0.398500</td>\n",
       "      <td>-0.098195</td>\n",
       "      <td>0.016469</td>\n",
       "      <td>0.214315</td>\n",
       "      <td>0.019285</td>\n",
       "      <td>-0.098405</td>\n",
       "      <td>-0.027059</td>\n",
       "      <td>0.002613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7360</th>\n",
       "      <td>G8</td>\n",
       "      <td>0.060507</td>\n",
       "      <td>-0.019765</td>\n",
       "      <td>-0.035082</td>\n",
       "      <td>-0.343901</td>\n",
       "      <td>-1.251671</td>\n",
       "      <td>-0.143826</td>\n",
       "      <td>-0.361381</td>\n",
       "      <td>-0.054660</td>\n",
       "      <td>-0.917349</td>\n",
       "      <td>-0.009047</td>\n",
       "      <td>0.025156</td>\n",
       "      <td>-0.747520</td>\n",
       "      <td>-0.065075</td>\n",
       "      <td>-0.715291</td>\n",
       "      <td>-0.898384</td>\n",
       "      <td>-0.213733</td>\n",
       "      <td>-0.029949</td>\n",
       "      <td>-0.046995</td>\n",
       "      <td>0.037750</td>\n",
       "      <td>-0.398438</td>\n",
       "      <td>-0.219984</td>\n",
       "      <td>-0.169016</td>\n",
       "      <td>-0.133886</td>\n",
       "      <td>-0.127145</td>\n",
       "      <td>-0.423685</td>\n",
       "      <td>0.934234</td>\n",
       "      <td>-1.015760</td>\n",
       "      <td>-0.155468</td>\n",
       "      <td>-0.080270</td>\n",
       "      <td>-0.017755</td>\n",
       "      <td>-0.047808</td>\n",
       "      <td>-0.059389</td>\n",
       "      <td>0.231319</td>\n",
       "      <td>0.229621</td>\n",
       "      <td>-0.064934</td>\n",
       "      <td>0.308226</td>\n",
       "      <td>0.010517</td>\n",
       "      <td>-0.036450</td>\n",
       "      <td>-0.020499</td>\n",
       "      <td>-0.067800</td>\n",
       "      <td>0.107171</td>\n",
       "      <td>0.039978</td>\n",
       "      <td>-0.166495</td>\n",
       "      <td>0.004272</td>\n",
       "      <td>0.761372</td>\n",
       "      <td>0.980511</td>\n",
       "      <td>-0.628000</td>\n",
       "      <td>0.529058</td>\n",
       "      <td>-0.306727</td>\n",
       "      <td>-0.341064</td>\n",
       "      <td>0.092000</td>\n",
       "      <td>-0.525532</td>\n",
       "      <td>-0.008640</td>\n",
       "      <td>0.481887</td>\n",
       "      <td>-0.083976</td>\n",
       "      <td>-0.566475</td>\n",
       "      <td>-0.483733</td>\n",
       "      <td>0.012824</td>\n",
       "      <td>0.349321</td>\n",
       "      <td>0.008012</td>\n",
       "      <td>0.000996</td>\n",
       "      <td>0.079583</td>\n",
       "      <td>-0.350336</td>\n",
       "      <td>-0.099390</td>\n",
       "      <td>-0.156289</td>\n",
       "      <td>-0.006645</td>\n",
       "      <td>-0.244872</td>\n",
       "      <td>0.012778</td>\n",
       "      <td>0.190468</td>\n",
       "      <td>-1.274220</td>\n",
       "      <td>-0.027382</td>\n",
       "      <td>0.007558</td>\n",
       "      <td>-0.144551</td>\n",
       "      <td>-0.034057</td>\n",
       "      <td>-0.014673</td>\n",
       "      <td>-0.000209</td>\n",
       "      <td>-0.018989</td>\n",
       "      <td>0.114891</td>\n",
       "      <td>-0.002929</td>\n",
       "      <td>0.009007</td>\n",
       "      <td>0.000585</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.061622</td>\n",
       "      <td>0.032263</td>\n",
       "      <td>0.023778</td>\n",
       "      <td>0.036839</td>\n",
       "      <td>0.003085</td>\n",
       "      <td>0.003307</td>\n",
       "      <td>0.010621</td>\n",
       "      <td>-0.022424</td>\n",
       "      <td>-0.015289</td>\n",
       "      <td>-0.015127</td>\n",
       "      <td>-0.035716</td>\n",
       "      <td>0.310548</td>\n",
       "      <td>0.271682</td>\n",
       "      <td>-0.047071</td>\n",
       "      <td>0.005356</td>\n",
       "      <td>0.031021</td>\n",
       "      <td>0.143232</td>\n",
       "      <td>0.108321</td>\n",
       "      <td>-0.072428</td>\n",
       "      <td>-0.177576</td>\n",
       "      <td>0.196806</td>\n",
       "      <td>0.198187</td>\n",
       "      <td>-0.072222</td>\n",
       "      <td>0.262585</td>\n",
       "      <td>0.002079</td>\n",
       "      <td>-0.037908</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>-0.036286</td>\n",
       "      <td>0.006220</td>\n",
       "      <td>0.043591</td>\n",
       "      <td>-0.013493</td>\n",
       "      <td>-0.097193</td>\n",
       "      <td>-0.102039</td>\n",
       "      <td>0.028013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5234</th>\n",
       "      <td>G2</td>\n",
       "      <td>0.086313</td>\n",
       "      <td>-0.010992</td>\n",
       "      <td>-0.012106</td>\n",
       "      <td>-0.434803</td>\n",
       "      <td>-0.061325</td>\n",
       "      <td>-0.123946</td>\n",
       "      <td>-0.144832</td>\n",
       "      <td>-0.013103</td>\n",
       "      <td>0.260357</td>\n",
       "      <td>0.011785</td>\n",
       "      <td>0.401126</td>\n",
       "      <td>0.014261</td>\n",
       "      <td>-0.107297</td>\n",
       "      <td>-0.284234</td>\n",
       "      <td>-0.468111</td>\n",
       "      <td>-0.242772</td>\n",
       "      <td>-0.122882</td>\n",
       "      <td>-0.044571</td>\n",
       "      <td>-0.117181</td>\n",
       "      <td>-0.290714</td>\n",
       "      <td>0.174885</td>\n",
       "      <td>0.040540</td>\n",
       "      <td>-0.018167</td>\n",
       "      <td>0.001006</td>\n",
       "      <td>-0.035097</td>\n",
       "      <td>-0.341259</td>\n",
       "      <td>1.221431</td>\n",
       "      <td>-0.429968</td>\n",
       "      <td>-0.191915</td>\n",
       "      <td>-0.094166</td>\n",
       "      <td>-0.819421</td>\n",
       "      <td>0.441783</td>\n",
       "      <td>0.007249</td>\n",
       "      <td>0.007931</td>\n",
       "      <td>-0.159149</td>\n",
       "      <td>-0.119148</td>\n",
       "      <td>-0.286449</td>\n",
       "      <td>-0.190721</td>\n",
       "      <td>-0.093747</td>\n",
       "      <td>-0.796925</td>\n",
       "      <td>0.935811</td>\n",
       "      <td>0.899968</td>\n",
       "      <td>-0.258627</td>\n",
       "      <td>-0.165092</td>\n",
       "      <td>-0.996623</td>\n",
       "      <td>0.583204</td>\n",
       "      <td>-0.401333</td>\n",
       "      <td>-0.794216</td>\n",
       "      <td>-0.950403</td>\n",
       "      <td>-0.834431</td>\n",
       "      <td>-1.699563</td>\n",
       "      <td>-0.413961</td>\n",
       "      <td>-0.098455</td>\n",
       "      <td>0.710961</td>\n",
       "      <td>-1.011674</td>\n",
       "      <td>-0.018991</td>\n",
       "      <td>-0.142281</td>\n",
       "      <td>-0.058202</td>\n",
       "      <td>-0.058614</td>\n",
       "      <td>-0.009804</td>\n",
       "      <td>-0.018869</td>\n",
       "      <td>-0.099054</td>\n",
       "      <td>0.039110</td>\n",
       "      <td>-0.075024</td>\n",
       "      <td>-0.037489</td>\n",
       "      <td>-0.017748</td>\n",
       "      <td>-0.139300</td>\n",
       "      <td>-0.016723</td>\n",
       "      <td>-0.343602</td>\n",
       "      <td>0.348050</td>\n",
       "      <td>0.008517</td>\n",
       "      <td>0.026425</td>\n",
       "      <td>-0.032539</td>\n",
       "      <td>0.019391</td>\n",
       "      <td>0.000904</td>\n",
       "      <td>-0.000602</td>\n",
       "      <td>-0.002395</td>\n",
       "      <td>0.016662</td>\n",
       "      <td>0.001178</td>\n",
       "      <td>-0.022583</td>\n",
       "      <td>0.003072</td>\n",
       "      <td>0.027286</td>\n",
       "      <td>-0.005873</td>\n",
       "      <td>-0.013298</td>\n",
       "      <td>0.185785</td>\n",
       "      <td>-0.010103</td>\n",
       "      <td>0.005493</td>\n",
       "      <td>0.002136</td>\n",
       "      <td>-0.017115</td>\n",
       "      <td>-0.118150</td>\n",
       "      <td>-0.274184</td>\n",
       "      <td>-0.271271</td>\n",
       "      <td>-0.218582</td>\n",
       "      <td>-0.037907</td>\n",
       "      <td>-0.015908</td>\n",
       "      <td>-0.004291</td>\n",
       "      <td>0.002191</td>\n",
       "      <td>-0.018740</td>\n",
       "      <td>0.019837</td>\n",
       "      <td>0.019237</td>\n",
       "      <td>0.273718</td>\n",
       "      <td>-0.160730</td>\n",
       "      <td>-0.129493</td>\n",
       "      <td>-0.240139</td>\n",
       "      <td>0.186333</td>\n",
       "      <td>0.043911</td>\n",
       "      <td>-0.019986</td>\n",
       "      <td>-0.042642</td>\n",
       "      <td>0.046750</td>\n",
       "      <td>0.089260</td>\n",
       "      <td>-0.013772</td>\n",
       "      <td>-0.189302</td>\n",
       "      <td>-0.045592</td>\n",
       "      <td>0.225644</td>\n",
       "      <td>-0.006541</td>\n",
       "      <td>0.000029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7390</th>\n",
       "      <td>G5</td>\n",
       "      <td>-0.255256</td>\n",
       "      <td>-0.030937</td>\n",
       "      <td>-0.037035</td>\n",
       "      <td>0.007486</td>\n",
       "      <td>-0.159601</td>\n",
       "      <td>-0.352192</td>\n",
       "      <td>-0.625296</td>\n",
       "      <td>-0.046568</td>\n",
       "      <td>-0.341165</td>\n",
       "      <td>-0.034231</td>\n",
       "      <td>-0.183508</td>\n",
       "      <td>0.459543</td>\n",
       "      <td>0.042620</td>\n",
       "      <td>0.604411</td>\n",
       "      <td>-0.577901</td>\n",
       "      <td>-0.251014</td>\n",
       "      <td>-0.042964</td>\n",
       "      <td>-0.047069</td>\n",
       "      <td>-0.056329</td>\n",
       "      <td>-0.315806</td>\n",
       "      <td>0.025422</td>\n",
       "      <td>0.489137</td>\n",
       "      <td>-0.052859</td>\n",
       "      <td>-0.035903</td>\n",
       "      <td>3.374987</td>\n",
       "      <td>-0.115236</td>\n",
       "      <td>1.563282</td>\n",
       "      <td>0.288623</td>\n",
       "      <td>-0.083593</td>\n",
       "      <td>-0.037174</td>\n",
       "      <td>-0.952541</td>\n",
       "      <td>-1.202174</td>\n",
       "      <td>-1.194927</td>\n",
       "      <td>-1.181475</td>\n",
       "      <td>-1.433258</td>\n",
       "      <td>-0.807743</td>\n",
       "      <td>-1.212239</td>\n",
       "      <td>-0.038827</td>\n",
       "      <td>-0.033429</td>\n",
       "      <td>-0.936630</td>\n",
       "      <td>-0.064422</td>\n",
       "      <td>-0.070031</td>\n",
       "      <td>0.594623</td>\n",
       "      <td>-0.062774</td>\n",
       "      <td>1.551814</td>\n",
       "      <td>0.153692</td>\n",
       "      <td>2.041333</td>\n",
       "      <td>0.630359</td>\n",
       "      <td>0.620957</td>\n",
       "      <td>0.625450</td>\n",
       "      <td>1.749688</td>\n",
       "      <td>0.837740</td>\n",
       "      <td>-0.078991</td>\n",
       "      <td>0.389643</td>\n",
       "      <td>1.000187</td>\n",
       "      <td>-0.422026</td>\n",
       "      <td>-0.123167</td>\n",
       "      <td>-0.024468</td>\n",
       "      <td>-0.295231</td>\n",
       "      <td>-0.002853</td>\n",
       "      <td>-0.001566</td>\n",
       "      <td>-0.026696</td>\n",
       "      <td>0.021710</td>\n",
       "      <td>-0.011464</td>\n",
       "      <td>-0.012290</td>\n",
       "      <td>-0.003000</td>\n",
       "      <td>-0.404625</td>\n",
       "      <td>-0.004563</td>\n",
       "      <td>-0.353086</td>\n",
       "      <td>0.365037</td>\n",
       "      <td>0.025932</td>\n",
       "      <td>-0.070656</td>\n",
       "      <td>-0.105224</td>\n",
       "      <td>0.090413</td>\n",
       "      <td>0.050910</td>\n",
       "      <td>-0.000531</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>-0.218571</td>\n",
       "      <td>-0.002811</td>\n",
       "      <td>0.024085</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.000852</td>\n",
       "      <td>-0.676160</td>\n",
       "      <td>-0.004991</td>\n",
       "      <td>-1.091260</td>\n",
       "      <td>0.041147</td>\n",
       "      <td>0.022314</td>\n",
       "      <td>0.009551</td>\n",
       "      <td>0.005854</td>\n",
       "      <td>-0.013834</td>\n",
       "      <td>-0.029088</td>\n",
       "      <td>-0.028779</td>\n",
       "      <td>-0.023056</td>\n",
       "      <td>-0.026850</td>\n",
       "      <td>-0.023376</td>\n",
       "      <td>0.031580</td>\n",
       "      <td>0.010351</td>\n",
       "      <td>0.006519</td>\n",
       "      <td>-0.113456</td>\n",
       "      <td>-0.110027</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.002713</td>\n",
       "      <td>0.711844</td>\n",
       "      <td>-0.361907</td>\n",
       "      <td>2.657222</td>\n",
       "      <td>-0.380154</td>\n",
       "      <td>0.671863</td>\n",
       "      <td>0.872523</td>\n",
       "      <td>1.168500</td>\n",
       "      <td>1.331260</td>\n",
       "      <td>-0.002295</td>\n",
       "      <td>0.574045</td>\n",
       "      <td>1.258303</td>\n",
       "      <td>-0.087401</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>0.007336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6841</th>\n",
       "      <td>G4</td>\n",
       "      <td>0.031819</td>\n",
       "      <td>-0.037022</td>\n",
       "      <td>-0.044227</td>\n",
       "      <td>-0.317018</td>\n",
       "      <td>0.242795</td>\n",
       "      <td>-0.344809</td>\n",
       "      <td>0.623469</td>\n",
       "      <td>-0.047369</td>\n",
       "      <td>1.158791</td>\n",
       "      <td>-0.023136</td>\n",
       "      <td>-0.416807</td>\n",
       "      <td>-0.279196</td>\n",
       "      <td>-0.133470</td>\n",
       "      <td>-0.143947</td>\n",
       "      <td>1.756249</td>\n",
       "      <td>0.244296</td>\n",
       "      <td>-0.134148</td>\n",
       "      <td>-0.046832</td>\n",
       "      <td>-0.165725</td>\n",
       "      <td>2.024314</td>\n",
       "      <td>-0.195136</td>\n",
       "      <td>-0.188528</td>\n",
       "      <td>-0.098879</td>\n",
       "      <td>-0.092271</td>\n",
       "      <td>-0.446074</td>\n",
       "      <td>0.352979</td>\n",
       "      <td>-0.803545</td>\n",
       "      <td>-0.489405</td>\n",
       "      <td>-0.077901</td>\n",
       "      <td>-0.068506</td>\n",
       "      <td>-0.130448</td>\n",
       "      <td>-0.467272</td>\n",
       "      <td>0.078394</td>\n",
       "      <td>0.078320</td>\n",
       "      <td>1.185403</td>\n",
       "      <td>0.316024</td>\n",
       "      <td>1.577853</td>\n",
       "      <td>-0.147648</td>\n",
       "      <td>-0.058157</td>\n",
       "      <td>0.064896</td>\n",
       "      <td>0.046359</td>\n",
       "      <td>0.037401</td>\n",
       "      <td>-1.033898</td>\n",
       "      <td>0.001902</td>\n",
       "      <td>-0.034155</td>\n",
       "      <td>-0.889122</td>\n",
       "      <td>0.541000</td>\n",
       "      <td>-0.137998</td>\n",
       "      <td>1.142597</td>\n",
       "      <td>1.126202</td>\n",
       "      <td>0.713437</td>\n",
       "      <td>1.195506</td>\n",
       "      <td>-0.141541</td>\n",
       "      <td>-2.039434</td>\n",
       "      <td>-1.056379</td>\n",
       "      <td>0.443707</td>\n",
       "      <td>-0.138525</td>\n",
       "      <td>-0.047632</td>\n",
       "      <td>0.421568</td>\n",
       "      <td>0.004148</td>\n",
       "      <td>0.003852</td>\n",
       "      <td>0.166190</td>\n",
       "      <td>0.038238</td>\n",
       "      <td>0.021522</td>\n",
       "      <td>0.055602</td>\n",
       "      <td>0.004376</td>\n",
       "      <td>0.469766</td>\n",
       "      <td>0.006659</td>\n",
       "      <td>0.387753</td>\n",
       "      <td>-1.846363</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008786</td>\n",
       "      <td>0.681667</td>\n",
       "      <td>-0.032697</td>\n",
       "      <td>-0.006242</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.005730</td>\n",
       "      <td>0.390622</td>\n",
       "      <td>0.011498</td>\n",
       "      <td>0.011624</td>\n",
       "      <td>0.003743</td>\n",
       "      <td>0.004588</td>\n",
       "      <td>0.087240</td>\n",
       "      <td>-0.144943</td>\n",
       "      <td>0.101536</td>\n",
       "      <td>0.007111</td>\n",
       "      <td>-0.024078</td>\n",
       "      <td>0.012408</td>\n",
       "      <td>0.298167</td>\n",
       "      <td>0.216780</td>\n",
       "      <td>0.599423</td>\n",
       "      <td>0.593056</td>\n",
       "      <td>0.319574</td>\n",
       "      <td>0.376658</td>\n",
       "      <td>0.137212</td>\n",
       "      <td>0.034104</td>\n",
       "      <td>0.013989</td>\n",
       "      <td>0.339359</td>\n",
       "      <td>0.013195</td>\n",
       "      <td>0.012547</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013734</td>\n",
       "      <td>-0.063987</td>\n",
       "      <td>-0.157049</td>\n",
       "      <td>-0.225333</td>\n",
       "      <td>-0.235138</td>\n",
       "      <td>0.362784</td>\n",
       "      <td>0.502303</td>\n",
       "      <td>0.055625</td>\n",
       "      <td>0.108987</td>\n",
       "      <td>0.001564</td>\n",
       "      <td>-0.150166</td>\n",
       "      <td>-0.053651</td>\n",
       "      <td>-1.001384</td>\n",
       "      <td>0.013728</td>\n",
       "      <td>0.006899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Group        I1        I2        I3        I4        I5        I6  \\\n",
       "1001    G5  0.339901 -0.027090 -0.038183 -0.034894 -0.129739  0.023217   \n",
       "7360    G8  0.060507 -0.019765 -0.035082 -0.343901 -1.251671 -0.143826   \n",
       "5234    G2  0.086313 -0.010992 -0.012106 -0.434803 -0.061325 -0.123946   \n",
       "7390    G5 -0.255256 -0.030937 -0.037035  0.007486 -0.159601 -0.352192   \n",
       "6841    G4  0.031819 -0.037022 -0.044227 -0.317018  0.242795 -0.344809   \n",
       "\n",
       "            I7        I8        I9       I10       I11       I12       I13  \\\n",
       "1001 -0.176605 -0.045379  0.309218 -0.020941  0.316883 -0.429229 -0.039442   \n",
       "7360 -0.361381 -0.054660 -0.917349 -0.009047  0.025156 -0.747520 -0.065075   \n",
       "5234 -0.144832 -0.013103  0.260357  0.011785  0.401126  0.014261 -0.107297   \n",
       "7390 -0.625296 -0.046568 -0.341165 -0.034231 -0.183508  0.459543  0.042620   \n",
       "6841  0.623469 -0.047369  1.158791 -0.023136 -0.416807 -0.279196 -0.133470   \n",
       "\n",
       "           I14       I15       I16       I17       I18       I19       I20  \\\n",
       "1001 -0.300570  0.031573 -0.243882 -0.104141 -0.045089 -0.079767  0.052063   \n",
       "7360 -0.715291 -0.898384 -0.213733 -0.029949 -0.046995  0.037750 -0.398438   \n",
       "5234 -0.284234 -0.468111 -0.242772 -0.122882 -0.044571 -0.117181 -0.290714   \n",
       "7390  0.604411 -0.577901 -0.251014 -0.042964 -0.047069 -0.056329 -0.315806   \n",
       "6841 -0.143947  1.756249  0.244296 -0.134148 -0.046832 -0.165725  2.024314   \n",
       "\n",
       "           I21       I22       I23       I24       I25       I26       I27  \\\n",
       "1001 -0.127503 -0.116164 -0.081128 -0.066821  0.057271 -0.072791  0.713720   \n",
       "7360 -0.219984 -0.169016 -0.133886 -0.127145 -0.423685  0.934234 -1.015760   \n",
       "5234  0.174885  0.040540 -0.018167  0.001006 -0.035097 -0.341259  1.221431   \n",
       "7390  0.025422  0.489137 -0.052859 -0.035903  3.374987 -0.115236  1.563282   \n",
       "6841 -0.195136 -0.188528 -0.098879 -0.092271 -0.446074  0.352979 -0.803545   \n",
       "\n",
       "           I28       I29       I30       I31       I32       I33       I34  \\\n",
       "1001 -0.157765 -0.082342 -0.018785 -0.166952 -0.004981  0.062033  0.062133   \n",
       "7360 -0.155468 -0.080270 -0.017755 -0.047808 -0.059389  0.231319  0.229621   \n",
       "5234 -0.429968 -0.191915 -0.094166 -0.819421  0.441783  0.007249  0.007931   \n",
       "7390  0.288623 -0.083593 -0.037174 -0.952541 -1.202174 -1.194927 -1.181475   \n",
       "6841 -0.489405 -0.077901 -0.068506 -0.130448 -0.467272  0.078394  0.078320   \n",
       "\n",
       "           I35       I36       I37       I38       I39       I40       I41  \\\n",
       "1001 -0.237783 -0.013891 -0.327838  0.038521 -0.007864 -0.064871 -0.052786   \n",
       "7360 -0.064934  0.308226  0.010517 -0.036450 -0.020499 -0.067800  0.107171   \n",
       "5234 -0.159149 -0.119148 -0.286449 -0.190721 -0.093747 -0.796925  0.935811   \n",
       "7390 -1.433258 -0.807743 -1.212239 -0.038827 -0.033429 -0.936630 -0.064422   \n",
       "6841  1.185403  0.316024  1.577853 -0.147648 -0.058157  0.064896  0.046359   \n",
       "\n",
       "           I42       I43       I44       I45       I46       I47       I48  \\\n",
       "1001 -0.058747 -0.135570  0.089810 -0.711503 -0.064696 -0.466000 -0.313633   \n",
       "7360  0.039978 -0.166495  0.004272  0.761372  0.980511 -0.628000  0.529058   \n",
       "5234  0.899968 -0.258627 -0.165092 -0.996623  0.583204 -0.401333 -0.794216   \n",
       "7390 -0.070031  0.594623 -0.062774  1.551814  0.153692  2.041333  0.630359   \n",
       "6841  0.037401 -1.033898  0.001902 -0.034155 -0.889122  0.541000 -0.137998   \n",
       "\n",
       "           I49       I50       I51       I52       I53       I54       I55  \\\n",
       "1001 -0.613122 -0.631239 -0.805312 -0.351338 -0.085776 -0.497588 -0.692350   \n",
       "7360 -0.306727 -0.341064  0.092000 -0.525532 -0.008640  0.481887 -0.083976   \n",
       "5234 -0.950403 -0.834431 -1.699563 -0.413961 -0.098455  0.710961 -1.011674   \n",
       "7390  0.620957  0.625450  1.749688  0.837740 -0.078991  0.389643  1.000187   \n",
       "6841  1.142597  1.126202  0.713437  1.195506 -0.141541 -2.039434 -1.056379   \n",
       "\n",
       "           I56       I57       I58       dI1       dI2       dI3       dI4  \\\n",
       "1001 -0.562542  0.041910 -0.016354  0.010755  0.001424  0.002607  0.043410   \n",
       "7360 -0.566475 -0.483733  0.012824  0.349321  0.008012  0.000996  0.079583   \n",
       "5234 -0.018991 -0.142281 -0.058202 -0.058614 -0.009804 -0.018869 -0.099054   \n",
       "7390 -0.422026 -0.123167 -0.024468 -0.295231 -0.002853 -0.001566 -0.026696   \n",
       "6841  0.443707 -0.138525 -0.047632  0.421568  0.004148  0.003852  0.166190   \n",
       "\n",
       "           dI5       dI6       dI7       dI8       dI9      dI10      dI11  \\\n",
       "1001  0.029651 -0.007953  0.010559  0.002893  0.084324  0.001083  0.142741   \n",
       "7360 -0.350336 -0.099390 -0.156289 -0.006645 -0.244872  0.012778  0.190468   \n",
       "5234  0.039110 -0.075024 -0.037489 -0.017748 -0.139300 -0.016723 -0.343602   \n",
       "7390  0.021710 -0.011464 -0.012290 -0.003000 -0.404625 -0.004563 -0.353086   \n",
       "6841  0.038238  0.021522  0.055602  0.004376  0.469766  0.006659  0.387753   \n",
       "\n",
       "          dI12      dI13      dI14      dI15      dI16      dI17      dI18  \\\n",
       "1001 -0.350074  0.001747  0.156097 -0.202596 -0.026362  0.004358 -0.000342   \n",
       "7360 -1.274220 -0.027382  0.007558 -0.144551 -0.034057 -0.014673 -0.000209   \n",
       "5234  0.348050  0.008517  0.026425 -0.032539  0.019391  0.000904 -0.000602   \n",
       "7390  0.365037  0.025932 -0.070656 -0.105224  0.090413  0.050910 -0.000531   \n",
       "6841 -1.846363  0.000000  0.008786  0.681667 -0.032697 -0.006242  0.000239   \n",
       "\n",
       "          dI19      dI20      dI21      dI22      dI23      dI24      dI25  \\\n",
       "1001  0.012561 -0.047178  0.003102  0.002239  0.001686  0.001928  0.027067   \n",
       "7360 -0.018989  0.114891 -0.002929  0.009007  0.000585  0.000669  0.061622   \n",
       "5234 -0.002395  0.016662  0.001178 -0.022583  0.003072  0.027286 -0.005873   \n",
       "7390  0.000262 -0.218571 -0.002811  0.024085  0.000134  0.000852 -0.676160   \n",
       "6841  0.005730  0.390622  0.011498  0.011624  0.003743  0.004588  0.087240   \n",
       "\n",
       "          dI26      dI27      dI28      dI29      dI30      dI31      dI32  \\\n",
       "1001  0.066567  0.183923  0.004980  0.007886  0.005248  0.074056 -0.017828   \n",
       "7360  0.032263  0.023778  0.036839  0.003085  0.003307  0.010621 -0.022424   \n",
       "5234 -0.013298  0.185785 -0.010103  0.005493  0.002136 -0.017115 -0.118150   \n",
       "7390 -0.004991 -1.091260  0.041147  0.022314  0.009551  0.005854 -0.013834   \n",
       "6841 -0.144943  0.101536  0.007111 -0.024078  0.012408  0.298167  0.216780   \n",
       "\n",
       "          dI33      dI34      dI35      dI36      dI37      dI38      dI39  \\\n",
       "1001  0.046981  0.046482  0.046121 -0.014443 -0.007524  0.022292  0.004008   \n",
       "7360 -0.015289 -0.015127 -0.035716  0.310548  0.271682 -0.047071  0.005356   \n",
       "5234 -0.274184 -0.271271 -0.218582 -0.037907 -0.015908 -0.004291  0.002191   \n",
       "7390 -0.029088 -0.028779 -0.023056 -0.026850 -0.023376  0.031580  0.010351   \n",
       "6841  0.599423  0.593056  0.319574  0.376658  0.137212  0.034104  0.013989   \n",
       "\n",
       "          dI40      dI41      dI42      dI43      dI44      dI45      dI46  \\\n",
       "1001  0.065736 -0.042020 -0.040750  0.171417  0.010829 -0.083443  0.351001   \n",
       "7360  0.031021  0.143232  0.108321 -0.072428 -0.177576  0.196806  0.198187   \n",
       "5234 -0.018740  0.019837  0.019237  0.273718 -0.160730 -0.129493 -0.240139   \n",
       "7390  0.006519 -0.113456 -0.110027       NaN -0.002713  0.711844 -0.361907   \n",
       "6841  0.339359  0.013195  0.012547  0.000000  0.013734 -0.063987 -0.157049   \n",
       "\n",
       "          dI47      dI48      dI49      dI50      dI51      dI52      dI53  \\\n",
       "1001 -0.014556 -0.040227 -0.274504 -0.245394 -0.398500 -0.098195  0.016469   \n",
       "7360 -0.072222  0.262585  0.002079 -0.037908  0.070312 -0.036286  0.006220   \n",
       "5234  0.186333  0.043911 -0.019986 -0.042642  0.046750  0.089260 -0.013772   \n",
       "7390  2.657222 -0.380154  0.671863  0.872523  1.168500  1.331260 -0.002295   \n",
       "6841 -0.225333 -0.235138  0.362784  0.502303  0.055625  0.108987  0.001564   \n",
       "\n",
       "          dI54      dI55      dI56      dI57      dI58  \n",
       "1001  0.214315  0.019285 -0.098405 -0.027059  0.002613  \n",
       "7360  0.043591 -0.013493 -0.097193 -0.102039  0.028013  \n",
       "5234 -0.189302 -0.045592  0.225644 -0.006541  0.000029  \n",
       "7390  0.574045  1.258303 -0.087401  0.000756  0.007336  \n",
       "6841 -0.150166 -0.053651 -1.001384  0.013728  0.006899  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bc0384-cbe0-44f2-8213-eb9593d584ad",
   "metadata": {},
   "source": [
    "## Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aecc89f2-c2ee-4ea5-8684-821d96bb9233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6400, 117)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78880b8-001f-4b1b-83ce-517ca37e82ab",
   "metadata": {},
   "source": [
    "# Only the two columns below have a different type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de0dc447-dce1-4a48-8dfa-aa37c6a418e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Group    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtypes[X_train.dtypes!='float64']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db50f016-d605-4f68-8a30-98434df59e4f",
   "metadata": {},
   "source": [
    "## we can conclude that all of the columns are float64 besides the group and class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "517e987d-fb06-4d7f-a279-8db111aaa902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([dtype('O'), dtype('float64')], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtypes.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed39c2b0-3582-46d7-8b8b-8929f48b8383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>50%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>I1</th>\n",
       "      <td>0.075013</td>\n",
       "      <td>-0.141740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I2</th>\n",
       "      <td>-0.013397</td>\n",
       "      <td>-0.029600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I3</th>\n",
       "      <td>-0.020962</td>\n",
       "      <td>-0.038703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I4</th>\n",
       "      <td>0.001090</td>\n",
       "      <td>-0.248822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I5</th>\n",
       "      <td>-0.003963</td>\n",
       "      <td>-0.077468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        mean       50%\n",
       "I1  0.075013 -0.141740\n",
       "I2 -0.013397 -0.029600\n",
       "I3 -0.020962 -0.038703\n",
       "I4  0.001090 -0.248822\n",
       "I5 -0.003963 -0.077468"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.select_dtypes(include='number').describe().T.loc[:,['mean', '50%']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0648db1-6391-4cfa-bcde-6f38ac235bb3",
   "metadata": {},
   "source": [
    "### It seems that the difference between median and mean values for each feature are not so high (not very skewed). the max difference is: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd7293cc-f98a-4665-a28c-6e60265da9c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2939161958064032"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.select_dtypes(include='number').describe().T.loc[:,['mean', '50%']].assign(diff=lambda x: x['mean'] - x['50%'])['diff'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f341669-8432-4d93-834f-0b526ac74dfa",
   "metadata": {},
   "source": [
    "# we can see that some of the columns' max and min values are extreme. it might indicate outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddfecdde-ae5e-457d-94da-e511d8264de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>I1</th>\n",
       "      <td>6400.0</td>\n",
       "      <td>0.075013</td>\n",
       "      <td>0.910312</td>\n",
       "      <td>-2.432857</td>\n",
       "      <td>-0.591216</td>\n",
       "      <td>-0.141740</td>\n",
       "      <td>0.494733</td>\n",
       "      <td>5.013767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I2</th>\n",
       "      <td>6400.0</td>\n",
       "      <td>-0.013397</td>\n",
       "      <td>0.194697</td>\n",
       "      <td>-0.076729</td>\n",
       "      <td>-0.036865</td>\n",
       "      <td>-0.029600</td>\n",
       "      <td>-0.017510</td>\n",
       "      <td>9.338686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I3</th>\n",
       "      <td>6400.0</td>\n",
       "      <td>-0.020962</td>\n",
       "      <td>0.212517</td>\n",
       "      <td>-0.060707</td>\n",
       "      <td>-0.046038</td>\n",
       "      <td>-0.038703</td>\n",
       "      <td>-0.027389</td>\n",
       "      <td>9.323656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I4</th>\n",
       "      <td>5996.0</td>\n",
       "      <td>0.001090</td>\n",
       "      <td>0.937334</td>\n",
       "      <td>-1.038730</td>\n",
       "      <td>-0.572480</td>\n",
       "      <td>-0.248822</td>\n",
       "      <td>0.282852</td>\n",
       "      <td>10.504271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I5</th>\n",
       "      <td>6395.0</td>\n",
       "      <td>-0.003963</td>\n",
       "      <td>1.021842</td>\n",
       "      <td>-15.806570</td>\n",
       "      <td>-0.190665</td>\n",
       "      <td>-0.077468</td>\n",
       "      <td>0.072210</td>\n",
       "      <td>22.755955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dI54</th>\n",
       "      <td>6400.0</td>\n",
       "      <td>0.011004</td>\n",
       "      <td>0.290574</td>\n",
       "      <td>-2.753721</td>\n",
       "      <td>-0.118378</td>\n",
       "      <td>0.005360</td>\n",
       "      <td>0.127927</td>\n",
       "      <td>1.676064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dI55</th>\n",
       "      <td>6272.0</td>\n",
       "      <td>0.015606</td>\n",
       "      <td>0.403970</td>\n",
       "      <td>-2.345764</td>\n",
       "      <td>-0.176970</td>\n",
       "      <td>-0.016946</td>\n",
       "      <td>0.165380</td>\n",
       "      <td>3.325363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dI56</th>\n",
       "      <td>6384.0</td>\n",
       "      <td>0.008597</td>\n",
       "      <td>0.498089</td>\n",
       "      <td>-5.744188</td>\n",
       "      <td>-0.150448</td>\n",
       "      <td>-0.022875</td>\n",
       "      <td>0.126711</td>\n",
       "      <td>8.336605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dI57</th>\n",
       "      <td>6291.0</td>\n",
       "      <td>0.007372</td>\n",
       "      <td>1.449936</td>\n",
       "      <td>-79.799539</td>\n",
       "      <td>-0.031728</td>\n",
       "      <td>0.000532</td>\n",
       "      <td>0.036795</td>\n",
       "      <td>71.825953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dI58</th>\n",
       "      <td>6207.0</td>\n",
       "      <td>0.003408</td>\n",
       "      <td>0.258850</td>\n",
       "      <td>-7.577418</td>\n",
       "      <td>-0.007033</td>\n",
       "      <td>0.000984</td>\n",
       "      <td>0.009205</td>\n",
       "      <td>10.114502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       count      mean       std        min       25%       50%       75%  \\\n",
       "I1    6400.0  0.075013  0.910312  -2.432857 -0.591216 -0.141740  0.494733   \n",
       "I2    6400.0 -0.013397  0.194697  -0.076729 -0.036865 -0.029600 -0.017510   \n",
       "I3    6400.0 -0.020962  0.212517  -0.060707 -0.046038 -0.038703 -0.027389   \n",
       "I4    5996.0  0.001090  0.937334  -1.038730 -0.572480 -0.248822  0.282852   \n",
       "I5    6395.0 -0.003963  1.021842 -15.806570 -0.190665 -0.077468  0.072210   \n",
       "...      ...       ...       ...        ...       ...       ...       ...   \n",
       "dI54  6400.0  0.011004  0.290574  -2.753721 -0.118378  0.005360  0.127927   \n",
       "dI55  6272.0  0.015606  0.403970  -2.345764 -0.176970 -0.016946  0.165380   \n",
       "dI56  6384.0  0.008597  0.498089  -5.744188 -0.150448 -0.022875  0.126711   \n",
       "dI57  6291.0  0.007372  1.449936 -79.799539 -0.031728  0.000532  0.036795   \n",
       "dI58  6207.0  0.003408  0.258850  -7.577418 -0.007033  0.000984  0.009205   \n",
       "\n",
       "            max  \n",
       "I1     5.013767  \n",
       "I2     9.338686  \n",
       "I3     9.323656  \n",
       "I4    10.504271  \n",
       "I5    22.755955  \n",
       "...         ...  \n",
       "dI54   1.676064  \n",
       "dI55   3.325363  \n",
       "dI56   8.336605  \n",
       "dI57  71.825953  \n",
       "dI58  10.114502  \n",
       "\n",
       "[116 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.select_dtypes(include='number').describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995dfe3e-7f19-45a7-8b42-dce172c4fcbf",
   "metadata": {},
   "source": [
    "# Missing Value Percentages for each column in descending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5da26c6f-3509-42f8-94b0-0aca7336000b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>missing_perc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dI21</th>\n",
       "      <td>19.390625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I21</th>\n",
       "      <td>19.234375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dI50</th>\n",
       "      <td>19.234375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dI48</th>\n",
       "      <td>19.234375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I48</th>\n",
       "      <td>19.109375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I50</th>\n",
       "      <td>19.109375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dI24</th>\n",
       "      <td>9.171875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I24</th>\n",
       "      <td>8.843750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      missing_perc\n",
       "dI21     19.390625\n",
       "I21      19.234375\n",
       "dI50     19.234375\n",
       "dI48     19.234375\n",
       "I48      19.109375\n",
       "I50      19.109375\n",
       "dI24      9.171875\n",
       "I24       8.843750"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((pd.DataFrame(\n",
    "    X_train.isna().sum()\n",
    ").rename(columns={0: 'missing_perc'}).\n",
    "  sort_values(['missing_perc'], ascending=False) / X_train.shape[0])*100).head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf46ebd-69ed-4c0d-84ce-82553d72a1f5",
   "metadata": {},
   "source": [
    "## The Target Class seems not balanced. The class 0 is way less than other two classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "269d0ac6-329c-4c50-b9b1-def87204d544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       " 1    2994\n",
       "-1    2477\n",
       " 0     929\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts() #buy or hold or sell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d79847c1-1753-4336-8b82-9ad38818a148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bar_plot = pd.DataFrame(y_train.value_counts()).reset_index()\n",
    "\n",
    "plt.figure(figsize=(5,3))\n",
    "plt.bar(x=bar_plot['Class'], height=bar_plot['count'])\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Counts')\n",
    "plt.title('Value Counts of the Target')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0a4ea1-cf1c-476e-a5dd-c3dfaa80e600",
   "metadata": {},
   "source": [
    "## There are many highly correlated columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b22a65b-5f83-4925-9741-813be0207b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairs with correlation greater than 0.6:\n",
      "[('I2', 'I3', 0.9848), ('I2', 'I8', 0.9766), ('I2', 'I10', 0.9348), ('I3', 'I2', 0.9848), ('I3', 'I8', 0.986)]\n"
     ]
    }
   ],
   "source": [
    "correlation_matrix = X_train.loc[:, ~X_train.columns.isin(['Group'])].corr()\n",
    "\n",
    "high_correlation_pairs = (correlation_matrix.abs() > 0.9) & (correlation_matrix != 1)\n",
    "\n",
    "pairs = [(col1, col2, round(correlation_matrix.loc[col1, col2],4)) for col1 in correlation_matrix.columns for col2 in correlation_matrix.columns if high_correlation_pairs.loc[col1, col2]]\n",
    "\n",
    "print(\"Pairs with correlation greater than 0.6:\")\n",
    "print(pairs[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1852d5c1-cd68-4fb6-a691-4436538012a3",
   "metadata": {},
   "source": [
    "# Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "346abda1-a979-431a-b6a2-0219de1a8b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_estimators = [\n",
    "    ('RandomForest', RandomForestClassifier(random_state=0)),\n",
    "    ('DecisionTree', DecisionTreeClassifier(random_state=0)),\n",
    "    ('SVM', SVC(random_state=0, probability=True)),\n",
    "    ('NaiveBayes', GaussianNB()),\n",
    "    ('KNN', KNeighborsClassifier()),\n",
    "    ('LogisticRegression', LogisticRegression(random_state=0, solver=\"saga\")),\n",
    "    ('AdaBoost', AdaBoostClassifier(random_state=0, algorithm='SAMME')),\n",
    "    ('GradientBoost', GradientBoostingClassifier(random_state=0)),\n",
    "    ('XGBoost', XGBClassifier(seed=0)),\n",
    "    ('NeuralNetwork', MLPClassifier(random_state=0, max_iter=1000)) #hidden_layer_sizes=(20,20) for 2 hidden layers with 20 neurons each\n",
    "]\n",
    "\n",
    "vote_model = VotingClassifier(\n",
    "    estimators=voting_estimators, \n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "stacking_estimators = [\n",
    "    ('RandomForest', RandomForestClassifier(random_state=0)),\n",
    "    ('DecisionTree', DecisionTreeClassifier(random_state=0)),\n",
    "    ('SVM', SVC(random_state=0, probability=True)),\n",
    "    ('NaiveBayes', GaussianNB()),\n",
    "    ('KNN', KNeighborsClassifier()),\n",
    "    ('AdaBoost', AdaBoostClassifier(random_state=0, algorithm='SAMME')),\n",
    "    ('GradientBoost', GradientBoostingClassifier(random_state=0)),\n",
    "    ('XGBoost', XGBClassifier(seed=0)),\n",
    "    ('NeuralNetwork', MLPClassifier(random_state=0, max_iter=1000))\n",
    "]\n",
    "meta_stack_classifier = LogisticRegression(random_state=0, solver=\"saga\")\n",
    "\n",
    "stacking_model = StackingClassifier(\n",
    "    estimators=stacking_estimators, \n",
    "    final_estimator=meta_stack_classifier, \n",
    "    cv=5\n",
    ")\n",
    "\n",
    "estimators = [\n",
    "    ('RandomForest', RandomForestClassifier(random_state=0)),\n",
    "    #('DecisionTree', DecisionTreeClassifier(random_state=0)),\n",
    "    ('SVM', SVC(random_state=0, probability=True)),\n",
    "    #('NaiveBayes', GaussianNB()),\n",
    "    #('KNN', KNeighborsClassifier()),\n",
    "    ('LogisticRegression', LogisticRegression(random_state=0, solver=\"saga\")),\n",
    "    ('GradientBoost', GradientBoostingClassifier(random_state=0)),\n",
    "    ('XGBoost', XGBClassifier(seed=0)),\n",
    "    ('AdaBoost', AdaBoostClassifier(random_state=0, algorithm='SAMME')),\n",
    "    #('Voting', vote_model),\n",
    "    #('Stacking', stacking_model),\n",
    "    #('NeuralNetwork', MLPClassifier(random_state=0, max_iter=1000)) # 2 hidden layers with 20 neurons each\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3b2aa3-2279-4c45-be46-3fa5b9668c35",
   "metadata": {},
   "source": [
    "# Create Pipeline with different combination of preprocessing steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7665f57b-10f3-482f-b28b-1b4fc3a5b25e",
   "metadata": {},
   "source": [
    "## Combination 1\n",
    "#### One hot encoding, median imputation, remove outliers with LOF, random oversampling, standard scaling, RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d91f42e-aedb-4430-b6dc-fedea5e7ff89",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1_objs = dict()\n",
    "####################################### One Hot Encoding \n",
    "X_train_ohe, ohe_encoder = apply_one_hot_encoding(\n",
    "    X_train, \n",
    "    'Group'\n",
    ")\n",
    "\n",
    "c1_objs['ohe'] = ohe_encoder\n",
    "####################################### Imputing Missing Values\n",
    "X_train_ohe_simpmiss, simp_imp = handle_missing_vals_simple(\n",
    "    X_train_ohe, \n",
    "    strategy='median'\n",
    ")\n",
    "\n",
    "c1_objs['miss'] = simp_imp\n",
    "####################################### Remove outliers with Local Outlier Factor\n",
    "X_train_ohe_simpmiss_df = pd.concat(\n",
    "    [\n",
    "        X_train_ohe_simpmiss.reset_index(drop=True), \n",
    "        pd.Series(y_train, name='Class').reset_index(drop=True)\n",
    "    ], \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "X_train_ohe_simpmiss_lof_df, lof_obj = detect_outliers_with_lof(\n",
    "    X_train_ohe_simpmiss_df, \n",
    "    n_neighbors=20\n",
    ")\n",
    "c1_objs['lof'] = lof_obj\n",
    "\n",
    "X_train_ohe_simpmiss_lof = (\n",
    "    X_train_ohe_simpmiss_lof_df\n",
    "    .loc[:, X_train_ohe_simpmiss_lof_df.columns != 'Class']\n",
    ")\n",
    "\n",
    "y_train_lof = X_train_ohe_simpmiss_lof_df['Class']\n",
    "####################################### Random Oversampling\n",
    "X_train_ohe_simpmiss_lof_ros, y_train_lof_ros = apply_random_oversampling(X_train_ohe_simpmiss_lof, y_train_lof)\n",
    "####################################### Standard Scaler\n",
    "std_scale_cols = (\n",
    "    X_train_ohe_simpmiss_lof_ros\n",
    "    .loc[:, ~X_train_ohe_simpmiss_lof_ros.columns.str.contains('Group')]\n",
    "    .columns\n",
    ")\n",
    "\n",
    "X_train_ohe_simpmiss_lof_ros_scaled, std_scaler = apply_std_scaler(\n",
    "    X_train_ohe_simpmiss_lof_ros, \n",
    "    std_scale_cols\n",
    ")\n",
    "\n",
    "c1_objs['scaler'] = std_scaler\n",
    "####################################### RFECV\n",
    "classifier = DecisionTreeClassifier()\n",
    "X_train_ohe_simpmiss_lof_ros_scaled_rfecv = select_features_rfecv(\n",
    "    X=X_train_ohe_simpmiss_lof_ros_scaled, \n",
    "    y=y_train_lof_ros, \n",
    "    classifier=classifier, \n",
    "    cv=3, \n",
    "    scoring='f1_weighted'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e230017-e092-4e62-8a14-5345a8c7ede4",
   "metadata": {},
   "source": [
    "### Prepare the test set according to combination 1 above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fb7be12-40c6-4249-acff-7c11bbd72d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols_test = X_test.loc[:, X_test.columns != 'Group'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c48ba29-ffe3-4158-8153-8beb3e417e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################## One Hot Encoding\n",
    "X_test_ohe = pd.DataFrame(\n",
    "        c1_objs['ohe'].transform(X_test[['Group']]).toarray(),\n",
    "        columns=ohe_encoder.get_feature_names_out(['Group'])\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "X_test = X_test.drop('Group', axis=1).reset_index(drop=True)\n",
    "X_test_ohe = pd.concat([X_test, X_test_ohe], axis=1)\n",
    "######################################## Imputing Missing Values\n",
    "X_test_ohe_simpmiss = pd.DataFrame(c1_objs['miss'].transform(X_test_ohe), columns=X_test_ohe.columns)\n",
    "######################################## Scaling\n",
    "cat_cols_test = X_test_ohe_simpmiss.loc[:, X_test_ohe_simpmiss.columns.str.contains('Group')].columns\n",
    "X_test_ohe_simpmiss_scaled = pd.DataFrame(c1_objs['scaler'].transform(X_test_ohe_simpmiss[num_cols_test]), columns=num_cols_test).reset_index(drop=True)\n",
    "X_test_ohe_simpmiss_scaled = pd.concat([X_test_ohe_simpmiss_scaled, X_test_ohe_simpmiss[cat_cols_test].reset_index(drop=True)], axis=1)\n",
    "######################################## RFECV\n",
    "subset_features_rfecv = X_train_ohe_simpmiss_lof_ros_scaled_rfecv.columns.to_list()\n",
    "X_test_ohe_simpmiss_scaled = X_test_ohe_simpmiss_scaled.loc[:, subset_features_rfecv]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa1fdbb-5b7a-43b3-83af-7b48bee5c3b4",
   "metadata": {},
   "source": [
    "# Apply cross validation with f1, auc and accuracy\n",
    "\n",
    "#### *Weighted F1 Score: F1 score calculated by taking the average of F1 scores for each class. Average is weighted by support which is the number of true instances for each label. \n",
    "#### *AUC One vs One Weighted: By considering all pairwise combinations of classes, average AUC is calculated. Average is weighted by the support. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79197db7-33cc-42da-b582-ecf52eba91a6",
   "metadata": {},
   "source": [
    "## Create Class object and apply cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5fcb2a67-1bbe-4f97-8660-0c76963e3245",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_cost_matrix = np.array([[0, 1, 2],\n",
    "                              [1, 0, 1],\n",
    "                              [2, 1, 0]])\n",
    "\n",
    "model_selector = ModelSelection(\n",
    "    x_train=X_train_ohe_simpmiss_lof_ros_scaled_rfecv, \n",
    "    y_train=y_train_lof_ros,\n",
    "    estimators=estimators,\n",
    "    x_test=X_test_ohe_simpmiss_scaled,\n",
    "    y_test=y_test,\n",
    "    cost_matrix=error_cost_matrix\n",
    ")\n",
    "model_selector.encode_y_train()\n",
    "model_selector.create_col_transformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "255d6131-2636-464d-91f0-d2cee3a3f369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: -1, 1: 0, 2: 1}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_selector.target_label_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ec19b29-b2f3-4d57-9c58-fbfe15b92c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Results for Mean F1 Score:\n",
      "\n",
      "RandomForest = 0.725568\n",
      "SVM = 0.460333\n",
      "LogisticRegression = 0.378517\n",
      "GradientBoost = 0.511430\n",
      "XGBoost = 0.696726\n",
      "AdaBoost = 0.433436\n",
      "NeuralNetwork = 0.486266\n",
      "\n",
      "Best Estimator (F1): RandomForest\n",
      "**********************************************\n",
      "CV Results for Mean AUC Score:\n",
      "\n",
      "RandomForest = 0.883375\n",
      "SVM = 0.648911\n",
      "LogisticRegression = 0.554787\n",
      "GradientBoost = 0.698650\n",
      "XGBoost = 0.862019\n",
      "AdaBoost = 0.615058\n",
      "NeuralNetwork = 0.676754\n",
      "\n",
      "Best Estimator (AUC): RandomForest\n",
      "**********************************************\n",
      "CV Results for Mean Accuracy Score:\n",
      "\n",
      "RandomForest = 0.726012\n",
      "SVM = 0.461518\n",
      "LogisticRegression = 0.378690\n",
      "GradientBoost = 0.512868\n",
      "XGBoost = 0.701397\n",
      "AdaBoost = 0.433907\n",
      "NeuralNetwork = 0.489882\n",
      "\n",
      "Best Estimator (Accuracy): RandomForest\n",
      "**********************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cagan Deliktas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Cagan Deliktas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Cagan Deliktas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Cagan Deliktas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Cagan Deliktas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Cagan Deliktas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Cagan Deliktas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Cagan Deliktas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Cagan Deliktas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Cagan Deliktas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Cagan Deliktas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Cagan Deliktas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Cagan Deliktas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Cagan Deliktas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Cagan Deliktas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Cagan Deliktas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Cagan Deliktas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Cagan Deliktas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Cagan Deliktas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Results for Cost Matrix Error Score:\n",
      "\n",
      "RandomForest = 0.511119\n",
      "SVM = 0.744503\n",
      "LogisticRegression = 0.825337\n",
      "GradientBoost = 0.699650\n",
      "XGBoost = 0.528736\n",
      "AdaBoost = 0.771739\n",
      "NeuralNetwork = 0.718266\n",
      "\n",
      "Best Estimator (Cost Metric Error Score): RandomForest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cagan Deliktas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_selector.calculate_cv_f1(n_folds=10, scoring_average='f1_weighted')\n",
    "print('**********************************************')\n",
    "model_selector.calculate_cv_auc(n_folds=10, scoring_average='roc_auc_ovo_weighted')\n",
    "print('**********************************************')   \n",
    "model_selector.calculate_cv_accuracy(n_folds=10, scoring_average='accuracy')\n",
    "print('**********************************************')   \n",
    "model_selector.calculate_cost_matrix_cv2(n_folds=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff78202-7717-4a74-9c00-2bd9aac5fb64",
   "metadata": {},
   "source": [
    "## GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f5076d9-0356-4356-86a4-f48bf781d89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'ClassificationModel__n_estimators': [50, 100, 150],\n",
    "    'ClassificationModel__criterion': ['gini', 'entropy'],\n",
    "    'ClassificationModel__max_depth': [None, 5, 10],\n",
    "    'ClassificationModel__min_samples_split': [2, 5],\n",
    "    'ClassificationModel__min_samples_leaf': [1, 2],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "78553300-8e68-4d61-bcb9-30d8b722128d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "Best parameters found by GridSearchCV (f1_weighted):\n",
      "{'ClassificationModel__criterion': 'gini', 'ClassificationModel__max_depth': None, 'ClassificationModel__min_samples_leaf': 2, 'ClassificationModel__min_samples_split': 2, 'ClassificationModel__n_estimators': 150}\n",
      "\n",
      "Best score found by GridSearchCV (f1_weighted):\n",
      "0.7106230025560166\n"
     ]
    }
   ],
   "source": [
    "model_selector.apply_grid_cv(\n",
    "    estimator=RandomForestClassifier(random_state=0),\n",
    "    params=param_grid,\n",
    "    cv=3,\n",
    "    scoring='f1_weighted'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d44c14aa-fb23-4797-a563-1549a0eb1379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: -1, 1: 0, 2: 1}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.40      0.41       619\n",
      "           1       0.13      0.04      0.06       207\n",
      "           2       0.51      0.63      0.56       774\n",
      "\n",
      "    accuracy                           0.46      1600\n",
      "   macro avg       0.35      0.35      0.34      1600\n",
      "weighted avg       0.43      0.46      0.44      1600\n",
      "\n",
      "{0: -1, 1: 0, 2: 1}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_selector.predict_on_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e71f1110-fc38-427a-82e7-9a9535bc0dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       " 1    774\n",
       "-1    619\n",
       " 0    207\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_selector.y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6e4c2a4e-e913-4677-9ad6-84fa6dc586a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "-1    2668\n",
       " 0    2668\n",
       " 1    2668\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_selector.y_train.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
