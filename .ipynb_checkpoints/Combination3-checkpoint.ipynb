{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18872d5e-2ee7-4f1c-8374-c436aa9ea3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier, AdaBoostClassifier, StackingClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, train_test_split, cross_val_predict, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, make_scorer, roc_auc_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "import random\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "\n",
    "from Functions_Classes import *\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "\n",
    "from feature_engine.encoding import CountFrequencyEncoder\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "403b851f-60a3-4d92-838e-9d6f00c5cc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"C:/Users/Cagan Deliktas/Desktop/ProjectDataMining2/DM2_DataCraft/data/training_data.xls\")\n",
    "X_test_compete = pd.read_excel(\"C:/Users/Cagan Deliktas/Desktop/ProjectDataMining2/DM2_DataCraft/data/test_data_no_target.xls\")\n",
    "\n",
    "df = df.loc[:, df.columns != 'Perform']\n",
    "df = df.loc[:, df.columns != 'Group']\n",
    "\n",
    "\n",
    "df_x = df.loc[:, df.columns != 'Class']\n",
    "df_y = df['Class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_x, df_y, test_size=0.2,shuffle=True, stratify=df_y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "006456f7-eecd-4486-abb2-db0ff3ef51a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = X_train.loc[:, ~X_train.columns.isin(['Group'])].columns.to_list()\n",
    "X_train[numeric_columns] = X_train[numeric_columns].replace(\n",
    "    {\n",
    "        'NA': np.nan, \n",
    "        '': np.nan,\n",
    "        ' ': np.nan\n",
    "    }\n",
    ").astype(float)\n",
    "\n",
    "X_test[numeric_columns] = X_test[numeric_columns].replace(\n",
    "    {\n",
    "        'NA': np.nan, \n",
    "        '': np.nan,\n",
    "        ' ': np.nan\n",
    "    }\n",
    ").astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88066b03-5993-437f-9af7-d0f10d3bf8ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I1</th>\n",
       "      <th>I2</th>\n",
       "      <th>I3</th>\n",
       "      <th>I4</th>\n",
       "      <th>I5</th>\n",
       "      <th>I6</th>\n",
       "      <th>I7</th>\n",
       "      <th>I8</th>\n",
       "      <th>I9</th>\n",
       "      <th>I10</th>\n",
       "      <th>I11</th>\n",
       "      <th>I12</th>\n",
       "      <th>I13</th>\n",
       "      <th>I14</th>\n",
       "      <th>I15</th>\n",
       "      <th>I16</th>\n",
       "      <th>I17</th>\n",
       "      <th>I18</th>\n",
       "      <th>I19</th>\n",
       "      <th>I20</th>\n",
       "      <th>I21</th>\n",
       "      <th>I22</th>\n",
       "      <th>I23</th>\n",
       "      <th>I24</th>\n",
       "      <th>I25</th>\n",
       "      <th>I26</th>\n",
       "      <th>I27</th>\n",
       "      <th>I28</th>\n",
       "      <th>I29</th>\n",
       "      <th>I30</th>\n",
       "      <th>I31</th>\n",
       "      <th>I32</th>\n",
       "      <th>I33</th>\n",
       "      <th>I34</th>\n",
       "      <th>I35</th>\n",
       "      <th>I36</th>\n",
       "      <th>I37</th>\n",
       "      <th>I38</th>\n",
       "      <th>I39</th>\n",
       "      <th>I40</th>\n",
       "      <th>I41</th>\n",
       "      <th>I42</th>\n",
       "      <th>I43</th>\n",
       "      <th>I44</th>\n",
       "      <th>I45</th>\n",
       "      <th>I46</th>\n",
       "      <th>I47</th>\n",
       "      <th>I48</th>\n",
       "      <th>I49</th>\n",
       "      <th>I50</th>\n",
       "      <th>I51</th>\n",
       "      <th>I52</th>\n",
       "      <th>I53</th>\n",
       "      <th>I54</th>\n",
       "      <th>I55</th>\n",
       "      <th>I56</th>\n",
       "      <th>I57</th>\n",
       "      <th>I58</th>\n",
       "      <th>dI1</th>\n",
       "      <th>dI2</th>\n",
       "      <th>dI3</th>\n",
       "      <th>dI4</th>\n",
       "      <th>dI5</th>\n",
       "      <th>dI6</th>\n",
       "      <th>dI7</th>\n",
       "      <th>dI8</th>\n",
       "      <th>dI9</th>\n",
       "      <th>dI10</th>\n",
       "      <th>dI11</th>\n",
       "      <th>dI12</th>\n",
       "      <th>dI13</th>\n",
       "      <th>dI14</th>\n",
       "      <th>dI15</th>\n",
       "      <th>dI16</th>\n",
       "      <th>dI17</th>\n",
       "      <th>dI18</th>\n",
       "      <th>dI19</th>\n",
       "      <th>dI20</th>\n",
       "      <th>dI21</th>\n",
       "      <th>dI22</th>\n",
       "      <th>dI23</th>\n",
       "      <th>dI24</th>\n",
       "      <th>dI25</th>\n",
       "      <th>dI26</th>\n",
       "      <th>dI27</th>\n",
       "      <th>dI28</th>\n",
       "      <th>dI29</th>\n",
       "      <th>dI30</th>\n",
       "      <th>dI31</th>\n",
       "      <th>dI32</th>\n",
       "      <th>dI33</th>\n",
       "      <th>dI34</th>\n",
       "      <th>dI35</th>\n",
       "      <th>dI36</th>\n",
       "      <th>dI37</th>\n",
       "      <th>dI38</th>\n",
       "      <th>dI39</th>\n",
       "      <th>dI40</th>\n",
       "      <th>dI41</th>\n",
       "      <th>dI42</th>\n",
       "      <th>dI43</th>\n",
       "      <th>dI44</th>\n",
       "      <th>dI45</th>\n",
       "      <th>dI46</th>\n",
       "      <th>dI47</th>\n",
       "      <th>dI48</th>\n",
       "      <th>dI49</th>\n",
       "      <th>dI50</th>\n",
       "      <th>dI51</th>\n",
       "      <th>dI52</th>\n",
       "      <th>dI53</th>\n",
       "      <th>dI54</th>\n",
       "      <th>dI55</th>\n",
       "      <th>dI56</th>\n",
       "      <th>dI57</th>\n",
       "      <th>dI58</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7426</th>\n",
       "      <td>0.474336</td>\n",
       "      <td>0.010288</td>\n",
       "      <td>-0.000710</td>\n",
       "      <td>-0.606795</td>\n",
       "      <td>-0.132097</td>\n",
       "      <td>0.227654</td>\n",
       "      <td>0.407601</td>\n",
       "      <td>-0.002148</td>\n",
       "      <td>0.255976</td>\n",
       "      <td>0.010343</td>\n",
       "      <td>0.069800</td>\n",
       "      <td>-0.042908</td>\n",
       "      <td>-0.031332</td>\n",
       "      <td>-0.039776</td>\n",
       "      <td>1.244465</td>\n",
       "      <td>-0.281740</td>\n",
       "      <td>-0.034615</td>\n",
       "      <td>-0.046939</td>\n",
       "      <td>0.046508</td>\n",
       "      <td>-0.189993</td>\n",
       "      <td>-0.042645</td>\n",
       "      <td>-0.201074</td>\n",
       "      <td>-0.061445</td>\n",
       "      <td>-0.044316</td>\n",
       "      <td>-0.571520</td>\n",
       "      <td>-0.145953</td>\n",
       "      <td>2.143646</td>\n",
       "      <td>-0.514716</td>\n",
       "      <td>-0.097087</td>\n",
       "      <td>-0.035054</td>\n",
       "      <td>0.599826</td>\n",
       "      <td>1.021227</td>\n",
       "      <td>1.567838</td>\n",
       "      <td>1.551942</td>\n",
       "      <td>1.468628</td>\n",
       "      <td>1.229721</td>\n",
       "      <td>1.321067</td>\n",
       "      <td>-0.084339</td>\n",
       "      <td>-0.042190</td>\n",
       "      <td>0.476034</td>\n",
       "      <td>0.192107</td>\n",
       "      <td>0.178743</td>\n",
       "      <td>0.425832</td>\n",
       "      <td>0.051295</td>\n",
       "      <td>-1.429454</td>\n",
       "      <td>-0.915034</td>\n",
       "      <td>-0.818222</td>\n",
       "      <td>-0.859571</td>\n",
       "      <td>-0.831964</td>\n",
       "      <td>-0.737321</td>\n",
       "      <td>-0.953812</td>\n",
       "      <td>-0.423662</td>\n",
       "      <td>0.167951</td>\n",
       "      <td>0.982461</td>\n",
       "      <td>1.507053</td>\n",
       "      <td>-0.872424</td>\n",
       "      <td>-0.117816</td>\n",
       "      <td>-0.031497</td>\n",
       "      <td>-0.008751</td>\n",
       "      <td>0.009108</td>\n",
       "      <td>0.008876</td>\n",
       "      <td>-0.008488</td>\n",
       "      <td>-0.122003</td>\n",
       "      <td>-0.150909</td>\n",
       "      <td>-0.168123</td>\n",
       "      <td>0.007286</td>\n",
       "      <td>-0.143467</td>\n",
       "      <td>0.005262</td>\n",
       "      <td>-0.017017</td>\n",
       "      <td>-0.045596</td>\n",
       "      <td>0.007570</td>\n",
       "      <td>0.026585</td>\n",
       "      <td>-0.414900</td>\n",
       "      <td>-0.012459</td>\n",
       "      <td>0.012176</td>\n",
       "      <td>-0.000270</td>\n",
       "      <td>0.020325</td>\n",
       "      <td>-0.037350</td>\n",
       "      <td>0.034140</td>\n",
       "      <td>0.004292</td>\n",
       "      <td>0.000737</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.036921</td>\n",
       "      <td>-0.025854</td>\n",
       "      <td>0.210788</td>\n",
       "      <td>0.002333</td>\n",
       "      <td>-0.046517</td>\n",
       "      <td>-0.028944</td>\n",
       "      <td>-0.756167</td>\n",
       "      <td>-0.166527</td>\n",
       "      <td>-0.281711</td>\n",
       "      <td>-0.278719</td>\n",
       "      <td>-0.292282</td>\n",
       "      <td>-0.167453</td>\n",
       "      <td>-0.215679</td>\n",
       "      <td>-0.088958</td>\n",
       "      <td>-0.036857</td>\n",
       "      <td>-0.895317</td>\n",
       "      <td>0.229733</td>\n",
       "      <td>0.222789</td>\n",
       "      <td>0.529174</td>\n",
       "      <td>0.039070</td>\n",
       "      <td>0.005165</td>\n",
       "      <td>0.065233</td>\n",
       "      <td>0.024111</td>\n",
       "      <td>-0.003079</td>\n",
       "      <td>-0.040331</td>\n",
       "      <td>-0.037055</td>\n",
       "      <td>-0.049063</td>\n",
       "      <td>0.009558</td>\n",
       "      <td>-0.000408</td>\n",
       "      <td>-0.016245</td>\n",
       "      <td>-0.044080</td>\n",
       "      <td>0.118029</td>\n",
       "      <td>-0.006498</td>\n",
       "      <td>-0.015567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4264</th>\n",
       "      <td>0.735381</td>\n",
       "      <td>-0.019519</td>\n",
       "      <td>-0.029400</td>\n",
       "      <td>1.373814</td>\n",
       "      <td>-0.242825</td>\n",
       "      <td>0.006498</td>\n",
       "      <td>-0.218154</td>\n",
       "      <td>-0.029641</td>\n",
       "      <td>1.226153</td>\n",
       "      <td>-0.014224</td>\n",
       "      <td>0.696016</td>\n",
       "      <td>0.219364</td>\n",
       "      <td>-0.037933</td>\n",
       "      <td>0.711385</td>\n",
       "      <td>0.669523</td>\n",
       "      <td>-0.165935</td>\n",
       "      <td>-0.110332</td>\n",
       "      <td>-0.044059</td>\n",
       "      <td>-0.110881</td>\n",
       "      <td>0.283741</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006747</td>\n",
       "      <td>-0.100089</td>\n",
       "      <td>-0.088502</td>\n",
       "      <td>0.737501</td>\n",
       "      <td>-0.100008</td>\n",
       "      <td>0.507143</td>\n",
       "      <td>1.584636</td>\n",
       "      <td>-0.123937</td>\n",
       "      <td>-0.048261</td>\n",
       "      <td>-0.549628</td>\n",
       "      <td>-0.592205</td>\n",
       "      <td>-0.239093</td>\n",
       "      <td>-0.235795</td>\n",
       "      <td>-0.505718</td>\n",
       "      <td>-0.186124</td>\n",
       "      <td>-0.501709</td>\n",
       "      <td>-0.046078</td>\n",
       "      <td>-0.036884</td>\n",
       "      <td>-0.457416</td>\n",
       "      <td>0.115378</td>\n",
       "      <td>0.104334</td>\n",
       "      <td>0.187516</td>\n",
       "      <td>0.077230</td>\n",
       "      <td>0.179328</td>\n",
       "      <td>-0.317715</td>\n",
       "      <td>0.771000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.230770</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.487625</td>\n",
       "      <td>0.532675</td>\n",
       "      <td>-0.113977</td>\n",
       "      <td>-0.502087</td>\n",
       "      <td>-0.072377</td>\n",
       "      <td>-0.530395</td>\n",
       "      <td>-0.119678</td>\n",
       "      <td>-0.035370</td>\n",
       "      <td>-0.020779</td>\n",
       "      <td>-0.001515</td>\n",
       "      <td>-0.001271</td>\n",
       "      <td>0.566549</td>\n",
       "      <td>0.112948</td>\n",
       "      <td>0.148753</td>\n",
       "      <td>0.146571</td>\n",
       "      <td>0.010503</td>\n",
       "      <td>0.791676</td>\n",
       "      <td>-0.004064</td>\n",
       "      <td>0.011731</td>\n",
       "      <td>0.351006</td>\n",
       "      <td>0.012634</td>\n",
       "      <td>-0.178190</td>\n",
       "      <td>0.477856</td>\n",
       "      <td>0.039291</td>\n",
       "      <td>-0.003576</td>\n",
       "      <td>0.001576</td>\n",
       "      <td>-0.013169</td>\n",
       "      <td>0.026280</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002315</td>\n",
       "      <td>-0.000972</td>\n",
       "      <td>-0.001111</td>\n",
       "      <td>-0.055436</td>\n",
       "      <td>-0.005346</td>\n",
       "      <td>-0.177226</td>\n",
       "      <td>-0.033158</td>\n",
       "      <td>0.017723</td>\n",
       "      <td>0.011541</td>\n",
       "      <td>0.098352</td>\n",
       "      <td>0.119397</td>\n",
       "      <td>0.039128</td>\n",
       "      <td>0.038712</td>\n",
       "      <td>0.037939</td>\n",
       "      <td>0.013403</td>\n",
       "      <td>0.017530</td>\n",
       "      <td>0.045437</td>\n",
       "      <td>0.016490</td>\n",
       "      <td>0.133769</td>\n",
       "      <td>-0.149494</td>\n",
       "      <td>-0.144975</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.077788</td>\n",
       "      <td>0.149001</td>\n",
       "      <td>-0.015912</td>\n",
       "      <td>0.704333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.135784</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.193875</td>\n",
       "      <td>0.478701</td>\n",
       "      <td>-0.024174</td>\n",
       "      <td>-0.148020</td>\n",
       "      <td>-0.161484</td>\n",
       "      <td>-0.100311</td>\n",
       "      <td>0.069675</td>\n",
       "      <td>-0.004375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5670</th>\n",
       "      <td>0.150030</td>\n",
       "      <td>-0.030559</td>\n",
       "      <td>-0.041371</td>\n",
       "      <td>-0.180490</td>\n",
       "      <td>0.023586</td>\n",
       "      <td>-0.143670</td>\n",
       "      <td>-0.301218</td>\n",
       "      <td>-0.039838</td>\n",
       "      <td>0.782315</td>\n",
       "      <td>-0.021184</td>\n",
       "      <td>-0.104858</td>\n",
       "      <td>0.603132</td>\n",
       "      <td>-0.063976</td>\n",
       "      <td>0.786947</td>\n",
       "      <td>0.997630</td>\n",
       "      <td>-0.155514</td>\n",
       "      <td>-0.070871</td>\n",
       "      <td>-0.045427</td>\n",
       "      <td>-0.083950</td>\n",
       "      <td>0.062908</td>\n",
       "      <td>-0.163518</td>\n",
       "      <td>-0.015327</td>\n",
       "      <td>-0.072948</td>\n",
       "      <td>-0.057468</td>\n",
       "      <td>0.767850</td>\n",
       "      <td>0.173958</td>\n",
       "      <td>-0.128118</td>\n",
       "      <td>-0.310119</td>\n",
       "      <td>-0.164138</td>\n",
       "      <td>-0.079906</td>\n",
       "      <td>-0.883528</td>\n",
       "      <td>-1.344381</td>\n",
       "      <td>-0.716429</td>\n",
       "      <td>-0.708061</td>\n",
       "      <td>-0.897027</td>\n",
       "      <td>-0.443576</td>\n",
       "      <td>-0.724724</td>\n",
       "      <td>-0.170219</td>\n",
       "      <td>-0.079356</td>\n",
       "      <td>-0.867710</td>\n",
       "      <td>0.626772</td>\n",
       "      <td>0.600270</td>\n",
       "      <td>0.559442</td>\n",
       "      <td>-0.010800</td>\n",
       "      <td>0.906108</td>\n",
       "      <td>-0.712064</td>\n",
       "      <td>0.854778</td>\n",
       "      <td>1.128683</td>\n",
       "      <td>1.737216</td>\n",
       "      <td>1.107266</td>\n",
       "      <td>1.701688</td>\n",
       "      <td>1.132818</td>\n",
       "      <td>-0.104753</td>\n",
       "      <td>-0.537718</td>\n",
       "      <td>0.410211</td>\n",
       "      <td>0.797962</td>\n",
       "      <td>-0.112652</td>\n",
       "      <td>-0.057491</td>\n",
       "      <td>-1.246969</td>\n",
       "      <td>-0.017840</td>\n",
       "      <td>-0.014250</td>\n",
       "      <td>-0.627947</td>\n",
       "      <td>0.082116</td>\n",
       "      <td>-0.027240</td>\n",
       "      <td>0.043286</td>\n",
       "      <td>-0.003879</td>\n",
       "      <td>-0.281142</td>\n",
       "      <td>-0.029354</td>\n",
       "      <td>-1.055325</td>\n",
       "      <td>0.657791</td>\n",
       "      <td>0.038651</td>\n",
       "      <td>-0.156749</td>\n",
       "      <td>-0.189418</td>\n",
       "      <td>0.051770</td>\n",
       "      <td>0.036775</td>\n",
       "      <td>-0.000911</td>\n",
       "      <td>0.020150</td>\n",
       "      <td>-0.690801</td>\n",
       "      <td>-0.011164</td>\n",
       "      <td>-0.048206</td>\n",
       "      <td>-0.008495</td>\n",
       "      <td>-0.009713</td>\n",
       "      <td>-0.455277</td>\n",
       "      <td>0.046544</td>\n",
       "      <td>-0.364856</td>\n",
       "      <td>-0.055686</td>\n",
       "      <td>0.034768</td>\n",
       "      <td>0.016951</td>\n",
       "      <td>0.031098</td>\n",
       "      <td>-0.228416</td>\n",
       "      <td>-0.394980</td>\n",
       "      <td>-0.390785</td>\n",
       "      <td>-0.315390</td>\n",
       "      <td>-0.323573</td>\n",
       "      <td>-0.280804</td>\n",
       "      <td>0.043982</td>\n",
       "      <td>0.018647</td>\n",
       "      <td>0.038100</td>\n",
       "      <td>-1.159936</td>\n",
       "      <td>-1.124875</td>\n",
       "      <td>0.182791</td>\n",
       "      <td>-0.007366</td>\n",
       "      <td>-0.049387</td>\n",
       "      <td>-0.078541</td>\n",
       "      <td>0.660222</td>\n",
       "      <td>-0.383559</td>\n",
       "      <td>0.192662</td>\n",
       "      <td>0.380037</td>\n",
       "      <td>0.006750</td>\n",
       "      <td>0.726753</td>\n",
       "      <td>-0.008247</td>\n",
       "      <td>0.087142</td>\n",
       "      <td>0.101860</td>\n",
       "      <td>-0.054802</td>\n",
       "      <td>-0.133887</td>\n",
       "      <td>0.001193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2110</th>\n",
       "      <td>-0.392277</td>\n",
       "      <td>-0.036396</td>\n",
       "      <td>-0.017427</td>\n",
       "      <td>0.000440</td>\n",
       "      <td>0.194470</td>\n",
       "      <td>0.427458</td>\n",
       "      <td>0.290762</td>\n",
       "      <td>-0.039829</td>\n",
       "      <td>-0.240505</td>\n",
       "      <td>-0.022131</td>\n",
       "      <td>-0.481441</td>\n",
       "      <td>1.195059</td>\n",
       "      <td>-0.133470</td>\n",
       "      <td>0.360923</td>\n",
       "      <td>0.753503</td>\n",
       "      <td>-0.114618</td>\n",
       "      <td>-0.059685</td>\n",
       "      <td>-0.046232</td>\n",
       "      <td>-0.002248</td>\n",
       "      <td>0.065763</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.221062</td>\n",
       "      <td>-0.119099</td>\n",
       "      <td>-0.110237</td>\n",
       "      <td>-0.664177</td>\n",
       "      <td>0.052724</td>\n",
       "      <td>-0.336943</td>\n",
       "      <td>0.021138</td>\n",
       "      <td>-0.160624</td>\n",
       "      <td>-0.099285</td>\n",
       "      <td>-0.440708</td>\n",
       "      <td>0.383819</td>\n",
       "      <td>0.641210</td>\n",
       "      <td>0.635158</td>\n",
       "      <td>2.653875</td>\n",
       "      <td>0.184460</td>\n",
       "      <td>2.560986</td>\n",
       "      <td>-0.241563</td>\n",
       "      <td>-0.109047</td>\n",
       "      <td>-0.653331</td>\n",
       "      <td>0.699936</td>\n",
       "      <td>0.671222</td>\n",
       "      <td>-1.033898</td>\n",
       "      <td>-0.016909</td>\n",
       "      <td>-0.901262</td>\n",
       "      <td>-1.001319</td>\n",
       "      <td>-0.371000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.127813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.241250</td>\n",
       "      <td>0.242688</td>\n",
       "      <td>-0.002609</td>\n",
       "      <td>0.139621</td>\n",
       "      <td>1.329443</td>\n",
       "      <td>2.329796</td>\n",
       "      <td>0.123187</td>\n",
       "      <td>-0.060640</td>\n",
       "      <td>-0.201366</td>\n",
       "      <td>-0.004628</td>\n",
       "      <td>-0.008292</td>\n",
       "      <td>-0.039354</td>\n",
       "      <td>-0.068543</td>\n",
       "      <td>0.074813</td>\n",
       "      <td>0.130321</td>\n",
       "      <td>-0.000238</td>\n",
       "      <td>0.128159</td>\n",
       "      <td>-0.007429</td>\n",
       "      <td>-0.154127</td>\n",
       "      <td>4.104377</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.260225</td>\n",
       "      <td>0.465077</td>\n",
       "      <td>0.126900</td>\n",
       "      <td>-0.000810</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>-0.009085</td>\n",
       "      <td>-0.026615</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000076</td>\n",
       "      <td>-0.000358</td>\n",
       "      <td>0.000831</td>\n",
       "      <td>-0.022250</td>\n",
       "      <td>-0.034998</td>\n",
       "      <td>-0.308995</td>\n",
       "      <td>-0.103373</td>\n",
       "      <td>-0.001026</td>\n",
       "      <td>-0.002704</td>\n",
       "      <td>-0.091684</td>\n",
       "      <td>-0.075261</td>\n",
       "      <td>-0.258189</td>\n",
       "      <td>-0.255447</td>\n",
       "      <td>-0.126716</td>\n",
       "      <td>-0.276211</td>\n",
       "      <td>-0.155800</td>\n",
       "      <td>-0.006981</td>\n",
       "      <td>-0.003381</td>\n",
       "      <td>-0.101877</td>\n",
       "      <td>-0.032694</td>\n",
       "      <td>-0.031706</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.012951</td>\n",
       "      <td>0.167433</td>\n",
       "      <td>-0.029549</td>\n",
       "      <td>0.353778</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.336252</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.227687</td>\n",
       "      <td>0.519870</td>\n",
       "      <td>-0.019833</td>\n",
       "      <td>-0.040847</td>\n",
       "      <td>-0.052477</td>\n",
       "      <td>1.004543</td>\n",
       "      <td>-0.061889</td>\n",
       "      <td>-0.005486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2116</th>\n",
       "      <td>-0.826989</td>\n",
       "      <td>-0.041629</td>\n",
       "      <td>-0.046757</td>\n",
       "      <td>-0.905674</td>\n",
       "      <td>0.165526</td>\n",
       "      <td>-0.942051</td>\n",
       "      <td>0.391674</td>\n",
       "      <td>-0.050908</td>\n",
       "      <td>-0.869245</td>\n",
       "      <td>-0.040587</td>\n",
       "      <td>-0.942128</td>\n",
       "      <td>-1.920122</td>\n",
       "      <td>0.109571</td>\n",
       "      <td>-0.295938</td>\n",
       "      <td>-0.482493</td>\n",
       "      <td>-0.302145</td>\n",
       "      <td>0.150220</td>\n",
       "      <td>-0.048025</td>\n",
       "      <td>0.346086</td>\n",
       "      <td>-0.710210</td>\n",
       "      <td>0.268111</td>\n",
       "      <td>-0.243370</td>\n",
       "      <td>-0.101431</td>\n",
       "      <td>-0.101193</td>\n",
       "      <td>-0.887292</td>\n",
       "      <td>-0.111807</td>\n",
       "      <td>0.080874</td>\n",
       "      <td>-0.527018</td>\n",
       "      <td>0.058842</td>\n",
       "      <td>0.002634</td>\n",
       "      <td>0.692140</td>\n",
       "      <td>0.591906</td>\n",
       "      <td>0.089524</td>\n",
       "      <td>0.089332</td>\n",
       "      <td>0.645773</td>\n",
       "      <td>-0.197195</td>\n",
       "      <td>0.443340</td>\n",
       "      <td>-0.100691</td>\n",
       "      <td>-0.055519</td>\n",
       "      <td>-0.113597</td>\n",
       "      <td>-0.179029</td>\n",
       "      <td>-0.461493</td>\n",
       "      <td>0.674174</td>\n",
       "      <td>-0.022750</td>\n",
       "      <td>-1.457341</td>\n",
       "      <td>-0.498530</td>\n",
       "      <td>-0.956111</td>\n",
       "      <td>-0.924697</td>\n",
       "      <td>-1.034101</td>\n",
       "      <td>-0.916229</td>\n",
       "      <td>-1.340563</td>\n",
       "      <td>-0.615273</td>\n",
       "      <td>0.028934</td>\n",
       "      <td>0.375269</td>\n",
       "      <td>0.591471</td>\n",
       "      <td>0.527293</td>\n",
       "      <td>-0.159744</td>\n",
       "      <td>-0.047051</td>\n",
       "      <td>-0.277401</td>\n",
       "      <td>-0.005865</td>\n",
       "      <td>-0.000638</td>\n",
       "      <td>-0.025115</td>\n",
       "      <td>0.030998</td>\n",
       "      <td>0.254083</td>\n",
       "      <td>0.314438</td>\n",
       "      <td>0.002076</td>\n",
       "      <td>-0.007482</td>\n",
       "      <td>-0.009609</td>\n",
       "      <td>-0.051676</td>\n",
       "      <td>-0.920798</td>\n",
       "      <td>0.125177</td>\n",
       "      <td>-0.170878</td>\n",
       "      <td>-0.094073</td>\n",
       "      <td>-0.004514</td>\n",
       "      <td>0.070196</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.115591</td>\n",
       "      <td>-0.187369</td>\n",
       "      <td>-0.197957</td>\n",
       "      <td>-0.014884</td>\n",
       "      <td>-0.013678</td>\n",
       "      <td>-0.015323</td>\n",
       "      <td>-0.098531</td>\n",
       "      <td>0.060141</td>\n",
       "      <td>-0.458352</td>\n",
       "      <td>-0.005823</td>\n",
       "      <td>0.060331</td>\n",
       "      <td>0.022833</td>\n",
       "      <td>0.580822</td>\n",
       "      <td>0.380013</td>\n",
       "      <td>0.235347</td>\n",
       "      <td>0.232847</td>\n",
       "      <td>0.416106</td>\n",
       "      <td>-0.428854</td>\n",
       "      <td>-0.192951</td>\n",
       "      <td>0.042064</td>\n",
       "      <td>-0.001595</td>\n",
       "      <td>0.154025</td>\n",
       "      <td>-0.323833</td>\n",
       "      <td>-0.594364</td>\n",
       "      <td>0.129474</td>\n",
       "      <td>-0.047782</td>\n",
       "      <td>-0.026050</td>\n",
       "      <td>0.222922</td>\n",
       "      <td>-0.022889</td>\n",
       "      <td>0.003734</td>\n",
       "      <td>-0.097475</td>\n",
       "      <td>-0.119853</td>\n",
       "      <td>-0.220500</td>\n",
       "      <td>-0.030727</td>\n",
       "      <td>0.039075</td>\n",
       "      <td>0.105650</td>\n",
       "      <td>0.332904</td>\n",
       "      <td>0.011538</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>-0.004688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            I1        I2        I3        I4        I5        I6        I7  \\\n",
       "7426  0.474336  0.010288 -0.000710 -0.606795 -0.132097  0.227654  0.407601   \n",
       "4264  0.735381 -0.019519 -0.029400  1.373814 -0.242825  0.006498 -0.218154   \n",
       "5670  0.150030 -0.030559 -0.041371 -0.180490  0.023586 -0.143670 -0.301218   \n",
       "2110 -0.392277 -0.036396 -0.017427  0.000440  0.194470  0.427458  0.290762   \n",
       "2116 -0.826989 -0.041629 -0.046757 -0.905674  0.165526 -0.942051  0.391674   \n",
       "\n",
       "            I8        I9       I10       I11       I12       I13       I14  \\\n",
       "7426 -0.002148  0.255976  0.010343  0.069800 -0.042908 -0.031332 -0.039776   \n",
       "4264 -0.029641  1.226153 -0.014224  0.696016  0.219364 -0.037933  0.711385   \n",
       "5670 -0.039838  0.782315 -0.021184 -0.104858  0.603132 -0.063976  0.786947   \n",
       "2110 -0.039829 -0.240505 -0.022131 -0.481441  1.195059 -0.133470  0.360923   \n",
       "2116 -0.050908 -0.869245 -0.040587 -0.942128 -1.920122  0.109571 -0.295938   \n",
       "\n",
       "           I15       I16       I17       I18       I19       I20       I21  \\\n",
       "7426  1.244465 -0.281740 -0.034615 -0.046939  0.046508 -0.189993 -0.042645   \n",
       "4264  0.669523 -0.165935 -0.110332 -0.044059 -0.110881  0.283741       NaN   \n",
       "5670  0.997630 -0.155514 -0.070871 -0.045427 -0.083950  0.062908 -0.163518   \n",
       "2110  0.753503 -0.114618 -0.059685 -0.046232 -0.002248  0.065763       NaN   \n",
       "2116 -0.482493 -0.302145  0.150220 -0.048025  0.346086 -0.710210  0.268111   \n",
       "\n",
       "           I22       I23       I24       I25       I26       I27       I28  \\\n",
       "7426 -0.201074 -0.061445 -0.044316 -0.571520 -0.145953  2.143646 -0.514716   \n",
       "4264  0.006747 -0.100089 -0.088502  0.737501 -0.100008  0.507143  1.584636   \n",
       "5670 -0.015327 -0.072948 -0.057468  0.767850  0.173958 -0.128118 -0.310119   \n",
       "2110 -0.221062 -0.119099 -0.110237 -0.664177  0.052724 -0.336943  0.021138   \n",
       "2116 -0.243370 -0.101431 -0.101193 -0.887292 -0.111807  0.080874 -0.527018   \n",
       "\n",
       "           I29       I30       I31       I32       I33       I34       I35  \\\n",
       "7426 -0.097087 -0.035054  0.599826  1.021227  1.567838  1.551942  1.468628   \n",
       "4264 -0.123937 -0.048261 -0.549628 -0.592205 -0.239093 -0.235795 -0.505718   \n",
       "5670 -0.164138 -0.079906 -0.883528 -1.344381 -0.716429 -0.708061 -0.897027   \n",
       "2110 -0.160624 -0.099285 -0.440708  0.383819  0.641210  0.635158  2.653875   \n",
       "2116  0.058842  0.002634  0.692140  0.591906  0.089524  0.089332  0.645773   \n",
       "\n",
       "           I36       I37       I38       I39       I40       I41       I42  \\\n",
       "7426  1.229721  1.321067 -0.084339 -0.042190  0.476034  0.192107  0.178743   \n",
       "4264 -0.186124 -0.501709 -0.046078 -0.036884 -0.457416  0.115378  0.104334   \n",
       "5670 -0.443576 -0.724724 -0.170219 -0.079356 -0.867710  0.626772  0.600270   \n",
       "2110  0.184460  2.560986 -0.241563 -0.109047 -0.653331  0.699936  0.671222   \n",
       "2116 -0.197195  0.443340 -0.100691 -0.055519 -0.113597 -0.179029 -0.461493   \n",
       "\n",
       "           I43       I44       I45       I46       I47       I48       I49  \\\n",
       "7426  0.425832  0.051295 -1.429454 -0.915034 -0.818222 -0.859571 -0.831964   \n",
       "4264  0.187516  0.077230  0.179328 -0.317715  0.771000       NaN  0.230770   \n",
       "5670  0.559442 -0.010800  0.906108 -0.712064  0.854778  1.128683  1.737216   \n",
       "2110 -1.033898 -0.016909 -0.901262 -1.001319 -0.371000       NaN  0.127813   \n",
       "2116  0.674174 -0.022750 -1.457341 -0.498530 -0.956111 -0.924697 -1.034101   \n",
       "\n",
       "           I50       I51       I52       I53       I54       I55       I56  \\\n",
       "7426 -0.737321 -0.953812 -0.423662  0.167951  0.982461  1.507053 -0.872424   \n",
       "4264       NaN  0.487625  0.532675 -0.113977 -0.502087 -0.072377 -0.530395   \n",
       "5670  1.107266  1.701688  1.132818 -0.104753 -0.537718  0.410211  0.797962   \n",
       "2110       NaN -0.241250  0.242688 -0.002609  0.139621  1.329443  2.329796   \n",
       "2116 -0.916229 -1.340563 -0.615273  0.028934  0.375269  0.591471  0.527293   \n",
       "\n",
       "           I57       I58       dI1       dI2       dI3       dI4       dI5  \\\n",
       "7426 -0.117816 -0.031497 -0.008751  0.009108  0.008876 -0.008488 -0.122003   \n",
       "4264 -0.119678 -0.035370 -0.020779 -0.001515 -0.001271  0.566549  0.112948   \n",
       "5670 -0.112652 -0.057491 -1.246969 -0.017840 -0.014250 -0.627947  0.082116   \n",
       "2110  0.123187 -0.060640 -0.201366 -0.004628 -0.008292 -0.039354 -0.068543   \n",
       "2116 -0.159744 -0.047051 -0.277401 -0.005865 -0.000638 -0.025115  0.030998   \n",
       "\n",
       "           dI6       dI7       dI8       dI9      dI10      dI11      dI12  \\\n",
       "7426 -0.150909 -0.168123  0.007286 -0.143467  0.005262 -0.017017 -0.045596   \n",
       "4264  0.148753  0.146571  0.010503  0.791676 -0.004064  0.011731  0.351006   \n",
       "5670 -0.027240  0.043286 -0.003879 -0.281142 -0.029354 -1.055325  0.657791   \n",
       "2110  0.074813  0.130321 -0.000238  0.128159 -0.007429 -0.154127  4.104377   \n",
       "2116  0.254083  0.314438  0.002076 -0.007482 -0.009609 -0.051676 -0.920798   \n",
       "\n",
       "          dI13      dI14      dI15      dI16      dI17      dI18      dI19  \\\n",
       "7426  0.007570  0.026585 -0.414900 -0.012459  0.012176 -0.000270  0.020325   \n",
       "4264  0.012634 -0.178190  0.477856  0.039291 -0.003576  0.001576 -0.013169   \n",
       "5670  0.038651 -0.156749 -0.189418  0.051770  0.036775 -0.000911  0.020150   \n",
       "2110  0.000000 -0.260225  0.465077  0.126900 -0.000810  0.000136 -0.009085   \n",
       "2116  0.125177 -0.170878 -0.094073 -0.004514  0.070196  0.000679  0.115591   \n",
       "\n",
       "          dI20      dI21      dI22      dI23      dI24      dI25      dI26  \\\n",
       "7426 -0.037350  0.034140  0.004292  0.000737  0.000842  0.036921 -0.025854   \n",
       "4264  0.026280       NaN  0.002315 -0.000972 -0.001111 -0.055436 -0.005346   \n",
       "5670 -0.690801 -0.011164 -0.048206 -0.008495 -0.009713 -0.455277  0.046544   \n",
       "2110 -0.026615       NaN -0.000076 -0.000358  0.000831 -0.022250 -0.034998   \n",
       "2116 -0.187369 -0.197957 -0.014884 -0.013678 -0.015323 -0.098531  0.060141   \n",
       "\n",
       "          dI27      dI28      dI29      dI30      dI31      dI32      dI33  \\\n",
       "7426  0.210788  0.002333 -0.046517 -0.028944 -0.756167 -0.166527 -0.281711   \n",
       "4264 -0.177226 -0.033158  0.017723  0.011541  0.098352  0.119397  0.039128   \n",
       "5670 -0.364856 -0.055686  0.034768  0.016951  0.031098 -0.228416 -0.394980   \n",
       "2110 -0.308995 -0.103373 -0.001026 -0.002704 -0.091684 -0.075261 -0.258189   \n",
       "2116 -0.458352 -0.005823  0.060331  0.022833  0.580822  0.380013  0.235347   \n",
       "\n",
       "          dI34      dI35      dI36      dI37      dI38      dI39      dI40  \\\n",
       "7426 -0.278719 -0.292282 -0.167453 -0.215679 -0.088958 -0.036857 -0.895317   \n",
       "4264  0.038712  0.037939  0.013403  0.017530  0.045437  0.016490  0.133769   \n",
       "5670 -0.390785 -0.315390 -0.323573 -0.280804  0.043982  0.018647  0.038100   \n",
       "2110 -0.255447 -0.126716 -0.276211 -0.155800 -0.006981 -0.003381 -0.101877   \n",
       "2116  0.232847  0.416106 -0.428854 -0.192951  0.042064 -0.001595  0.154025   \n",
       "\n",
       "          dI41      dI42      dI43      dI44      dI45      dI46      dI47  \\\n",
       "7426  0.229733  0.222789  0.529174  0.039070  0.005165  0.065233  0.024111   \n",
       "4264 -0.149494 -0.144975       NaN  0.077788  0.149001 -0.015912  0.704333   \n",
       "5670 -1.159936 -1.124875  0.182791 -0.007366 -0.049387 -0.078541  0.660222   \n",
       "2110 -0.032694 -0.031706  0.000000 -0.012951  0.167433 -0.029549  0.353778   \n",
       "2116 -0.323833 -0.594364  0.129474 -0.047782 -0.026050  0.222922 -0.022889   \n",
       "\n",
       "          dI48      dI49      dI50      dI51      dI52      dI53      dI54  \\\n",
       "7426 -0.003079 -0.040331 -0.037055 -0.049063  0.009558 -0.000408 -0.016245   \n",
       "4264       NaN  0.135784       NaN  0.193875  0.478701 -0.024174 -0.148020   \n",
       "5670 -0.383559  0.192662  0.380037  0.006750  0.726753 -0.008247  0.087142   \n",
       "2110       NaN  0.336252       NaN  0.227687  0.519870 -0.019833 -0.040847   \n",
       "2116  0.003734 -0.097475 -0.119853 -0.220500 -0.030727  0.039075  0.105650   \n",
       "\n",
       "          dI55      dI56      dI57      dI58  \n",
       "7426 -0.044080  0.118029 -0.006498 -0.015567  \n",
       "4264 -0.161484 -0.100311  0.069675 -0.004375  \n",
       "5670  0.101860 -0.054802 -0.133887  0.001193  \n",
       "2110 -0.052477  1.004543 -0.061889 -0.005486  \n",
       "2116  0.332904  0.011538  0.000010 -0.004688  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bc0384-cbe0-44f2-8213-eb9593d584ad",
   "metadata": {},
   "source": [
    "## Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aecc89f2-c2ee-4ea5-8684-821d96bb9233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6400, 116)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1852d5c1-cd68-4fb6-a691-4436538012a3",
   "metadata": {},
   "source": [
    "# Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "346abda1-a979-431a-b6a2-0219de1a8b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_estimators = [\n",
    "    ('RandomForest', RandomForestClassifier(random_state=0)),\n",
    "    ('DecisionTree', DecisionTreeClassifier(random_state=0)),\n",
    "    ('SVM', SVC(random_state=0, probability=True)),\n",
    "    ('NaiveBayes', GaussianNB()),\n",
    "    ('KNN', KNeighborsClassifier()),\n",
    "    ('LogisticRegression', LogisticRegression(random_state=0, solver=\"saga\", max_iter=1000)),\n",
    "    ('AdaBoost', AdaBoostClassifier(random_state=0, algorithm='SAMME')),\n",
    "    ('GradientBoost', GradientBoostingClassifier(random_state=0)),\n",
    "    ('XGBoost', XGBClassifier(seed=0)),\n",
    "    ('NeuralNetwork', MLPClassifier(random_state=0, max_iter=1000)) #hidden_layer_sizes=(20,20) for 2 hidden layers with 20 neurons each\n",
    "]\n",
    "\n",
    "vote_model = VotingClassifier(\n",
    "    estimators=voting_estimators, \n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "stacking_estimators = [\n",
    "    ('RandomForest', RandomForestClassifier(random_state=0)),\n",
    "    ('DecisionTree', DecisionTreeClassifier(random_state=0)),\n",
    "    ('SVM', SVC(random_state=0, probability=True)),\n",
    "    ('NaiveBayes', GaussianNB()),\n",
    "    ('KNN', KNeighborsClassifier()),\n",
    "    ('AdaBoost', AdaBoostClassifier(random_state=0, algorithm='SAMME')),\n",
    "    ('GradientBoost', GradientBoostingClassifier(random_state=0)),\n",
    "    ('XGBoost', XGBClassifier(seed=0)),\n",
    "    ('NeuralNetwork', MLPClassifier(random_state=0, max_iter=1000))\n",
    "]\n",
    "meta_stack_classifier = LogisticRegression(random_state=0, solver=\"saga\", max_iter=1000)\n",
    "\n",
    "stacking_model = StackingClassifier(\n",
    "    estimators=stacking_estimators, \n",
    "    final_estimator=meta_stack_classifier, \n",
    "    cv=5\n",
    ")\n",
    "\n",
    "estimators = [\n",
    "    ('RandomForest', RandomForestClassifier(random_state=0)),\n",
    "    #('DecisionTree', DecisionTreeClassifier(random_state=0)),\n",
    "    ('SVM', SVC(random_state=0, probability=True)),\n",
    "    #('NaiveBayes', GaussianNB()),\n",
    "    #('KNN', KNeighborsClassifier()),\n",
    "    ('LogisticRegression', LogisticRegression(random_state=0, solver=\"saga\", max_iter=1000)),\n",
    "    ('GradientBoost', GradientBoostingClassifier(random_state=0)),\n",
    "    ('XGBoost', XGBClassifier(seed=0)),\n",
    "    ('AdaBoost', AdaBoostClassifier(random_state=0, algorithm='SAMME'))\n",
    "    #('Voting', vote_model),\n",
    "    #('Stacking', stacking_model),\n",
    "    #('NeuralNetwork', MLPClassifier(random_state=0, max_iter=1000)) # 2 hidden layers with 20 neurons each\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3b2aa3-2279-4c45-be46-3fa5b9668c35",
   "metadata": {},
   "source": [
    "# Create Pipeline with different combination of preprocessing steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7665f57b-10f3-482f-b28b-1b4fc3a5b25e",
   "metadata": {},
   "source": [
    "## Combination 3\n",
    "#### median imputation, remove outliers with LOF, Smote oversampling, standard scaling, Remove Highly Correlated Features, RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d91f42e-aedb-4430-b6dc-fedea5e7ff89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns removed:  ['I3']\n",
      "columns removed:  ['I7']\n",
      "columns removed:  ['I8']\n",
      "columns removed:  ['I9']\n",
      "columns removed:  ['I10']\n",
      "columns removed:  ['I11']\n",
      "columns removed:  ['I19']\n",
      "columns removed:  ['I20']\n",
      "columns removed:  ['I24']\n",
      "columns removed:  ['I25']\n",
      "columns removed:  ['I31']\n",
      "columns removed:  ['I34']\n",
      "columns removed:  ['I35']\n",
      "columns removed:  ['I36']\n",
      "columns removed:  ['I37']\n",
      "columns removed:  ['I38']\n",
      "columns removed:  ['I39']\n",
      "columns removed:  ['I40']\n",
      "columns removed:  ['I42']\n",
      "columns removed:  ['I50']\n",
      "columns removed:  ['I51']\n",
      "columns removed:  ['I52']\n",
      "columns removed:  ['dI3']\n",
      "columns removed:  ['dI5']\n",
      "columns removed:  ['dI7']\n",
      "columns removed:  ['dI8']\n",
      "columns removed:  ['dI10']\n",
      "columns removed:  ['dI11']\n",
      "columns removed:  ['dI15']\n",
      "columns removed:  ['dI19']\n",
      "columns removed:  ['dI20']\n",
      "columns removed:  ['dI24']\n",
      "columns removed:  ['dI33']\n",
      "columns removed:  ['dI34']\n",
      "columns removed:  ['dI36']\n",
      "columns removed:  ['dI37']\n",
      "columns removed:  ['dI39']\n",
      "columns removed:  ['dI40']\n",
      "columns removed:  ['dI42']\n",
      "columns removed:  ['dI44']\n",
      "columns removed:  ['dI50']\n",
      "columns removed:  ['dI51']\n",
      "columns removed:  ['dI52']\n"
     ]
    }
   ],
   "source": [
    "c3_objs = dict()\n",
    "####################################### Imputing Missing Values\n",
    "X_trainP, imp = handle_missing_vals_simple(\n",
    "    X_train, \n",
    "    strategy='median'\n",
    ")\n",
    "\n",
    "c3_objs['miss'] = imp\n",
    "####################################### Remove outliers with Local Outlier Factor\n",
    "X_trainP_df = pd.concat(\n",
    "    [\n",
    "        X_trainP.reset_index(drop=True), \n",
    "        pd.Series(y_train, name='Class').reset_index(drop=True)\n",
    "    ], \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "X_trainP_df, lof = detect_outliers_with_lof(\n",
    "    X_trainP_df, \n",
    "    n_neighbors=20\n",
    ")\n",
    "c3_objs['lof'] = lof\n",
    "\n",
    "X_trainP = (\n",
    "    X_trainP_df\n",
    "    .loc[:, X_trainP_df.columns != 'Class']\n",
    ")\n",
    "\n",
    "y_trainP = X_trainP_df['Class']\n",
    "####################################### Random Oversampling\n",
    "X_trainP, y_trainP = apply_smote(X_trainP, y_trainP)\n",
    "####################################### Standard Scaler\n",
    "std_scale_cols = (\n",
    "    X_trainP\n",
    "    .loc[:, ~X_trainP.columns.str.contains('Group')]\n",
    "    .columns\n",
    ")\n",
    "\n",
    "X_trainP, std_scaler = apply_std_scaler(\n",
    "    X_trainP, \n",
    "    std_scale_cols\n",
    ")\n",
    "\n",
    "c3_objs['scaler'] = std_scaler\n",
    "####################################### Remove Highly Correlated Features\n",
    "X_trainP = remove_collinear(X_trainP, threshold=0.7)\n",
    "####################################### RFECV\n",
    "classifier = DecisionTreeClassifier()\n",
    "X_trainP = select_features_rfecv(\n",
    "    X=X_trainP, \n",
    "    y=y_trainP, \n",
    "    classifier=classifier, \n",
    "    cv=3, \n",
    "    scoring='f1_weighted'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e230017-e092-4e62-8a14-5345a8c7ede4",
   "metadata": {},
   "source": [
    "### Prepare the test set according to combination 3 above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fb7be12-40c6-4249-acff-7c11bbd72d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols_test = X_test.loc[:, X_test.columns != 'Group'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c48ba29-ffe3-4158-8153-8beb3e417e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################## Imputing Missing Values\n",
    "X_testP = pd.DataFrame(c3_objs['miss'].transform(X_test), columns=X_test.columns)\n",
    "######################################## Scaling\n",
    "X_testP = pd.DataFrame(c3_objs['scaler'].transform(X_testP[num_cols_test]), columns=num_cols_test).reset_index(drop=True)\n",
    "######################################## RFECV\n",
    "subset_features_rfecv = X_trainP.columns.to_list()\n",
    "X_testP = X_testP.loc[:, subset_features_rfecv]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa1fdbb-5b7a-43b3-83af-7b48bee5c3b4",
   "metadata": {},
   "source": [
    "# Apply cross validation with f1, auc and accuracy\n",
    "\n",
    "#### *Weighted F1 Score: F1 score calculated by taking the average of F1 scores for each class. Average is weighted by support which is the number of true instances for each label. \n",
    "#### *AUC One vs One Weighted: By considering all pairwise combinations of classes, average AUC is calculated. Average is weighted by the support. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79197db7-33cc-42da-b582-ecf52eba91a6",
   "metadata": {},
   "source": [
    "## Create Class object and apply cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fcb2a67-1bbe-4f97-8660-0c76963e3245",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_cost_matrix = np.array([[0, 1, 2],\n",
    "                              [1, 0, 1],\n",
    "                              [2, 1, 0]])\n",
    "\n",
    "model_selector = ModelSelection(\n",
    "    x_train=X_trainP, \n",
    "    y_train=y_trainP,\n",
    "    estimators=estimators,\n",
    "    x_test=X_testP,\n",
    "    y_test=y_test,\n",
    "    cost_matrix=error_cost_matrix\n",
    ")\n",
    "model_selector.encode_y_train()\n",
    "model_selector.create_col_transformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "255d6131-2636-464d-91f0-d2cee3a3f369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: -1, 1: 0, 2: 1}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_selector.target_label_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ec19b29-b2f3-4d57-9c58-fbfe15b92c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Results for Mean F1 Score:\n",
      "\n",
      "RandomForest = 0.643181\n",
      "SVM = 0.503802\n",
      "LogisticRegression = 0.399198\n",
      "GradientBoost = 0.513232\n",
      "XGBoost = 0.637576\n",
      "AdaBoost = 0.419344\n",
      "\n",
      "Best Estimator (F1): RandomForest\n",
      "**********************************************\n",
      "CV Results for Mean AUC Score:\n",
      "\n",
      "RandomForest = 0.828574\n",
      "SVM = 0.713549\n",
      "LogisticRegression = 0.569741\n",
      "GradientBoost = 0.699802\n",
      "XGBoost = 0.812597\n",
      "AdaBoost = 0.587350\n",
      "\n",
      "Best Estimator (AUC): RandomForest\n",
      "**********************************************\n",
      "CV Results for Mean Accuracy Score:\n",
      "\n",
      "RandomForest = 0.647623\n",
      "SVM = 0.515572\n",
      "LogisticRegression = 0.400804\n",
      "GradientBoost = 0.519737\n",
      "XGBoost = 0.641316\n",
      "AdaBoost = 0.422121\n",
      "\n",
      "Best Estimator (Accuracy): RandomForest\n",
      "**********************************************\n",
      "CV Results for Cost Matrix Error Score:\n",
      "\n",
      "RandomForest = 0.581662\n",
      "SVM = 0.672720\n",
      "LogisticRegression = 0.791525\n",
      "GradientBoost = 0.679279\n",
      "XGBoost = 0.584311\n",
      "AdaBoost = 0.763274\n",
      "\n",
      "Best Estimator (Cost Metric Error Score): RandomForest\n"
     ]
    }
   ],
   "source": [
    "model_selector.calculate_cv_f1(n_folds=10, scoring_average='f1_weighted')\n",
    "print('**********************************************')\n",
    "model_selector.calculate_cv_auc(n_folds=10, scoring_average='roc_auc_ovo_weighted')\n",
    "print('**********************************************')   \n",
    "model_selector.calculate_cv_accuracy(n_folds=10, scoring_average='accuracy')\n",
    "print('**********************************************')   \n",
    "model_selector.calculate_cost_matrix_cv2(n_folds=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff78202-7717-4a74-9c00-2bd9aac5fb64",
   "metadata": {},
   "source": [
    "## GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f5076d9-0356-4356-86a4-f48bf781d89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'ClassificationModel__n_estimators': [50, 100, 150],\n",
    "    'ClassificationModel__criterion': ['gini', 'entropy'],\n",
    "    'ClassificationModel__max_depth': [None, 5, 10],\n",
    "    'ClassificationModel__min_samples_split': [2, 5],\n",
    "    'ClassificationModel__min_samples_leaf': [1, 2],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78553300-8e68-4d61-bcb9-30d8b722128d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "Best parameters found by GridSearchCV (f1_weighted):\n",
      "{'ClassificationModel__criterion': 'entropy', 'ClassificationModel__max_depth': None, 'ClassificationModel__min_samples_leaf': 1, 'ClassificationModel__min_samples_split': 5, 'ClassificationModel__n_estimators': 150}\n",
      "\n",
      "Best score found by GridSearchCV (f1_weighted):\n",
      "0.6367236466611358\n"
     ]
    }
   ],
   "source": [
    "model_selector.apply_grid_cv(\n",
    "    estimator=RandomForestClassifier(random_state=0),\n",
    "    params=param_grid,\n",
    "    cv=3,\n",
    "    scoring='f1_weighted'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d44c14aa-fb23-4797-a563-1549a0eb1379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: -1, 1: 0, 2: 1}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.44      0.44       619\n",
      "           1       0.15      0.11      0.13       227\n",
      "           2       0.50      0.54      0.52       754\n",
      "\n",
      "    accuracy                           0.44      1600\n",
      "   macro avg       0.36      0.36      0.36      1600\n",
      "weighted avg       0.43      0.44      0.43      1600\n",
      "\n",
      "{0: -1, 1: 0, 2: 1}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_selector.predict_on_test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
